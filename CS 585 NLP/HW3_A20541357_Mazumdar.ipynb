{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d6aafbfa-2d87-4f34-91fc-6228d87954b9",
      "metadata": {
        "id": "d6aafbfa-2d87-4f34-91fc-6228d87954b9"
      },
      "source": [
        "# CS 585 - HW 1\n",
        "• For Problems 1 through 7, please upload to Blackboard:\n",
        "o One Jupyter notebook (.ipynb file) with cell output, showing your work for both\n",
        "datasets. Name this file \"HW3_[CWID]_[LastName].ipynb\".\n",
        "o A PDF copy of the exact same notebook (same code and same output).\n",
        "o You will lose points if you do not submit both of these files. Please do not zip or\n",
        "compress files before you upload.\n",
        "• For Problem 8: Enter your written answer in Blackboard with your HW submission."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROBLEM 1 – Reading the data (5 pts)\n",
        "• Read in file \"train.tsv\" from the Stanford Sentiment Treebank (SST) as shared in the GLUE task.\n",
        "(See section \"DATA\" above.)\n",
        "• Next, split your dataset into train, test, and validation datasets with these sizes (Note that 100\n",
        "is a small size for test and validation datasets; it was selected to simplify this homework):\n",
        "o Validation: 100 rows\n",
        "o Test: 100 rows\n",
        "o Training: All remaining rows.\n",
        "• Review the column \"label\" which indicates positive=1 or negative=0 sentiment. What is the prior\n",
        "probability of each class on your training set? Show results in your notebook.\n"
      ],
      "metadata": {
        "id": "nCQDiE1-c55x"
      },
      "id": "nCQDiE1-c55x"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6cfbd0c8-48c1-4773-ad47-f0bf80f9b885",
      "metadata": {
        "id": "6cfbd0c8-48c1-4773-ad47-f0bf80f9b885",
        "outputId": "fa5a98b5-3a78-4672-ea2f-24fad40355f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive_prior_probability: 0.557968\n",
            "negative_prior_probability: 0.442032\n"
          ]
        }
      ],
      "source": [
        "# !pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file with a header row\n",
        "df = pd.read_csv(\"/content/train.tsv\", delimiter='\\t')\n",
        "\n",
        "# To split the dataset into train, test, and validation sets\n",
        "validation_set = df[:100]\n",
        "test_set = df[100:200]\n",
        "training_set = df[200:]\n",
        "\n",
        "# Calculate the prior probabilities:\n",
        "value_counts  = training_set['label'].value_counts()\n",
        "# Calculate the total count of instances\n",
        "total_count = value_counts.sum()\n",
        "\n",
        "# Calculate the prior probabilities\n",
        "prior_probabilities = value_counts / total_count\n",
        "\n",
        "# Display the prior probabilities\n",
        "# print(prior_probabilities)\n",
        "positive_prior_probability = prior_probabilities[1]\n",
        "negative_prior_probability = prior_probabilities[0]\n",
        "print(f\"positive_prior_probability: {positive_prior_probability:.6f}\")\n",
        "print(f\"negative_prior_probability: {negative_prior_probability:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROBLEM 2 – Tokenizing data (10 pts)\n",
        "• Write a function that takes a sentence as input, represented as a string, and converts it to a\n",
        "tokenized sequence padded by start and end symbols. For example, \"hello class\" would be\n",
        "converted to:\n",
        "o ['<_s>', 'hello', 'class', '</_s>']\n",
        "• Apply your function to all sentences in your training set. Show the tokenization of the first\n",
        "sentence of your training set in your notebook output.\n",
        "• What is the vocabulary size of your training set? Include your start and end symbol in your\n",
        "vocabulary. Show your result in your notebook.\n"
      ],
      "metadata": {
        "id": "cCuVLCCidt84"
      },
      "id": "cCuVLCCidt84"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')  # Download the 'punkt' tokenizer model\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKbsyW2PcBts",
        "outputId": "0206d95d-3f80-40fe-aa4c-90833ae2efee"
      },
      "id": "gKbsyW2PcBts",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to tokenize and add start/end symbols\n",
        "def tokenize_and_add_symbols(sentence):\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tokens = ['<_s>'] + tokens + ['</_s>']\n",
        "    return tokens\n",
        "\n",
        "# # Apply the function to all sentences in the training set\n",
        "# training_set['tokenized_sentence'] = training_set['sentence'].apply(tokenize_and_add_symbols)\n",
        "# Apply the function to all sentences in the training set and create a new column\n",
        "training_set = training_set.copy()\n",
        "training_set['tokenized_sentence'] = training_set['sentence'].apply(lambda x: tokenize_and_add_symbols(x))\n",
        "\n",
        "# Tokenization of the first sentence in the training set\n",
        "print(\"Tokenization of the first sentence:\")\n",
        "print(training_set['tokenized_sentence'].iloc[0])\n",
        "\n",
        "# Calculate the vocabulary size\n",
        "vocabulary = set()\n",
        "for tokens in training_set['tokenized_sentence']:\n",
        "    vocabulary.update(tokens)\n",
        "\n",
        "# Vocabulary size, including start and end symbols\n",
        "vocabulary_size = len(vocabulary)\n",
        "print(\"Vocabulary Size (including start and end symbols):\", vocabulary_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxWVR5r97wFE",
        "outputId": "ec2c4541-4cf2-4cc8-a71d-cc8ef43e9bcb"
      },
      "id": "jxWVR5r97wFE",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization of the first sentence:\n",
            "['<_s>', 'told', 'in', 'scattered', 'fashion', '</_s>']\n",
            "Vocabulary Size (including start and end symbols): 14801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROBLEM 3 – Bigram counts (10 pts)\n",
        "• Write a function that takes an array of tokenized sequences as input (i.e., a list of lists) and\n",
        "counts bigram frequencies in that dataset. Your function should return a two-level dictionary\n",
        "(dictionary of dictionaries) or similar data structure, where the value at index [wi][wj] gives the\n",
        "frequency count of bigram (wi, wj). For example, this expression would give the counts of the\n",
        "bigram \"academy award\":\n",
        "bigram_counts[\"academy\"][\"award\"]\n",
        "• Apply your function to the output of problem 2. You should build one counter that represents all\n",
        "sentences in the training dataset.\n",
        "• Use this result to show how many times a sentence starts with \"the\". That is, how often do you\n",
        "see the bigram (\"< s>\",\"the\") in your training set? Show results in your notebook.\n",
        "PROGRAMMING HINTS:\n",
        "• You can use the function nltk.bigrams to convert a sequence to bigrams, but you are not\n",
        "required to do so.\n",
        "• In python, you can use function \"dict.get(key, default)\" to return the value \"default\" if \"key\" is\n",
        "not present in a dictionary.\n"
      ],
      "metadata": {
        "id": "XN0sqz5Do5zW"
      },
      "id": "XN0sqz5Do5zW"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Function to count bigram frequencies in a list of tokenized sequences\n",
        "def count_bigrams(tokenized_sequences):\n",
        "    bigram_counts = {}\n",
        "\n",
        "    for tokens in tokenized_sequences:\n",
        "        # Convert the tokens into bigrams\n",
        "        bigrams = list(nltk.bigrams(tokens))\n",
        "\n",
        "        # Count the bigram frequencies\n",
        "        for bigram in bigrams:\n",
        "            wi, wj = bigram\n",
        "            if wi not in bigram_counts:\n",
        "                bigram_counts[wi] = {}\n",
        "            bigram_counts[wi][wj] = bigram_counts[wi].setdefault(wj, 0) + 1\n",
        "\n",
        "    return bigram_counts\n",
        "\n",
        "# Apply the function to the tokenized sentences in the training set\n",
        "tokenized_sentences = training_set['tokenized_sentence'].tolist()\n",
        "bigram_counts = count_bigrams(tokenized_sentences)\n",
        "\n",
        "# Count how often a sentence starts with \"the\"\n",
        "the_count = bigram_counts.get('<_s>', {}).get('the', 0)\n",
        "\n",
        "# Display the count of \"<_s>\", \"the\"\n",
        "print(f'Count of \"<_s>\", \"the\": {the_count}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so_lT3WrBQQp",
        "outputId": "66108ed6-f5a3-4fa2-ddc0-ca9dcf932f00"
      },
      "id": "so_lT3WrBQQp",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of \"<_s>\", \"the\": 4450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROBLEM 4 – Smoothing (20 pts)\n",
        "• Write a function that implements formula [6.13] in that E-NLP textbook (page 129, 6.2\n",
        "Smoothing and discounting). That is, write a function that applies smoothing and returns a\n",
        "(negative) log-probability of a word given the previous word in the sequence. It is suggested\n",
        "that you use these parameters:\n",
        "o The current word, wm\n",
        "o The previous word, wm-1\n",
        "o bigram counts (output of Problem 3)\n",
        "o alpha, a smoothing parameter\n",
        "o vocabulary size\n",
        "• Using this function to show the log probability that the word \"academy\" will be followed by the\n",
        "word \"award\". Try this with alpha=0.001 and alpha=0.5 (you should see very different results!).\n",
        "Show your results in your notebook.\n",
        "PROGRAMMING ALTERNATIVE: If you are familiar with python classes, you may build a LanguageModel\n",
        "class that is initialized with the above parameters and implements formula [6.13] as a member function.\n"
      ],
      "metadata": {
        "id": "0i3T03DophvJ"
      },
      "id": "0i3T03DophvJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def smoothing_log_probability(wm, wm_1, bigram_counts, alpha, size_of_vocabulary):\n",
        "    if wm_1 in bigram_counts and wm in bigram_counts[wm_1]:\n",
        "        count_wm_1_wm = bigram_counts[wm_1][wm]\n",
        "    else:\n",
        "        count_wm_1_wm = 0\n",
        "\n",
        "    prob = (count_wm_1_wm + alpha) / (sum(bigram_counts.get(wm_1, {}).values()) + (alpha * size_of_vocabulary))\n",
        "    return  math.log(prob, 2)\n",
        "\n",
        "\n",
        "alpha_1 = 0.001\n",
        "alpha_2 = 0.5\n",
        "\n",
        "log_prob_1 = smoothing_log_probability(\"award\", \"academy\", bigram_counts, alpha_1, vocabulary_size)\n",
        "log_prob_2 = smoothing_log_probability(\"award\", \"academy\", bigram_counts, alpha_2, vocabulary_size)\n",
        "\n",
        "print(f\"Negative log probability (alpha=0.001): {log_prob_1}\")\n",
        "print(f\"Negative log probability (alpha=0.5): {log_prob_2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZfZHk5ECmQT",
        "outputId": "48e04871-84cf-4e44-caee-8dbf90c4fc7a"
      },
      "id": "uZfZHk5ECmQT",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative log probability (alpha=0.001): -1.4784787789440406\n",
            "Negative log probability (alpha=0.5): -8.904464674335902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROBLEM 5 – Sentence log-probability (10 pts)\n",
        "• Write a function that returns the log-probability of a sentence which is expected to be a\n",
        "negative number. To do this, assume that the probability of a word in a sequence only depends\n",
        "on the previous word. It is suggested that you use these parameters:\n",
        "o A sentence represented as a single python string\n",
        "o bigram counts (output of Problem 3)\n",
        "o alpha, a smoothing parameter\n",
        "o vocabulary size\n",
        "• Use your function to compute the log probability of these two sentences (Note that the 2nd is\n",
        "not natural English, so it should have a lower (more negative) result that the first):\n",
        "o \"this was a really great movie but it was a little too long.\"\n",
        "o \"long too little a was it but movie great really a was this.\"\n"
      ],
      "metadata": {
        "id": "QGiO-P5Mp4RG"
      },
      "id": "QGiO-P5Mp4RG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the log-probability of a sentence using bigrams and smoothing\n",
        "def sentence_log_probability(sentence, bigram_counts, alpha, vocabulary_size):\n",
        "    # Tokenize the sentence into words\n",
        "    words = nltk.word_tokenize(sentence)\n",
        "\n",
        "    # Initialize the log probability\n",
        "    log_probability = 0.0\n",
        "\n",
        "    # Iterate through the words to calculate the log probability\n",
        "    for i in range(1, len(words)):\n",
        "        wm_minus_1 = words[i - 1]\n",
        "        wm = words[i]\n",
        "\n",
        "        # Use the calculate_negative_log_prob function\n",
        "        log_prob = smoothing_log_probability(wm, wm_minus_1, bigram_counts, alpha, vocabulary_size)\n",
        "\n",
        "        # Add the log probability to the overall log probability\n",
        "        log_probability += log_prob\n",
        "\n",
        "    return log_probability\n",
        "\n",
        "# Example sentences\n",
        "sentence1 = \"this was a really great movie but it was a little too long.\"\n",
        "sentence2 = \"long too little a was it but movie great really a was this.\"\n",
        "\n",
        "# Example usage with alpha=0.001 and vocabulary size\n",
        "alpha = 0.001\n",
        "vocabulary_size = 10000  # Replace with your vocabulary size\n",
        "\n",
        "log_prob1 = sentence_log_probability(sentence1, bigram_counts, alpha, vocabulary_size)\n",
        "log_prob2 = sentence_log_probability(sentence2, bigram_counts, alpha, vocabulary_size)\n",
        "\n",
        "print(f'Log Probability (alpha={alpha}) - Sentence 1: {log_prob1}')\n",
        "print(f'Log Probability (alpha={alpha}) - Sentence 2: {log_prob2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTz1dGX4tpro",
        "outputId": "d892f2cb-19f8-4cda-ec9a-60db0246f903"
      },
      "id": "GTz1dGX4tpro",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Probability (alpha=0.001) - Sentence 1: -91.40757002585701\n",
            "Log Probability (alpha=0.001) - Sentence 2: -218.02674910987346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROBLEM 6 – Tuning Alpha (10pts)\n",
        "Next, use your validation set to select a good value for \"alpha\".\n",
        "• Apply the function you wrote in Problem 5 to your validation dataset using 3 different values of\n",
        "\"alpha\", such as (0.001, 0.01, 0.1). For each value, show the log-likelihood estimate of the\n",
        "validation set. That is, in your notebook show the sum of the log probabilities of all sentences.\n",
        "• Which alpha gives you the best result? To indicate your selection to the grader, save your\n",
        "selected value to a variable named \"selected_alpha\".\n"
      ],
      "metadata": {
        "id": "Rmxkb6mgkm-Y"
      },
      "id": "Rmxkb6mgkm-Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of alpha values to test\n",
        "alpha_values = [0.001, 0.01, 0.1]\n",
        "\n",
        "# Initialize variables to keep track of the best alpha and its corresponding log likelihood\n",
        "best_alpha = None\n",
        "best_log_likelihood = float(\"-inf\")\n",
        "\n",
        "for alpha in alpha_values:\n",
        "    total_log_likelihood = 0.0\n",
        "\n",
        "    # Calculate log likelihood for each sentence in the validation set\n",
        "    for sentence in validation_set['sentence']:\n",
        "        # log_prob = sentence_log_probability(sentence, bigram_counts, alpha, vocabulary_size)\n",
        "        total_log_likelihood += sentence_log_probability(sentence, bigram_counts, alpha, vocabulary_size)\n",
        "\n",
        "    print(f\"Log likelihood for alpha={alpha}: {total_log_likelihood}\")\n",
        "\n",
        "    # Check if this alpha is the best so far\n",
        "    if total_log_likelihood > best_log_likelihood:\n",
        "        best_log_likelihood = total_log_likelihood\n",
        "        best_alpha = alpha\n",
        "\n",
        "# Display the best alpha and its corresponding log likelihood\n",
        "print(f\"Best alpha: {best_alpha}\")\n",
        "print(f\"Log likelihood with the best alpha: {best_log_likelihood}\")\n",
        "\n",
        "# Save the selected alpha to a variable named \"selected_alpha\"\n",
        "selected_alpha = best_alpha\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTRAb4MjpMUu",
        "outputId": "d6427f22-a165-44b4-f47c-ae8c8b7a4ee1"
      },
      "id": "hTRAb4MjpMUu",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log likelihood for alpha=0.001: -4981.168778451172\n",
            "Log likelihood for alpha=0.01: -5508.845270385804\n",
            "Log likelihood for alpha=0.1: -6644.975804447448\n",
            "Best alpha: 0.001\n",
            "Log likelihood with the best alpha: -4981.168778451172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROBLEM 7 – Applying Language Models (20 pts)\n",
        "In this problem, you will classify your test set of 100 sentences by sentiment, by applying your work\n",
        "from previous problems and modeling the language of both positive and negative sentiment.\n",
        "To do this, you can follow these steps:\n",
        "• Separate your training dataset into positive and negative sentences, and compute vocabulary\n",
        "size and bigram counts for both datasets.\n",
        "• For each of the 100 sentences in your test set:\n",
        "o Compute both a \"positive sentiment score\" and a \"negative sentiment score\" using (1)\n",
        "the function you wrote in Problem 5, (2) Bayes rule, and (3) class priors as computed in\n",
        "Problem 1.\n",
        "o Compare these scores to assign a predicted sentiment label to the sentence.\n",
        "• What is the class distribution of your predicted label? That is, how often did your method\n",
        "predict positive sentiment, correctly or incorrectly? How often did it predict negative\n",
        "sentiment? Show results in your notebook.\n",
        "• Compare your predicted label to the true sentiment label. What is the accuracy of this\n",
        "experiment? That is, how often did the true and predicted label match on the test set? Show\n",
        "results in your notebook.\n",
        "For this problem, you do not need to re-tune alpha for your positive and negative datasets (although it\n",
        "may be a good idea to do so), you can re-use the value selected in Problem 6.\n"
      ],
      "metadata": {
        "id": "kwZd0p59kqCY"
      },
      "id": "kwZd0p59kqCY"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Separate Training Dataset\n",
        "positive_training = training_set[training_set['label'] == 1]\n",
        "negative_training = training_set[training_set['label'] == 0]\n",
        "\n",
        "# Calculate vocabulary size and bigram counts for both datasets\n",
        "positive_bigram_counts = count_bigrams(positive_training['tokenized_sentence'])\n",
        "negative_bigram_counts = count_bigrams(negative_training['tokenized_sentence'])\n",
        "\n",
        "# Step 2: Classify Test Sentences\n",
        "def classify_sentiment(sentence, positive_bigram_counts, negative_bigram_counts, alpha_positive, alpha_negative, vocabulary_size, prior_positive, prior_negative):\n",
        "    positive_log_prob = sentence_log_probability(sentence, positive_bigram_counts, alpha_positive, vocabulary_size) + math.log(prior_positive)\n",
        "    negative_log_prob = sentence_log_probability(sentence, negative_bigram_counts, alpha_negative, vocabulary_size) + math.log(prior_negative)\n",
        "    return \"positive\" if positive_log_prob > negative_log_prob else \"negative\"\n",
        "\n",
        "# Classify test sentences\n",
        "selected_alpha_positive = 0.001\n",
        "selected_alpha_negative = 0.001\n",
        "\n",
        "test_set = test_set.copy()\n",
        "test_set['predicted_sentiment'] = test_set['sentence'].apply(lambda x: classify_sentiment(x, positive_bigram_counts, negative_bigram_counts, selected_alpha_positive, selected_alpha_negative, vocabulary_size, positive_prior_probability, negative_prior_probability))\n",
        "\n",
        "# Step 3: Evaluate Predictions\n",
        "correct_predictions = (test_set['label'] == (test_set['predicted_sentiment'] == 'positive')).sum()\n",
        "accuracy = correct_predictions / len(test_set)\n",
        "\n",
        "# Calculate class distribution\n",
        "predicted_positive = (test_set['predicted_sentiment'] == 'positive').sum()\n",
        "predicted_negative = (test_set['predicted_sentiment'] == 'negative').sum()\n",
        "\n",
        "print(f\"Class Distribution - Predicted Positive: {predicted_positive}\")\n",
        "print(f\"Class Distribution - Predicted Negative: {predicted_negative}\")\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heaVnpUwpUJi",
        "outputId": "8d60c8da-5714-448e-861c-ee58b06d99ca"
      },
      "id": "heaVnpUwpUJi",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution - Predicted Positive: 53\n",
            "Class Distribution - Predicted Negative: 47\n",
            "Accuracy: 92.00%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}