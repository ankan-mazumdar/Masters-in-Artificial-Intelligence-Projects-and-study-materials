{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PROBLEM 1 – Reading the data in CoNLL format (20pts)\n",
        "Note that the NCBI Disease Corpus (See section DATA above) is already split into train, development,\n",
        "and test datasets. You will use the train and test datasets in this homework.\n",
        "As noted above, you should use files in the \"ncbi-disease/conll\" subfolder. In this file format, a blank line\n",
        "indicates the start of a new sequence.\n",
        "• Write a function that reads a .tsv files in the CoNLL format and returns two “list of lists” as\n",
        "output:\n",
        "o A list of sequences of tokens, where a single token may be a word or punctuation.\n",
        "o A list of sequences of tags, representing token-level annotation. You should see these 3\n",
        "tags in your data (“B-Disease”, “I-Disease”, “O”)\n",
        "• Apply your function to train.tsv and test.tsv. To show you have read in the data correctly, show\n",
        "the following in your notebook output:\n",
        "o The number of sequences in train and test. (You should see 5432 sequences in train and\n",
        "940 sequences in test.)\n",
        "o The tokens and tags of the first sequence in the training dataset. Your output should\n",
        "look like this:\n",
        "['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous',\n",
        "'polyposis', 'coli', 'tumour', 'suppressor', '.']\n",
        "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'IDisease', 'O', 'O']\n"
      ],
      "metadata": {
        "id": "oEyquVj1LUsg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ06UG8LBJOy",
        "outputId": "bab43b66-e411-4033-c3c5-fbc3850994a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sequences in train: 5432\n",
            "Number of sequences in test: 940\n",
            "Tokens of the first sequence in training dataset:\n",
            "['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous', 'polyposis', 'coli', 'tumour', 'suppressor', '.']\n",
            "Tags of the first sequence in training dataset:\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "def read_conll_file(file_path):\n",
        "    # Initialize lists to hold tokens and tags\n",
        "    tokens, tags = [], []\n",
        "\n",
        "    # Open the CoNLL file for reading\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        # Initialize current sequence lists\n",
        "        current_tokens, current_tags = [], []\n",
        "\n",
        "        # Read lines from the file\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line:  # If the line is not empty\n",
        "                parts = line.split('\\t')\n",
        "                token, tag = parts[0], parts[1]\n",
        "                current_tokens.append(token)\n",
        "                current_tags.append(tag)\n",
        "            else:  # Empty line indicates the end of a sequence\n",
        "                tokens.append(current_tokens)\n",
        "                tags.append(current_tags)\n",
        "                current_tokens, current_tags = [], []\n",
        "\n",
        "    return tokens, tags\n",
        "\n",
        "# Apply the function to train.tsv and test.tsv\n",
        "train_tokens, train_tags = read_conll_file('/content/conll/train.tsv')\n",
        "test_tokens, test_tags = read_conll_file('/content/conll/test.tsv')\n",
        "\n",
        "# Display the number of sequences in train and test\n",
        "print(\"Number of sequences in train:\", len(train_tokens))\n",
        "print(\"Number of sequences in test:\", len(test_tokens))\n",
        "\n",
        "# Display the tokens and tags of the first sequence in the training dataset\n",
        "print(\"Tokens of the first sequence in training dataset:\")\n",
        "print(train_tokens[0])\n",
        "print(\"Tags of the first sequence in training dataset:\")\n",
        "print(train_tags[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROBLEM 2 – Data Discovery (5 pts)\n",
        "In this problem you will examine the data that you read into memory in the previous problem. Using the\n",
        "training dataset for analysis, show the following in your notebook output:\n",
        "• The count of each of the 3 tags in the training data: “B-Disease”, “I-Disease”, and “O”. Note that\n",
        "the most frequent token is \"O\", since most words are not part of a disease mention.\n",
        "• The 20 most common words/tokens that appear with the tags “B-Disease” or “I-Disease”. That\n",
        "is, show words that often appear disease mentions. (You may show frequent “B-Disease” and “IDisease” words separately, or you may combine them into a single list.)\n",
        "• OPTIONAL: Any other data exploration you would like to perform. For example, you may want to\n",
        "print and read a small sample of token sequences, to become familiar with the data.\n",
        "Review the list of words that commonly appear in disease mentions. Do you see any patterns? (You do\n",
        "not need to answer in writing, but it may be helpful in Problem 3 where you design a feature.)\n"
      ],
      "metadata": {
        "id": "JdazjfEtLZAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In the realm of data, let's explore and see,\n",
        "# What insights the training dataset brings to be.\n",
        "# With Python's aid, we'll unveil the hidden lore,\n",
        "# The count of tags and common words galore.\n",
        "\n",
        "# First, we shall count the tags three,\n",
        "# \"B-Disease,\" \"I-Disease,\" and \"O\" you'll agree.\n",
        "# Among them, \"O\" shall reign supreme,\n",
        "# For non-disease words, it's like a dream.\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# Combine tokens and tags from training data\n",
        "combined_data = list(zip(train_tokens, train_tags))\n",
        "\n",
        "# Count of each tag in the training data\n",
        "tag_counts = Counter(tag for tags in train_tags for tag in tags)\n",
        "\n",
        "# Display the count of each tag\n",
        "print(\"Count of 'B-Disease' tag:\", tag_counts['B-Disease'])\n",
        "print(\"Count of 'I-Disease' tag:\", tag_counts['I-Disease'])\n",
        "print(\"Count of 'O' tag:\", tag_counts['O'])\n",
        "# With these lines of code, the tags' count we found,\n",
        "# To \"B-Disease,\" \"I-Disease,\" and \"O,\" we're bound.\n",
        "# Now, let's seek the common words that dwell,\n",
        "# Within the realm of disease, as stories tell.\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# Create a list of words associated with \"B-Disease\" and \"I-Disease\"\n",
        "disease_words = [token for tokens, tags in combined_data for token, tag in zip(tokens, tags) if tag in ['B-Disease', 'I-Disease']]\n",
        "\n",
        "# Count the frequency of each word\n",
        "word_counts = Counter(disease_words)\n",
        "\n",
        "# Display the 20 most common disease words\n",
        "most_common_disease_words = word_counts.most_common(20)\n",
        "print(\"The 20 most common disease words:\")\n",
        "for word, count in most_common_disease_words:\n",
        "    print(word, \":\", count)\n",
        "\n",
        "\n",
        "# With this code, the words are revealed,\n",
        "# That in disease mentions, are often sealed.\n",
        "# The 20 most common, they grace our sight,\n",
        "# In this poetic exploration, a data delight.\n",
        "\n",
        "# Optionally, we may journey further to explore,\n",
        "# Sample token sequences, data's core.\n",
        "# To discern patterns, to understand,\n",
        "# The secrets of the data, like grains of sand.\n",
        "\n",
        "# With these revelations, we set the stage,\n",
        "# To craft features in the next coding page.\n",
        "# In the world of data, our understanding grows,\n",
        "# As we navigate the rivers where knowledge flows."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUF5lioYLZeH",
        "outputId": "bbadbe5f-78d7-4a9a-f756-382e8b97198b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of 'B-Disease' tag: 5145\n",
            "Count of 'I-Disease' tag: 6122\n",
            "Count of 'O' tag: 124819\n",
            "The 20 most common disease words:\n",
            "- : 636\n",
            "deficiency : 322\n",
            "syndrome : 281\n",
            "cancer : 269\n",
            "disease : 256\n",
            "of : 178\n",
            "dystrophy : 176\n",
            "breast : 151\n",
            "ovarian : 132\n",
            "X : 122\n",
            "and : 120\n",
            "DM : 120\n",
            "ALD : 114\n",
            "DMD : 110\n",
            "APC : 100\n",
            "disorder : 94\n",
            "muscular : 94\n",
            "G6PD : 92\n",
            "linked : 81\n",
            "the : 78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROBLEM 3 – Building features (20 pts)\n",
        "In this problem, you will build the features that you will use in your CRF model. You may find it helpful to\n",
        "refer to this demo notebook, to understand how to work with the python-crfsuite library.\n",
        "• Write a function that takes two inputs:\n",
        "o A sequence of tokens\n",
        "o An integer position, pointing to one token in that sequence.\n",
        "and returns a list of features, represented as a list of strings. At minimum, include these\n",
        "features:\n",
        "o The current word/token in lower case\n",
        "o The suffix (last 3 characters) of the current word\n",
        "o The previous word/token (position i-1) or “BOS” if at the beginning of the sequence\n",
        "o The next word/token (position i+1), or “EOS” if at the beginning of the sequence\n",
        "o At least one other feature of your choice\n",
        "• Apply your function your train and test token sequences (from output of Problem 1).\n",
        "• To show that you have completed this step, apply your output to the first 3 words in the first\n",
        "sequence of the training set. Your output should look something like this (note the names and\n",
        "order of your features in your notebook do not need to match this output):\n",
        "['w0.lower=identification', 'w0.suffix3=ion', <other features not shown...>, BOS ]\n",
        "['w0.lower=of', 'w0.suffix3=of', <other features not shown...>]\n",
        "['w0.lower=apc2', 'w0.suffix3=PC2', <other features not shown...>]\n"
      ],
      "metadata": {
        "id": "mIGCjBPkLaEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In the land of feature crafting, we embark today,\n",
        "# To pave the way for a robust model, we say.\n",
        "# With a function's grace, our tools we shall employ,\n",
        "# Creating features for tokens to bring us joy.\n",
        "\n",
        "# A function we script, to shape our features right,\n",
        "# Given tokens and a position, in the data's light.\n",
        "# From these, we extract knowledge with delight,\n",
        "# Features to empower our model's might.\n",
        "\n",
        "# Here's the code, let's unveil the art,\n",
        "# Of crafting features, each playing its part.\n",
        "\n",
        "def extract_features(tokens, position):\n",
        "    # Get the current word and its last 3 characters as features\n",
        "    current_word = tokens[position].lower()\n",
        "    word_suffix = tokens[position][-3:] if len(tokens[position]) > 2 else tokens[position]\n",
        "\n",
        "    # Get the previous and next words (or \"BOS\" and \"EOS\" if at the sequence boundaries)\n",
        "    previous_word = tokens[position - 1] if position > 0 else \"BOS\"\n",
        "    next_word = tokens[position + 1] if position < len(tokens) - 1 else \"EOS\"\n",
        "\n",
        "    # Include one more feature of your choice (e.g., word shape, capitalization)\n",
        "    # For example, let's add a feature that represents whether the current word is capitalized\n",
        "    is_capitalized = \"Capitalized\" if current_word.istitle() else \"NotCapitalized\"\n",
        "\n",
        "    # Return the features as a list of strings\n",
        "    features = [\n",
        "        f'w0.lower={current_word}',\n",
        "        f'w0.suffix3={word_suffix}',\n",
        "        f'w-1={previous_word}',\n",
        "        f'w+1={next_word}',\n",
        "        f'w0.capitalization={is_capitalized}'\n",
        "    ]\n",
        "\n",
        "    return features\n",
        "\n",
        "# Apply the function to the first 3 words in the first sequence of the training set\n",
        "for i in range(3):\n",
        "    features = extract_features(train_tokens[0], i)\n",
        "    print(features)\n",
        "\n",
        "\n",
        "# With this code, we take a token's hand,\n",
        "# And from it, features we gently expand.\n",
        "# Lowercased words, suffixes that guide,\n",
        "# Contextual words on either side.\n",
        "\n",
        "# Our chosen feature, capitalization's might,\n",
        "# Sheds light on tokens, be they bold or light.\n",
        "# With these crafted gems, our journey's begun,\n",
        "# To empower the model, we craft features, one by one."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYV_uVfALaie",
        "outputId": "4169cc3e-7503-4f4c-bd5d-be4a28383d1d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['w0.lower=identification', 'w0.suffix3=ion', 'w-1=BOS', 'w+1=of', 'w0.capitalization=NotCapitalized']\n",
            "['w0.lower=of', 'w0.suffix3=of', 'w-1=Identification', 'w+1=APC2', 'w0.capitalization=NotCapitalized']\n",
            "['w0.lower=apc2', 'w0.suffix3=PC2', 'w-1=of', 'w+1=,', 'w0.capitalization=NotCapitalized']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 3\n",
        "def get_features(tokens, i):\n",
        "\n",
        "  features = []\n",
        "\n",
        "  # Baseline features\n",
        "  features.append(f\"w{i}.lower={tokens[i].lower()}\")\n",
        "  features.append(f\"w{i}.suffix3={tokens[i][-3:]}\")\n",
        "\n",
        "  if i > 0:\n",
        "    features.append(f\"w{i-1}={tokens[i-1]}\")\n",
        "  else:\n",
        "    features.append(\"BOS\")\n",
        "\n",
        "  if i < len(tokens)-1:\n",
        "    features.append(f\"w{i+1}={tokens[i+1]}\")\n",
        "  else:\n",
        "    features.append(\"EOS\")\n",
        "\n",
        "  # Additional feature\n",
        "  features.append(f\"w{i}.isdigit={str(tokens[i].isdigit()).lower()}\")\n",
        "\n",
        "  return features\n",
        "\n",
        "train_features = [get_features(seq, i) for seq in train_tokens for i in range(len(seq))]\n",
        "test_features = [get_features(seq, i) for seq in test_tokens for i in range(len(seq))]\n",
        "\n",
        "print(train_features[0][:3])\n",
        "print(test_features[0][:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLuF1CjLyttS",
        "outputId": "c7f71f6d-a982-4cb4-9428-c4e6b0a61b2d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['w0.lower=identification', 'w0.suffix3=ion', 'BOS']\n",
            "['w0.lower=clustering', 'w0.suffix3=ing', 'BOS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROBLEM 4 – Training a CRF model (20 pts)\n",
        "In this problem, you will train a CRF model and evaluate it using metrics computed over individual tags.\n",
        "• Using the python-crfsuite library, train a CRF sequential tagging model using feature sequences\n",
        "that you built in the previous step. Using your training data as input.\n",
        "• Apply your model to your test dataset to generate predicted tag sequences.\n",
        "• For each of the 3 labels (\"B-Disease\", \"I-Disease\", and “O\") show precision, recall, f1-score. [You\n",
        "may use the sckit-learn function classification_report to complete this step. You may also want\n",
        "to “flatten” both the true and predicted tags into a single list of tags to apply this function.]\n"
      ],
      "metadata": {
        "id": "W_Unu0GBPosT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-crfsuite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_KapgCZQOCr",
        "outputId": "1dfeed26-529e-45af-8e8d-5c74a90105c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-crfsuite\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycrfsuite\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Prepare training data\n",
        "X_train = [extract_features(tokens, i) for tokens in train_tokens for i in range(len(tokens))]\n",
        "y_train = [tag for tags in train_tags for tag in tags]\n",
        "\n",
        "# Prepare test data\n",
        "X_test = [extract_features(tokens, i) for tokens in test_tokens for i in range(len(tokens))]\n",
        "y_test = [tag for tags in test_tags for tag in tags]\n",
        "\n",
        "# Initialize and train the CRF model\n",
        "trainer = pycrfsuite.Trainer()\n",
        "for x, y in zip(X_train, y_train):\n",
        "    trainer.append(x, y)\n",
        "\n",
        "trainer.set_params({\n",
        "    'c1': 1.0,\n",
        "    'c2': 1e-3,\n",
        "    'max_iterations': 50,\n",
        "    'feature.possible_transitions': True\n",
        "})\n",
        "\n",
        "trainer.train('disease_crf_model.crfsuite')\n",
        "\n",
        "# Load the trained model\n",
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('disease_crf_model.crfsuite')\n",
        "\n",
        "# Predict tags for the test dataset\n",
        "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
        "\n",
        "# Flatten the true and predicted tags\n",
        "y_true_flat = [tag for tags in y_test for tag in tags]\n",
        "y_pred_flat = [tag for tags in y_pred for tag in tags]\n",
        "\n",
        "# Calculate precision, recall, and f1-score\n",
        "report = classification_report(y_true_flat, y_pred_flat, target_names=[\"B-Disease\", \"I-Disease\", \"O\"])\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "bqOe-hFNQH8A",
        "outputId": "7e589083-df21-4579-d473-da526df31854"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-acd1b9c8852b>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Train the CRF model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_crf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# Evaluate the model on the test data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-acd1b9c8852b>\u001b[0m in \u001b[0;36mtrain_crf_model\u001b[0;34m(features, labels)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'pycrfsuite._pycrfsuite.Tagger' object has no attribute 'fit'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycrfsuite\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Prepare training data\n",
        "X_train = [extract_features(tokens, i) for tokens in train_tokens for i in range(len(tokens))]\n",
        "y_train = [tag for tags in train_tags for tag in tags]\n",
        "\n",
        "# Prepare test data\n",
        "X_test = [extract_features(tokens, i) for tokens in test_tokens for i in range(len(tokens))]\n",
        "y_test = [tag for tags in test_tags for tag in tags]\n",
        "\n",
        "print (type(X_train),type(y_train),type(X_test),type(y_test))\n",
        "print (len(X_train),len(y_train),len(X_test),len(y_test))\n",
        "print (len(X_train[0]),len(y_train[0]),len(X_test[0]),len(y_test[0]))\n",
        "print (X_train[0],y_train[0])\n",
        "\n",
        "# # Initialize the CRF model trainer\n",
        "# trainer = pycrfsuite.Trainer()\n",
        "\n",
        "# # Prepare your training data\n",
        "# for xseq, yseq in zip(X_train, y_train):\n",
        "#     trainer.append(xseq, yseq)\n",
        "\n",
        "# # Set training parameters\n",
        "# trainer.set_params({\n",
        "#     'c1': 1.0,\n",
        "#     'c2': 1e-3,\n",
        "#     'max_iterations': 50,\n",
        "#     'feature.possible_transitions': True\n",
        "# })\n",
        "\n",
        "# # Train the CRF model and save it\n",
        "# trainer.train('disease_crf_model.crfsuite')\n",
        "\n",
        "# # Load the trained model\n",
        "# tagger = pycrfsuite.Tagger()\n",
        "# tagger.open('disease_crf_model.crfsuite')\n",
        "\n",
        "# # Make predictions on the test data\n",
        "# y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
        "\n",
        "# # Flatten the true and predicted labels for evaluation\n",
        "# y_true_flat = [label for labels in y_test for label in labels]\n",
        "# y_pred_flat = [label for labels in y_pred for label in labels]\n",
        "\n",
        "# # Calculate precision, recall, and F1-score\n",
        "# report = classification_report(y_true_flat, y_pred_flat, target_names=[\"B-Disease\", \"I-Disease\", \"O\"])\n",
        "# print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKdhHMQuVgEK",
        "outputId": "d675e557-8d14-4e02-fcdc-c81b5e990292"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> <class 'list'> <class 'list'> <class 'list'>\n",
            "136086 136086 24497 24497\n",
            "5 1 5 1\n",
            "['w0.lower=identification', 'w0.suffix3=ion', 'w-1=BOS', 'w+1=of', 'w0.capitalization=NotCapitalized'] O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycrfsuite\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load training data\n",
        "train_tokens, train_tags = load_train_data(train_file)\n",
        "\n",
        "# Load test data\n",
        "test_tokens, test_tags = load_test_data(test_file)\n",
        "\n",
        "# Extract features for train and test\n",
        "train_features = extract_features(train_tokens)\n",
        "test_features = extract_features(test_tokens)\n",
        "\n",
        "# Initialize CRF model\n",
        "crf = pycrfsuite.Trainer()\n",
        "\n",
        "# Train CRF\n",
        "crf.train(train_features, train_tags)\n",
        "\n",
        "# Predict tags on test features\n",
        "pred_tags = crf.tag(test_features)\n",
        "\n",
        "# Flatten tags\n",
        "flat_test_tags = [tag for seq in test_tags for tag in seq]\n",
        "flat_pred_tags = [tag for seq in pred_tags for tag in seq]\n",
        "\n",
        "# Compute metrics\n",
        "report = classification_report(flat_test_tags, flat_pred_tags)\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "HUU1ociFzQIG",
        "outputId": "395f234d-b745-4a17-a28d-8d90cdda1e17"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-edf7132b5aef>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROBLEM 5 – Inspecting the trained model (10 pts)\n",
        "In this problem you will examine parameter weights assigned by your model. You can do this by calling\n",
        "“tagger.info().transitions” and “tagger.info().state_features” on your trained model object.\n",
        "• In your notebook, show parameter weights given to transitions between the 3 tag types (\"BDisease\", \"I-Disease\", and \"O\").\n",
        "• Refer back to the feature you designed in Problem 3 (the feature \"of your choice\"). Show the\n",
        "parameter weights assigned to this feature. You may truncate this list if it is very long. [This may\n",
        "happen if you included a word from the sequence in the feature name, so your feature was\n",
        "expanded to become a larger set of features that grows with your vocabulary]\n",
        "• *IF* your feature was dropped during model training (that is, there is nothing to show in the\n",
        "previous step) then return to Problem 4 and design a new feature that is used in your model.\n",
        "PROBLEM 6 – Document level performance (10 pts)\n",
        "Tag-level accuracy is easy to compute, but it is not very easy to understand. In particular, one disease\n",
        "reference may cover both \"B-Disease\" and \"I-Disease\" tokens. To give another view of model\n",
        "performance, compute document-level precision and recall on your experiment output. To do this:\n",
        "• Write a function that aggregates token-level tags to a document-level label. For example,\n",
        "convert a tag sequence like [\"O\", \"B-Disease\", \"I-Disease\", \"O\", \"O\"] to a single label y=1. Your\n",
        "function should assign y=1 to a sequence with one or more disease mentions (at least one \"BDisease\" tag) and y=0 to a sequence with no disease mentions.\n",
        "• Apply your function to both true and predicted document-level labels from your test set. Use\n",
        "the output to compute document level precision and recall of your model. Show your results in\n",
        "your notebook.\n",
        "PROBLEM 7 – State Transitions (10 pts – Answer in Blackboard)\n",
        "The python-crfsuite library allows you to set a Boolean hyper-parameter called\n",
        "“feature.possible_transitions”. If this parameter is True, then the model may output tag-to-tag\n",
        "transitions that were never seen in training data. [You do not need to apply this parameter in your code\n",
        "to answer this question]\n",
        "• What is an example of one tag-to-tag transition that never occurred in the training data?\n",
        "• For this particular experiment, do you think it makes sense to set this parameter to True or\n",
        "False? That is, should you allow transitions that never occurred in the training data? Explain your\n",
        "answer briefly."
      ],
      "metadata": {
        "id": "w8iaiVujQhE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn-crfsuite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCgtA4EB0uN4",
        "outputId": "d6dd8d35-fd13-4c9a-ea82-195913c49504"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (0.9.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (4.66.1)\n",
            "Installing collected packages: sklearn-crfsuite\n",
            "Successfully installed sklearn-crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_conll(file_path):\n",
        "    sequences = []\n",
        "    tags = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        sequence = []\n",
        "        tag_sequence = []\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                token, tag = line.split('\\t')\n",
        "                sequence.append(token)\n",
        "                tag_sequence.append(tag)\n",
        "            else:\n",
        "                sequences.append(sequence)\n",
        "                tags.append(tag_sequence)\n",
        "                sequence = []\n",
        "                tag_sequence = []\n",
        "        if sequence:\n",
        "            sequences.append(sequence)\n",
        "            tags.append(tag_sequence)\n",
        "    return sequences, tags\n",
        "\n",
        "# Read train.tsv and test.tsv files\n",
        "train_sequences, train_tags = read_conll('/content/conll/train.tsv')\n",
        "test_sequences, test_tags = read_conll('/content/conll/test.tsv')\n",
        "\n",
        "# Print the number of sequences in train and test\n",
        "print(\"Number of sequences in train:\", len(train_sequences))\n",
        "print(\"Number of sequences in test:\", len(test_sequences))\n",
        "\n",
        "# Print the tokens and tags of the first sequence in the training dataset\n",
        "print(\"Tokens of the first sequence in train:\")\n",
        "print(train_sequences[0])\n",
        "print(\"Tags of the first sequence in train:\")\n",
        "print(train_tags[0])\n",
        "\n",
        "print('Problem 2 Solution------>>>>>')\n",
        "from collections import Counter\n",
        "\n",
        "# Count of each tag in the training data\n",
        "tag_counts = Counter(tag for sequence in train_tags for tag in sequence)\n",
        "print(\"Tag counts in train:\", tag_counts)\n",
        "\n",
        "# Word counts for B-Disease and I-Disease tags\n",
        "bdisease_words = [token for sequence, tag_sequence in zip(train_sequences, train_tags) for token, tag in zip(sequence, tag_sequence) if tag == 'B-Disease']\n",
        "idisease_words = [token for sequence, tag_sequence in zip(train_sequences, train_tags) for token, tag in zip(sequence, tag_sequence) if tag == 'I-Disease']\n",
        "bdisease_counts = Counter(bdisease_words)\n",
        "idisease_counts = Counter(idisease_words)\n",
        "print(\"20 most common words/tokens with B-Disease tag:\")\n",
        "print(bdisease_counts.most_common(20))\n",
        "print(\"20 most common words/tokens with I-Disease tag:\")\n",
        "print(idisease_counts.most_common(20))\n",
        "\n",
        "\n",
        "print('Problem 3 Solution------>>>>>')\n",
        "def get_features(tokens, position):\n",
        "    features = []\n",
        "    current_word = tokens[position].lower()\n",
        "    current_suffix = tokens[position][-3:]\n",
        "    previous_word = tokens[position - 1] if position > 0 else 'BOS'\n",
        "    next_word = tokens[position + 1] if position < len(tokens) - 1 else 'EOS'\n",
        "\n",
        "    features.append('w0.lower=' + current_word)\n",
        "    features.append('w0.suffix3=' + current_suffix)\n",
        "    features.append('w-1=' + previous_word)\n",
        "    features.append('w+1=' + next_word)\n",
        "\n",
        "    # Add your own additional feature(s) here\n",
        "\n",
        "    return features\n",
        "\n",
        "# Test the get_features function on the first 3 words of the first sequence in the training set\n",
        "for i in range(3):\n",
        "    features = get_features(train_sequences[0], i)\n",
        "    print(features)\n",
        "\n",
        "print('Problem 4 Solution------>>>>>')\n",
        "import sklearn_crfsuite\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize CRF model and fit it on training data\n",
        "crf_model = sklearn_crfsuite.CRF()\n",
        "crf_model.fit(train_sequences, train_tags)\n",
        "\n",
        "# Use the fitted model to predict tags on the test data\n",
        "predicted_tags = crf_model.predict(test_sequences)\n",
        "\n",
        "# Flatten the true and predicted tags into single lists\n",
        "true_tags = [tag for sequence in test_tags for tag in sequence]\n",
        "predicted_tags = [tag for sequence in predicted_tags for tag in sequence]\n",
        "\n",
        "# Compute precision, recall, and f1-score for each label\n",
        "report = classification_report(true_tags, predicted_tags)\n",
        "print(\"Precision, Recall, and F1-score:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLjlQ6rI0XGK",
        "outputId": "2c2c1f6a-f5ff-432e-b70c-97ad00dfe0cc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sequences in train: 5432\n",
            "Number of sequences in test: 940\n",
            "Tokens of the first sequence in train:\n",
            "['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous', 'polyposis', 'coli', 'tumour', 'suppressor', '.']\n",
            "Tags of the first sequence in train:\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'O', 'O']\n",
            "Problem 2 Solution------>>>>>\n",
            "Tag counts in train: Counter({'O': 124819, 'I-Disease': 6122, 'B-Disease': 5145})\n",
            "20 most common words/tokens with B-Disease tag:\n",
            "[('DM', 120), ('breast', 115), ('DMD', 110), ('APC', 94), ('X', 92), ('ALD', 86), ('PWS', 75), ('G6PD', 68), ('WAS', 63), ('autosomal', 58), ('familial', 58), ('myotonic', 57), ('Duchenne', 56), ('HD', 55), ('PKU', 52), ('aniridia', 50), ('deficiency', 47), ('ovarian', 46), ('hereditary', 45), ('VHL', 45)]\n",
            "20 most common words/tokens with I-Disease tag:\n",
            "[('-', 636), ('syndrome', 281), ('deficiency', 275), ('disease', 256), ('cancer', 230), ('of', 178), ('dystrophy', 176), ('and', 120), ('disorder', 92), ('ovarian', 86), ('muscular', 84), ('linked', 81), ('the', 78), ('polyposis', 59), ('recessive', 52), ('(', 46), (')', 46), ('cancers', 45), ('tumors', 39), ('Sachs', 38)]\n",
            "Problem 3 Solution------>>>>>\n",
            "['w0.lower=identification', 'w0.suffix3=ion', 'w-1=BOS', 'w+1=of']\n",
            "['w0.lower=of', 'w0.suffix3=of', 'w-1=Identification', 'w+1=APC2']\n",
            "['w0.lower=apc2', 'w0.suffix3=PC2', 'w-1=of', 'w+1=,']\n",
            "Problem 4 Solution------>>>>>\n",
            "Precision, Recall, and F1-score:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-Disease       0.63      0.15      0.24       960\n",
            "   I-Disease       0.47      0.13      0.21      1087\n",
            "           O       0.93      0.99      0.96     22450\n",
            "\n",
            "    accuracy                           0.92     24497\n",
            "   macro avg       0.67      0.42      0.47     24497\n",
            "weighted avg       0.90      0.92      0.90     24497\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycrfsuite\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize CRF model\n",
        "crf_model = pycrfsuite.Trainer()\n",
        "\n",
        "# Add training data to the model\n",
        "for sequence, tag_sequence in zip(train_sequences, train_tags):\n",
        "    crf_model.append(sequence, tag_sequence)\n",
        "\n",
        "# Set algorithm parameters (optional)\n",
        "crf_model.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 100,  # maximum number of iterations\n",
        "    'feature.possible_transitions': True  # allow tag transitions not present in the training data\n",
        "})\n",
        "\n",
        "# Train the CRF model\n",
        "crf_model.train('model.crfsuite')\n",
        "\n",
        "# Initialize a new CRF model for prediction\n",
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('model.crfsuite')\n",
        "\n",
        "# Use the model to predict tags on the test data\n",
        "predicted_tags = [tagger.tag(sequence) for sequence in test_sequences]\n",
        "\n",
        "# Flatten the true and predicted tags into single lists\n",
        "true_tags = [tag for sequence in test_tags for tag in sequence]\n",
        "predicted_tags = [tag for sequence in predicted_tags for tag in sequence]\n",
        "\n",
        "# Compute precision, recall, and f1-score for each label\n",
        "report = classification_report(true_tags, predicted_tags)\n",
        "print(\"Precision, Recall, and F1-score:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwOoktRQzP_c",
        "outputId": "e21541c3-46cb-45b8-e2e3-901888e46898"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 224\n",
            "Seconds required: 0.054\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 1.000000\n",
            "c2: 0.001000\n",
            "num_memories: 6\n",
            "max_iterations: 100\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "***** Iteration #1 *****\n",
            "Loss: 60423.946806\n",
            "Feature norm: 1.000000\n",
            "Error norm: 39234.889966\n",
            "Active features: 222\n",
            "Line search trials: 1\n",
            "Line search step: 0.000007\n",
            "Seconds required for this iteration: 0.070\n",
            "\n",
            "***** Iteration #2 *****\n",
            "Loss: 49982.906930\n",
            "Feature norm: 1.336998\n",
            "Error norm: 17901.896707\n",
            "Active features: 216\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.038\n",
            "\n",
            "***** Iteration #3 *****\n",
            "Loss: 45605.097285\n",
            "Feature norm: 1.540933\n",
            "Error norm: 14719.544187\n",
            "Active features: 210\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.048\n",
            "\n",
            "***** Iteration #4 *****\n",
            "Loss: 40387.617965\n",
            "Feature norm: 1.902508\n",
            "Error norm: 16155.977042\n",
            "Active features: 188\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.048\n",
            "\n",
            "***** Iteration #5 *****\n",
            "Loss: 33870.327518\n",
            "Feature norm: 2.220642\n",
            "Error norm: 7113.436651\n",
            "Active features: 194\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #6 *****\n",
            "Loss: 31665.737762\n",
            "Feature norm: 2.738012\n",
            "Error norm: 15508.298231\n",
            "Active features: 209\n",
            "Line search trials: 2\n",
            "Line search step: 0.500000\n",
            "Seconds required for this iteration: 0.069\n",
            "\n",
            "***** Iteration #7 *****\n",
            "Loss: 30503.220075\n",
            "Feature norm: 3.001784\n",
            "Error norm: 6167.571691\n",
            "Active features: 216\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #8 *****\n",
            "Loss: 29665.612051\n",
            "Feature norm: 3.348294\n",
            "Error norm: 13234.269691\n",
            "Active features: 218\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #9 *****\n",
            "Loss: 28558.988890\n",
            "Feature norm: 3.665303\n",
            "Error norm: 4592.507260\n",
            "Active features: 217\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.039\n",
            "\n",
            "***** Iteration #10 *****\n",
            "Loss: 27075.261210\n",
            "Feature norm: 4.277922\n",
            "Error norm: 5712.971717\n",
            "Active features: 213\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.039\n",
            "\n",
            "***** Iteration #11 *****\n",
            "Loss: 24779.818995\n",
            "Feature norm: 5.671411\n",
            "Error norm: 4755.608260\n",
            "Active features: 206\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.038\n",
            "\n",
            "***** Iteration #12 *****\n",
            "Loss: 24532.499176\n",
            "Feature norm: 7.946577\n",
            "Error norm: 22968.697359\n",
            "Active features: 209\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #13 *****\n",
            "Loss: 22820.209359\n",
            "Feature norm: 8.147395\n",
            "Error norm: 1721.578174\n",
            "Active features: 214\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.042\n",
            "\n",
            "***** Iteration #14 *****\n",
            "Loss: 22483.945624\n",
            "Feature norm: 8.885090\n",
            "Error norm: 1634.032267\n",
            "Active features: 216\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #15 *****\n",
            "Loss: 21243.660186\n",
            "Feature norm: 12.723469\n",
            "Error norm: 1545.652109\n",
            "Active features: 208\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #16 *****\n",
            "Loss: 20988.153333\n",
            "Feature norm: 14.018401\n",
            "Error norm: 3362.730252\n",
            "Active features: 207\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.043\n",
            "\n",
            "***** Iteration #17 *****\n",
            "Loss: 20762.302971\n",
            "Feature norm: 14.214317\n",
            "Error norm: 4178.185579\n",
            "Active features: 214\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.043\n",
            "\n",
            "***** Iteration #18 *****\n",
            "Loss: 20650.923509\n",
            "Feature norm: 14.349815\n",
            "Error norm: 2348.696984\n",
            "Active features: 215\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #19 *****\n",
            "Loss: 20609.250941\n",
            "Feature norm: 14.432989\n",
            "Error norm: 2021.377539\n",
            "Active features: 213\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #20 *****\n",
            "Loss: 20556.213203\n",
            "Feature norm: 14.498690\n",
            "Error norm: 1827.924184\n",
            "Active features: 216\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #21 *****\n",
            "Loss: 20530.501994\n",
            "Feature norm: 14.679755\n",
            "Error norm: 3209.864426\n",
            "Active features: 216\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.039\n",
            "\n",
            "***** Iteration #22 *****\n",
            "Loss: 20503.367231\n",
            "Feature norm: 14.786529\n",
            "Error norm: 4554.482069\n",
            "Active features: 216\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #23 *****\n",
            "Loss: 20389.101616\n",
            "Feature norm: 14.952108\n",
            "Error norm: 2253.482912\n",
            "Active features: 214\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #24 *****\n",
            "Loss: 20370.568050\n",
            "Feature norm: 15.053543\n",
            "Error norm: 3712.126362\n",
            "Active features: 214\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #25 *****\n",
            "Loss: 20291.840799\n",
            "Feature norm: 15.160955\n",
            "Error norm: 1875.711717\n",
            "Active features: 214\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #26 *****\n",
            "Loss: 20273.289378\n",
            "Feature norm: 15.280397\n",
            "Error norm: 3142.108839\n",
            "Active features: 214\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #27 *****\n",
            "Loss: 20211.086141\n",
            "Feature norm: 15.288937\n",
            "Error norm: 1570.966260\n",
            "Active features: 214\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #28 *****\n",
            "Loss: 20171.548988\n",
            "Feature norm: 15.247059\n",
            "Error norm: 2405.063435\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #29 *****\n",
            "Loss: 20130.522468\n",
            "Feature norm: 15.219583\n",
            "Error norm: 2669.881862\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #30 *****\n",
            "Loss: 20070.799842\n",
            "Feature norm: 15.161173\n",
            "Error norm: 3339.435917\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.038\n",
            "\n",
            "***** Iteration #31 *****\n",
            "Loss: 20006.204479\n",
            "Feature norm: 15.152712\n",
            "Error norm: 2487.367933\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #32 *****\n",
            "Loss: 19957.275722\n",
            "Feature norm: 15.079335\n",
            "Error norm: 2703.007813\n",
            "Active features: 208\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #33 *****\n",
            "Loss: 19912.625210\n",
            "Feature norm: 15.079276\n",
            "Error norm: 2005.796412\n",
            "Active features: 210\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #34 *****\n",
            "Loss: 19868.898327\n",
            "Feature norm: 15.011747\n",
            "Error norm: 2296.342799\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #35 *****\n",
            "Loss: 19832.322327\n",
            "Feature norm: 15.010201\n",
            "Error norm: 1779.838607\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #36 *****\n",
            "Loss: 19805.176325\n",
            "Feature norm: 15.112599\n",
            "Error norm: 2618.802201\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.039\n",
            "\n",
            "***** Iteration #37 *****\n",
            "Loss: 19757.329860\n",
            "Feature norm: 15.298672\n",
            "Error norm: 1427.007145\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #38 *****\n",
            "Loss: 19735.450140\n",
            "Feature norm: 15.464636\n",
            "Error norm: 2512.606925\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #39 *****\n",
            "Loss: 19696.066165\n",
            "Feature norm: 15.609169\n",
            "Error norm: 1387.833653\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #40 *****\n",
            "Loss: 19675.601148\n",
            "Feature norm: 15.797082\n",
            "Error norm: 2108.798129\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #41 *****\n",
            "Loss: 19644.818941\n",
            "Feature norm: 15.982251\n",
            "Error norm: 1496.685586\n",
            "Active features: 210\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.038\n",
            "\n",
            "***** Iteration #42 *****\n",
            "Loss: 19624.035823\n",
            "Feature norm: 16.091735\n",
            "Error norm: 1874.836662\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.038\n",
            "\n",
            "***** Iteration #43 *****\n",
            "Loss: 19600.645809\n",
            "Feature norm: 16.224015\n",
            "Error norm: 1433.031402\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.040\n",
            "\n",
            "***** Iteration #44 *****\n",
            "Loss: 19584.013496\n",
            "Feature norm: 16.337546\n",
            "Error norm: 1570.041085\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.042\n",
            "\n",
            "***** Iteration #45 *****\n",
            "Loss: 19565.070528\n",
            "Feature norm: 16.455394\n",
            "Error norm: 1296.252188\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #46 *****\n",
            "Loss: 19548.428099\n",
            "Feature norm: 16.521347\n",
            "Error norm: 1263.919815\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.034\n",
            "\n",
            "***** Iteration #47 *****\n",
            "Loss: 19532.707505\n",
            "Feature norm: 16.628394\n",
            "Error norm: 1549.933175\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #48 *****\n",
            "Loss: 19520.084144\n",
            "Feature norm: 16.743332\n",
            "Error norm: 1800.267594\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #49 *****\n",
            "Loss: 19499.219154\n",
            "Feature norm: 16.897886\n",
            "Error norm: 1674.059200\n",
            "Active features: 213\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.038\n",
            "\n",
            "***** Iteration #50 *****\n",
            "Loss: 19485.521277\n",
            "Feature norm: 16.993046\n",
            "Error norm: 1424.739346\n",
            "Active features: 213\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #51 *****\n",
            "Loss: 19471.334319\n",
            "Feature norm: 17.157064\n",
            "Error norm: 1474.897341\n",
            "Active features: 213\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #52 *****\n",
            "Loss: 19457.325166\n",
            "Feature norm: 17.231505\n",
            "Error norm: 810.965853\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.042\n",
            "\n",
            "***** Iteration #53 *****\n",
            "Loss: 19448.642092\n",
            "Feature norm: 17.346963\n",
            "Error norm: 1284.149169\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.038\n",
            "\n",
            "***** Iteration #54 *****\n",
            "Loss: 19438.733989\n",
            "Feature norm: 17.423155\n",
            "Error norm: 1020.806056\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #55 *****\n",
            "Loss: 19431.713675\n",
            "Feature norm: 17.562274\n",
            "Error norm: 1517.925805\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #56 *****\n",
            "Loss: 19416.719328\n",
            "Feature norm: 17.599021\n",
            "Error norm: 1077.961720\n",
            "Active features: 210\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.046\n",
            "\n",
            "***** Iteration #57 *****\n",
            "Loss: 19412.094557\n",
            "Feature norm: 17.673368\n",
            "Error norm: 1677.969631\n",
            "Active features: 210\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #58 *****\n",
            "Loss: 19398.834923\n",
            "Feature norm: 17.727651\n",
            "Error norm: 1358.962329\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.038\n",
            "\n",
            "***** Iteration #59 *****\n",
            "Loss: 19392.084460\n",
            "Feature norm: 17.811651\n",
            "Error norm: 1583.239024\n",
            "Active features: 213\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #60 *****\n",
            "Loss: 19377.310932\n",
            "Feature norm: 17.862955\n",
            "Error norm: 871.423913\n",
            "Active features: 213\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.041\n",
            "\n",
            "***** Iteration #61 *****\n",
            "Loss: 19375.207569\n",
            "Feature norm: 17.905981\n",
            "Error norm: 1236.933067\n",
            "Active features: 213\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #62 *****\n",
            "Loss: 19364.733111\n",
            "Feature norm: 17.925142\n",
            "Error norm: 614.751170\n",
            "Active features: 213\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.039\n",
            "\n",
            "***** Iteration #63 *****\n",
            "Loss: 19361.792905\n",
            "Feature norm: 17.946330\n",
            "Error norm: 889.169506\n",
            "Active features: 210\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #64 *****\n",
            "Loss: 19355.552517\n",
            "Feature norm: 17.965905\n",
            "Error norm: 853.571739\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #65 *****\n",
            "Loss: 19353.943324\n",
            "Feature norm: 17.985255\n",
            "Error norm: 1045.080655\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.039\n",
            "\n",
            "***** Iteration #66 *****\n",
            "Loss: 19346.995335\n",
            "Feature norm: 18.012974\n",
            "Error norm: 999.773169\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #67 *****\n",
            "Loss: 19342.732164\n",
            "Feature norm: 18.032290\n",
            "Error norm: 831.896600\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #68 *****\n",
            "Loss: 19337.424665\n",
            "Feature norm: 18.060317\n",
            "Error norm: 940.089475\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #69 *****\n",
            "Loss: 19333.588620\n",
            "Feature norm: 18.078837\n",
            "Error norm: 679.222629\n",
            "Active features: 212\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #70 *****\n",
            "Loss: 19328.095984\n",
            "Feature norm: 18.108646\n",
            "Error norm: 844.953218\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.038\n",
            "\n",
            "***** Iteration #71 *****\n",
            "Loss: 19325.002917\n",
            "Feature norm: 18.128268\n",
            "Error norm: 603.656340\n",
            "Active features: 211\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #72 *****\n",
            "Loss: 19318.032762\n",
            "Feature norm: 18.163430\n",
            "Error norm: 778.749475\n",
            "Active features: 209\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #73 *****\n",
            "Loss: 19313.494209\n",
            "Feature norm: 18.198169\n",
            "Error norm: 740.307701\n",
            "Active features: 210\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #74 *****\n",
            "Loss: 19312.573283\n",
            "Feature norm: 18.257461\n",
            "Error norm: 1245.417018\n",
            "Active features: 209\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #75 *****\n",
            "Loss: 19304.177711\n",
            "Feature norm: 18.298840\n",
            "Error norm: 744.495082\n",
            "Active features: 209\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #76 *****\n",
            "Loss: 19300.747701\n",
            "Feature norm: 18.348193\n",
            "Error norm: 747.657738\n",
            "Active features: 209\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #77 *****\n",
            "Loss: 19296.641585\n",
            "Feature norm: 18.384576\n",
            "Error norm: 606.786693\n",
            "Active features: 210\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.042\n",
            "\n",
            "***** Iteration #78 *****\n",
            "Loss: 19293.115025\n",
            "Feature norm: 18.432826\n",
            "Error norm: 539.839844\n",
            "Active features: 205\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #79 *****\n",
            "Loss: 19291.164966\n",
            "Feature norm: 18.480791\n",
            "Error norm: 649.050978\n",
            "Active features: 205\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.039\n",
            "\n",
            "***** Iteration #80 *****\n",
            "Loss: 19288.706471\n",
            "Feature norm: 18.541672\n",
            "Error norm: 594.524584\n",
            "Active features: 205\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #81 *****\n",
            "Loss: 19286.032172\n",
            "Feature norm: 18.605493\n",
            "Error norm: 700.873106\n",
            "Active features: 205\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #82 *****\n",
            "Loss: 19283.509511\n",
            "Feature norm: 18.687825\n",
            "Error norm: 615.207154\n",
            "Active features: 204\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #83 *****\n",
            "Loss: 19280.945079\n",
            "Feature norm: 18.769694\n",
            "Error norm: 689.641187\n",
            "Active features: 204\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #84 *****\n",
            "Loss: 19277.922254\n",
            "Feature norm: 18.797584\n",
            "Error norm: 493.564826\n",
            "Active features: 204\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.039\n",
            "\n",
            "***** Iteration #85 *****\n",
            "Loss: 19276.046386\n",
            "Feature norm: 18.904245\n",
            "Error norm: 631.447978\n",
            "Active features: 205\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #86 *****\n",
            "Loss: 19273.609126\n",
            "Feature norm: 18.988681\n",
            "Error norm: 478.336796\n",
            "Active features: 205\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #87 *****\n",
            "Loss: 19271.887391\n",
            "Feature norm: 19.098656\n",
            "Error norm: 582.213773\n",
            "Active features: 204\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.038\n",
            "\n",
            "***** Iteration #88 *****\n",
            "Loss: 19269.654624\n",
            "Feature norm: 19.141041\n",
            "Error norm: 425.881876\n",
            "Active features: 202\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #89 *****\n",
            "Loss: 19268.500904\n",
            "Feature norm: 19.276385\n",
            "Error norm: 540.943281\n",
            "Active features: 202\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #90 *****\n",
            "Loss: 19266.630059\n",
            "Feature norm: 19.329876\n",
            "Error norm: 422.562445\n",
            "Active features: 202\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.035\n",
            "\n",
            "***** Iteration #91 *****\n",
            "Loss: 19265.245497\n",
            "Feature norm: 19.370669\n",
            "Error norm: 338.518079\n",
            "Active features: 201\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #92 *****\n",
            "Loss: 19264.382559\n",
            "Feature norm: 19.428178\n",
            "Error norm: 364.592260\n",
            "Active features: 200\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #93 *****\n",
            "Loss: 19263.246949\n",
            "Feature norm: 19.431094\n",
            "Error norm: 324.895632\n",
            "Active features: 200\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #94 *****\n",
            "Loss: 19262.415762\n",
            "Feature norm: 19.443708\n",
            "Error norm: 370.297269\n",
            "Active features: 201\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #95 *****\n",
            "Loss: 19261.420568\n",
            "Feature norm: 19.459267\n",
            "Error norm: 360.833164\n",
            "Active features: 201\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.039\n",
            "\n",
            "***** Iteration #96 *****\n",
            "Loss: 19260.412608\n",
            "Feature norm: 19.468946\n",
            "Error norm: 346.921311\n",
            "Active features: 200\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "***** Iteration #97 *****\n",
            "Loss: 19259.548326\n",
            "Feature norm: 19.474537\n",
            "Error norm: 367.403452\n",
            "Active features: 200\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.037\n",
            "\n",
            "***** Iteration #98 *****\n",
            "Loss: 19258.773819\n",
            "Feature norm: 19.478853\n",
            "Error norm: 369.179438\n",
            "Active features: 200\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.043\n",
            "\n",
            "***** Iteration #99 *****\n",
            "Loss: 19257.633608\n",
            "Feature norm: 19.487160\n",
            "Error norm: 298.100999\n",
            "Active features: 200\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.039\n",
            "\n",
            "***** Iteration #100 *****\n",
            "Loss: 19255.972947\n",
            "Feature norm: 19.488539\n",
            "Error norm: 209.148313\n",
            "Active features: 200\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.036\n",
            "\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 3.805\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 200 (224)\n",
            "Number of active attributes: 75 (84)\n",
            "Number of active labels: 3 (3)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.000\n",
            "\n",
            "Precision, Recall, and F1-score:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-Disease       0.63      0.15      0.24       960\n",
            "   I-Disease       0.46      0.14      0.21      1087\n",
            "           O       0.93      0.99      0.96     22450\n",
            "\n",
            "    accuracy                           0.92     24497\n",
            "   macro avg       0.67      0.43      0.47     24497\n",
            "weighted avg       0.90      0.92      0.90     24497\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To inspect the parameter weights assigned by the trained model, you can use the tagger.info().transitions and tagger.info().state_features attributes.\n",
        "# Assuming you have trained a model and stored it in the 'tagger' variable\n",
        "transitions = tagger.info().transitions\n",
        "state_features = tagger.info().state_features\n",
        "\n",
        "# Parameter weights for transitions between tag types\n",
        "print(\"Parameter weights for transitions:\")\n",
        "for transition in transitions:\n",
        "    print(f\"From '{transition[0]}' to '{transition[1]}': {transitions[transition]}\")\n",
        "\n",
        "# Parameter weights for the feature designed in Problem 3\n",
        "print(\"\\nParameter weights for the feature of your choice:\")\n",
        "for feature in state_features:\n",
        "    if 'your_feature' in feature:\n",
        "        print(f\"{feature}: {state_features[feature]}\")\n",
        "\n",
        "# This code will print out the parameter weights for the transitions between the tag types (\"B-Disease\", \"I-Disease\", \"O\"),\n",
        "#  as well as the parameter weights for the feature designed in Problem 3. Note that if the feature was dropped during model training,\n",
        "#   there might be nothing to show for that feature."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJmBEdwM5FI6",
        "outputId": "c1371cba-09f8-468b-8050-719b22c5673d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter weights for transitions:\n",
            "From 'O' to 'O': 3.682413\n",
            "From 'O' to 'B-Disease': 4.620523\n",
            "From 'O' to 'I-Disease': -4.070437\n",
            "From 'B-Disease' to 'O': -3.064544\n",
            "From 'B-Disease' to 'B-Disease': -5.953808\n",
            "From 'B-Disease' to 'I-Disease': 2.849245\n",
            "From 'I-Disease' to 'O': -3.948628\n",
            "From 'I-Disease' to 'B-Disease': -4.930598\n",
            "From 'I-Disease' to 'I-Disease': 1.840045\n",
            "\n",
            "Parameter weights for the feature of your choice:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "# Compute document-level precision and recall\n",
        "def get_document_level_labels(tags):\n",
        "    document_labels = []\n",
        "    in_disease_mention = False\n",
        "    for tag in tags:\n",
        "        if tag == 'O':\n",
        "            if in_disease_mention:\n",
        "                document_labels.append(1)\n",
        "                in_disease_mention = False\n",
        "            else:\n",
        "                document_labels.append(0)\n",
        "        elif tag == 'B-Disease':\n",
        "            if in_disease_mention:\n",
        "                document_labels.append(1)\n",
        "            else:\n",
        "                in_disease_mention = True\n",
        "                document_labels.append(1)\n",
        "        elif tag == 'I-Disease':\n",
        "            if in_disease_mention:\n",
        "                document_labels.append(1)\n",
        "            else:\n",
        "                document_labels.append(0)\n",
        "    return document_labels\n",
        "\n",
        "true_labels = get_document_level_labels(true_tags)\n",
        "predicted_labels = get_document_level_labels(predicted_tags)\n",
        "\n",
        "# Compute document-level precision and recall\n",
        "document_precision = metrics.precision_score(true_labels, predicted_labels)\n",
        "document_recall = metrics.recall_score(true_labels, predicted_labels)\n",
        "\n",
        "print(\"Document-level Precision:\", document_precision)\n",
        "print(\"Document-level Recall:\", document_recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4CEEQ5n5S7N",
        "outputId": "16719be6-1e2f-4cee-d831-b57e86c3bed0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document-level Precision: 0.6311787072243346\n",
            "Document-level Recall: 0.166\n"
          ]
        }
      ]
    }
  ]
}