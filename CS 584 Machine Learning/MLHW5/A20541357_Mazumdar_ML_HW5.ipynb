{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 1.1 - 1.4"
      ],
      "metadata": {
        "id": "DbCpp8834eT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import fractional_matrix_power\n",
        "\n",
        "# Problem 1.1\n",
        "initial_labels = np.matrix([0, 0, 0, -1, -1, 1]).T\n",
        "print(\"Given, V4, V5 have Label 2 and V6 as Label 1\")\n",
        "print(\"Let's denote the initial label vector as P0, Initial Label Vector P0:\")\n",
        "print(initial_labels)\n",
        "\n",
        "# Problem 1.2\n",
        "print('Taking reference from Class Lecture slide- Let S be the similarity matrix S=[Si,j]nxn')\n",
        "print('Let D be a diagonal matrix where Di = summation of j Si,j')\n",
        "print('Lets Compute normalized similarity matrix S’=D^{-1/2}.S.D^{-1/2}')\n",
        "\n",
        "def compute_similarity_matrix(adjacency_matrix):\n",
        "    degree_matrix = np.diag(np.sum(adjacency_matrix, axis=1))\n",
        "    degree_matrix_neg_half = fractional_matrix_power(degree_matrix, -0.5)\n",
        "    similarity_matrix = np.round(\n",
        "        np.matmul(np.matmul(degree_matrix_neg_half, adjacency_matrix), degree_matrix_neg_half),\n",
        "        3\n",
        "    )\n",
        "    return similarity_matrix\n",
        "\n",
        "graph_adjacency_matrix = np.array([[0, 1, 0, 0, 1, 1],\n",
        "                                   [1, 0, 1, 1, 0, 0],\n",
        "                                   [0, 1, 0, 1, 0, 0],\n",
        "                                   [0, 1, 1, 0, 0, 0],\n",
        "                                   [1, 0, 0, 0, 0, 0],\n",
        "                                   [1, 0, 0, 0, 0, 0]])\n",
        "\n",
        "similarity_matrix_norm = compute_similarity_matrix(graph_adjacency_matrix)\n",
        "print('\\nNormalized Similarity Matrix (S_norm):\\n')\n",
        "print(similarity_matrix_norm)\n",
        "print('Given alpha = 0.8')\n",
        "alpha = 0.8\n",
        "\n",
        "# Problem 1.2\n",
        "print('Let Y be the initial assignment of node labels')\n",
        "print('• Yi = 1 when the i-th node is assigned to the positive class  ')\n",
        "print('• Yi = -1 when the i-th node is assigned to the negative class')\n",
        "print('• Yi = 0 when the i-th node is unlabeled')\n",
        "print('• Let F be the predicted node labels')\n",
        "print('• The i-th node is unassigned if Fi =0, 0 is the threshold boundary here ')\n",
        "print('• The i-th node is assigned to the positive class if Fi >0')\n",
        "print('• The i-th node is assigned to the negative class if Fi < 0')\n",
        "\n",
        "print('Applying 1st propagation P(1) = (1-a)Y + aSP(0)')\n",
        "print('P1= (1-a)Y + aSY')\n",
        "iteration_1_labels = (1 - alpha) * initial_labels + alpha * np.matmul(similarity_matrix_norm, initial_labels)\n",
        "print('\\nAfter 1 Iteration (P1):\\n')\n",
        "print(np.round(iteration_1_labels, 3))\n",
        "[l1, l2, l3] = np.concatenate(iteration_1_labels[:3])\n",
        "label_status_1 = np.where(iteration_1_labels > 0, \"Positive\", np.where(iteration_1_labels < 0, \"Negative\", \"Unlabeled\"))\n",
        "print(f'l1 = {l1}, l2 = {l2}, l3 = {l3}, Labels: {label_status_1[:3]}')\n",
        "\n",
        "# Problem 1.3\n",
        "print('\\n')\n",
        "print('P2 = (1-a)Y + aSP1')\n",
        "iteration_2_labels = (1 - alpha) * iteration_1_labels + alpha * np.matmul(similarity_matrix_norm, iteration_1_labels)\n",
        "print('\\nAfter 2 Iterations (P2):\\n')\n",
        "print(np.round(iteration_2_labels, 3))\n",
        "[l1, l2, l3] = np.concatenate(iteration_2_labels[:3])\n",
        "label_status_2 = np.where(iteration_2_labels > 0, \"Positive\", np.where(iteration_2_labels < 0, \"Negative\", \"Unlabeled\"))\n",
        "print(f'l1 = {l1}, l2 = {l2}, l3 = {l3}, Labels: {label_status_2[:3]}')\n",
        "\n",
        "# Problem 1.4\n",
        "print('\\n')\n",
        "print('For Infinite propagation Pinf = (I − aS)^−1.Y')\n",
        "identity_matrix = np.identity(similarity_matrix_norm.shape[0])\n",
        "inverse_term = fractional_matrix_power(identity_matrix - alpha * similarity_matrix_norm, -1.0)\n",
        "infinity_labels = np.round((1 - alpha) * np.matmul(inverse_term, initial_labels), 3)\n",
        "print('\\nAfter Infinite Iterations (P∞):\\n')\n",
        "print(infinity_labels)\n",
        "[l1, l2, l3] = np.concatenate(infinity_labels[:3])\n",
        "label_status_inf = np.where(infinity_labels > 0, \"Positive\", np.where(infinity_labels < 0, \"Negative\", \"Unlabeled\"))\n",
        "print(f'l1 = {l1}, l2 = {l2}, l3 = {l3}, Labels: {label_status_inf[:3]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehid1ENCeB4p",
        "outputId": "785d081e-8bde-4e05-ddbd-43bb05505c60"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given, V4, V5 have Label 2 and V6 as Label 1\n",
            "Let's denote the initial label vector as P0, Initial Label Vector P0:\n",
            "[[ 0]\n",
            " [ 0]\n",
            " [ 0]\n",
            " [-1]\n",
            " [-1]\n",
            " [ 1]]\n",
            "Taking reference from Class Lecture slide- Let S be the similarity matrix S=[Si,j]nxn\n",
            "Let D be a diagonal matrix where Di = summation of j Si,j\n",
            "Lets Compute normalized similarity matrix S’=D^{-1/2}.S.D^{-1/2}\n",
            "\n",
            "Normalized Similarity Matrix (S_norm):\n",
            "\n",
            "[[0.    0.333 0.    0.    0.577 0.577]\n",
            " [0.333 0.    0.408 0.408 0.    0.   ]\n",
            " [0.    0.408 0.    0.5   0.    0.   ]\n",
            " [0.    0.408 0.5   0.    0.    0.   ]\n",
            " [0.577 0.    0.    0.    0.    0.   ]\n",
            " [0.577 0.    0.    0.    0.    0.   ]]\n",
            "Given alpha = 0.8\n",
            "Let Y be the initial assignment of node labels\n",
            "• Yi = 1 when the i-th node is assigned to the positive class  \n",
            "• Yi = -1 when the i-th node is assigned to the negative class\n",
            "• Yi = 0 when the i-th node is unlabeled\n",
            "• Let F be the predicted node labels\n",
            "• The i-th node is unassigned if Fi =0, 0 is the threshold boundary here \n",
            "• The i-th node is assigned to the positive class if Fi >0\n",
            "• The i-th node is assigned to the negative class if Fi < 0\n",
            "Applying 1st propagation P(1) = (1-a)Y + aSP(0)\n",
            "P1= (1-a)Y + aSY\n",
            "\n",
            "After 1 Iteration (P1):\n",
            "\n",
            "[[ 0.   ]\n",
            " [-0.326]\n",
            " [-0.4  ]\n",
            " [-0.2  ]\n",
            " [-0.2  ]\n",
            " [ 0.2  ]]\n",
            "l1 = [[0.]], l2 = [[-0.3264]], l3 = [[-0.4]], Labels: [['Unlabeled']\n",
            " ['Negative']\n",
            " ['Negative']]\n",
            "\n",
            "\n",
            "P2 = (1-a)Y + aSP1\n",
            "\n",
            "After 2 Iterations (P2):\n",
            "\n",
            "[[-0.087]\n",
            " [-0.261]\n",
            " [-0.267]\n",
            " [-0.307]\n",
            " [-0.04 ]\n",
            " [ 0.04 ]]\n",
            "l1 = [[-0.08695296]], l2 = [[-0.26112]], l3 = [[-0.26653696]], Labels: [['Negative']\n",
            " ['Negative']\n",
            " ['Negative']]\n",
            "\n",
            "\n",
            "For Infinite propagation Pinf = (I − aS)^−1.Y\n",
            "\n",
            "After Infinite Iterations (P∞):\n",
            "\n",
            "[[-0.097]\n",
            " [-0.209]\n",
            " [-0.209]\n",
            " [-0.352]\n",
            " [-0.245]\n",
            " [ 0.155]]\n",
            "l1 = -0.097, l2 = -0.209, l3 = -0.209, Labels: [['Negative']\n",
            " ['Negative']\n",
            " ['Negative']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 1.5"
      ],
      "metadata": {
        "id": "2fsggHuHF7nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1.5\n",
        "print('\\n')\n",
        "print('Energy minimization-')\n",
        "# Given data\n",
        "initial_labels = np.array([0, 0, 0, -1, -1, 1])\n",
        "observed_labels = np.array([-1, -1, 0, -1, 1, 1])\n",
        "\n",
        "# Energy minimization iterations\n",
        "for iteration in range(1, 5):\n",
        "    print(f\"\\nIteration {iteration}:\")\n",
        "\n",
        "    # Calculate Fi for each node\n",
        "    Fi = np.zeros_like(initial_labels, dtype=float)\n",
        "    for i in range(len(initial_labels)):\n",
        "        Fi[i] = np.sum(similarity_matrix[i, j] * observed_labels[j] for j in range(len(observed_labels)))\n",
        "\n",
        "    # Update observed labels based on Fi\n",
        "    observed_labels = Fi\n",
        "\n",
        "    # Print results\n",
        "    [l1, l2, l3] = np.round(Fi[:3], 3)\n",
        "    label_status_final = np.where(Fi > 0, \"Positive\", np.where(Fi < 0, \"Negative\", \"Unlabeled\"))\n",
        "    print(f'l1 = {l1}, l2 = {l2}, l3 = {l3}, Labels: {label_status_final[:3]}')\n",
        "\n",
        "# Final Result\n",
        "print(\"\\nFinal Result:\")\n",
        "labels_final = np.where(Fi > 0, \"Positive\", np.where(Fi < 0, \"Negative\", \"Unlabeled\"))\n",
        "print(f\"Energy values for unlabeled nodes: {Fi[:3]}\")\n",
        "print(\"Labels for unlabeled nodes:\")\n",
        "print(labels_final[:3])\n",
        "\n",
        "\n",
        "print('\\n')\n",
        "print('Alternatively we can also compute this by laplacian approach')\n",
        "degree_matrix = np.diag(np.sum(graph_adjacency_matrix, axis=1))\n",
        "laplacian_matrix = degree_matrix - graph_adjacency_matrix\n",
        "laplacian_uu = laplacian_matrix[:3, :3]\n",
        "laplacian_ul = laplacian_matrix[:3, 3:]\n",
        "observed_labels = initial_labels[3:]\n",
        "energy_minimization_labels = np.round(np.matmul(np.matmul(-fractional_matrix_power(laplacian_uu, -1.0), laplacian_ul), observed_labels), 3)\n",
        "[l1, l2, l3] = np.round(energy_minimization_labels, 3).tolist()[:3]\n",
        "print('\\nUsing Energy Minimization Algorithm:\\n')\n",
        "print(f'Labels after energy minimization\\nl1 = {l1}, l2 = {l2}, l3 = {l3}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA8pcFV-Fv2t",
        "outputId": "1e39af95-3153-4aec-c902-db8f7d25f7c1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Energy minimization-\n",
            "\n",
            "Iteration 1:\n",
            "l1 = -0.833, l2 = -1.833, l3 = -1.0, Labels: ['Negative' 'Negative' 'Negative']\n",
            "\n",
            "Iteration 2:\n",
            "l1 = -1.139, l2 = -3.194, l3 = -2.583, Labels: ['Negative' 'Negative' 'Negative']\n",
            "\n",
            "Iteration 3:\n",
            "l1 = -2.227, l2 = -5.87, l3 = -5.403, Labels: ['Negative' 'Negative' 'Negative']\n",
            "\n",
            "Iteration 4:\n",
            "l1 = -5.059, l2 = -11.285, l3 = -10.738, Labels: ['Negative' 'Negative' 'Negative']\n",
            "\n",
            "Final Result:\n",
            "Energy values for unlabeled nodes: [ -5.05856251 -11.28508474 -10.73811621]\n",
            "Labels for unlabeled nodes:\n",
            "['Negative' 'Negative' 'Negative']\n",
            "\n",
            "\n",
            "Alternatively we can also compute this by laplacian approach\n",
            "\n",
            "Using Energy Minimization Algorithm:\n",
            "\n",
            "Labels after energy minimization\n",
            "l1 = -0.231, l2 = -0.692, l3 = -0.846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-65af6ad47b10>:15: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  Fi[i] = np.sum(similarity_matrix[i, j] * observed_labels[j] for j in range(len(observed_labels)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 2\n",
        "In this problem, you will implement Label Spreading to classify data points from two circles (See left figure\n",
        "in Figure 1). As both label groups lie inside their own distinct shape, we can see that Label Spreading can\n",
        "propagate labels correctly around the circle (See right figure in Figure 1).\n"
      ],
      "metadata": {
        "id": "bEg_-FCS0vP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Taking referenece from sklearn label spread algo implemntaion in this page- ')\n",
        "print(' https://scikit-learn.org/stable/auto_examples/semi_supervised/plot_label_propagation_structure.html#sphx-glr-auto-examples-semi-supervised-plot-label-propagation-structure-py ')\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.semi_supervised import LabelSpreading\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generating synthetic data with two concentric circles\n",
        "num_samples = 200\n",
        "features, labels_true = make_circles(n_samples=num_samples, shuffle=False)\n",
        "outer_class, inner_class = 0, 1\n",
        "\n",
        "# Creating labels for the data, marking the first and last samples as outer and inner circles\n",
        "all_labels = np.full(num_samples, -1.0)\n",
        "all_labels[0] = outer_class\n",
        "all_labels[-1] = inner_class\n",
        "\n",
        "# Plotting the raw data with labeled and unlabeled points\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(\n",
        "    features[all_labels == outer_class, 0],\n",
        "    features[all_labels == outer_class, 1],\n",
        "    color=\"navy\",\n",
        "    marker=\"s\",\n",
        "    lw=0,\n",
        "    label=\"outer labeled\",\n",
        "    s=10,\n",
        ")\n",
        "plt.scatter(\n",
        "    features[all_labels == inner_class, 0],\n",
        "    features[all_labels == inner_class, 1],\n",
        "    color=\"c\",\n",
        "    marker=\"s\",\n",
        "    lw=0,\n",
        "    label=\"inner labeled\",\n",
        "    s=10,\n",
        ")\n",
        "plt.scatter(\n",
        "    features[all_labels == -1, 0],\n",
        "    features[all_labels == -1, 1],\n",
        "    color=\"darkorange\",\n",
        "    marker=\".\",\n",
        "    label=\"unlabeled\",\n",
        ")\n",
        "plt.legend(scatterpoints=1, shadow=False, loc=\"center\")\n",
        "plt.title(\"Raw data (2 classes=outer and inner)\")\n",
        "plt.gca().set_aspect('equal', adjustable='box')  # Setting aspect ratio to be equal\n",
        "\n",
        "# Applying Label Spreading algorithm\n",
        "label_spread_model = LabelSpreading(kernel=\"knn\", alpha=0.8)\n",
        "label_spread_model.fit(features, all_labels)\n",
        "\n",
        "# Plotting the labels learned with Label Spreading\n",
        "output_labels = label_spread_model.transduction_\n",
        "output_label_array = np.asarray(output_labels)\n",
        "outer_numbers = np.where(output_label_array == outer_class)[0]\n",
        "inner_numbers = np.where(output_label_array == inner_class)[0]\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(\n",
        "    features[outer_numbers, 0],\n",
        "    features[outer_numbers, 1],\n",
        "    color=\"navy\",\n",
        "    marker=\"s\",\n",
        "    lw=0,\n",
        "    s=10,\n",
        "    label=\"outer learned\",\n",
        ")\n",
        "plt.scatter(\n",
        "    features[inner_numbers, 0],\n",
        "    features[inner_numbers, 1],\n",
        "    color=\"c\",\n",
        "    marker=\"s\",\n",
        "    lw=0,\n",
        "    s=10,\n",
        "    label=\"inner learned\",\n",
        ")\n",
        "plt.legend(scatterpoints=1, shadow=False, loc=\"center\")\n",
        "plt.title(\"Labels learned with Label Spreading (KNN)\")\n",
        "plt.gca().set_aspect('equal', adjustable='box')  # Setting aspect ratio to be equal\n",
        "\n",
        "plt.tight_layout()  # Adjusting layout to prevent overlapping\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "JtZ6w3Iy0xg3",
        "outputId": "f9339add-fc88-497d-943d-43c21b8da4db"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taking referenece from sklearn label spread algo implemntaion in this page- \n",
            " https://scikit-learn.org/stable/auto_examples/semi_supervised/plot_label_propagation_structure.html#sphx-glr-auto-examples-semi-supervised-plot-label-propagation-structure-py \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Alternatively, here is my attempt to implement the label spread algo')\n",
        "# print('alpha=0.2, kernel='knn', n_neighbors=2, tol=1e-1, max_iter=500')\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "class CustomLabelSpreading:\n",
        "    def __init__(self, alpha=0.2, kernel='knn', n_neighbors=2, tol=1e-1, max_iter=500):\n",
        "        self.alpha = alpha\n",
        "        self.kernel = kernel\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "        self.label_distributions_prev_ = None\n",
        "\n",
        "    def fit(self, X, labels):\n",
        "        self.X = np.asarray(X)\n",
        "        self.labels = np.asarray(labels)\n",
        "        self.n_samples, self.n_features = self.X.shape\n",
        "        self.classes = np.unique(labels)\n",
        "        self.n_classes = len(self.classes)\n",
        "\n",
        "        # Create the graph Laplacian\n",
        "        self.compute_laplacian()\n",
        "\n",
        "        # Initialize the label distribution\n",
        "        self.label_distributions_ = np.zeros((self.n_samples, self.n_classes))\n",
        "        for label in self.classes:\n",
        "            self.label_distributions_[self.labels == label, self.classes == label] = 1.0\n",
        "\n",
        "        # Iterate until convergence or maximum iterations reached\n",
        "        for i in range(self.max_iter):\n",
        "            self.label_distributions_prev_ = np.copy(self.label_distributions_)\n",
        "\n",
        "            self.label_distributions_ = (1 - self.alpha) * self.label_distributions_ + \\\n",
        "                self.alpha * np.dot(self.graph_laplacian, self.label_distributions_)\n",
        "\n",
        "            # Check for convergence\n",
        "            if np.sum(np.abs(self.label_distributions_ - self.label_distributions_prev_)) < self.tol:\n",
        "                break\n",
        "\n",
        "        # Assign the most probable label to each sample\n",
        "        self.transduction_ = self.classes[np.argmax(self.label_distributions_, axis=1)]\n",
        "\n",
        "    def compute_laplacian(self):\n",
        "        if self.kernel == 'knn':\n",
        "            self.graph_laplacian = self.compute_knn_laplacian()\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported kernel: {}\".format(self.kernel))\n",
        "\n",
        "    def compute_knn_laplacian(self):\n",
        "        distances = cdist(self.X, self.X)\n",
        "        indices = np.argsort(distances, axis=1)[:, 1:self.n_neighbors+1]\n",
        "        weights = np.exp(-distances[np.arange(self.n_samples)[:, None], indices]**2)\n",
        "        laplacian = np.zeros((self.n_samples, self.n_samples))\n",
        "\n",
        "        for i in range(self.n_samples):\n",
        "            laplacian[i, indices[i]] = -weights[i]\n",
        "            laplacian[i, i] = np.sum(weights[i])\n",
        "\n",
        "        return laplacian\n",
        "\n",
        "# Create raw data\n",
        "n_samples = 200\n",
        "X, y = make_circles(n_samples=n_samples, shuffle=False)\n",
        "outer, inner = 0, 1\n",
        "labels = np.full(n_samples, -1.0)\n",
        "labels[0] = outer\n",
        "labels[-1] = inner\n",
        "\n",
        "# Plot raw data\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.scatter(X[labels == outer, 0], X[labels == outer, 1], color=\"navy\", marker=\"s\", lw=0, label=\"outer labeled\", s=10)\n",
        "plt.scatter(X[labels == inner, 0], X[labels == inner, 1], color=\"c\", marker=\"s\", lw=0, label=\"inner labeled\", s=10)\n",
        "plt.scatter(X[labels == -1, 0], X[labels == -1, 1], color=\"darkorange\", marker=\".\", label=\"unlabeled\")\n",
        "plt.legend(scatterpoints=1, shadow=False, loc=\"center\")\n",
        "plt.title(\"Raw data (2 classes=outer and inner)\")\n",
        "\n",
        "# Use custom Label Spreading\n",
        "label_spreading = CustomLabelSpreading(alpha=0.8, kernel='knn')\n",
        "label_spreading.fit(X, labels)\n",
        "\n",
        "# Plot results\n",
        "output_labels = label_spreading.transduction_\n",
        "outer_numbers = np.where(output_labels == outer)[0]\n",
        "inner_numbers = np.where(output_labels == inner)[0]\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.scatter(X[outer_numbers, 0], X[outer_numbers, 1], color=\"navy\", marker=\"s\", lw=0, s=12, label=\"outer learned\")\n",
        "plt.scatter(X[inner_numbers, 0], X[inner_numbers, 1], color=\"c\", marker=\"s\", lw=0, s=12, label=\"inner learned\")\n",
        "plt.legend(scatterpoints=1, shadow=False, loc=\"center\")\n",
        "plt.title(\"Labels learned with Custom Label Spreading (KNN)\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "KZxLPvbJ2Ej5",
        "outputId": "6a293fb6-fb78-469b-fd56-26e5da0ad820"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alternatively, here is my attempt to implement the label spread algo\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem3"
      ],
      "metadata": {
        "id": "zJu46roWKe8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Load digit dataset\n",
        "digit_data = datasets.load_digits()\n",
        "random_generator = np.random.RandomState(0)\n",
        "data_indices = np.arange(len(digit_data.data))\n",
        "random_generator.shuffle(data_indices)\n",
        "\n",
        "features = digit_data.data[data_indices[:330]]\n",
        "labels = digit_data.target[data_indices[:330]]\n",
        "images = digit_data.images[data_indices[:330]]\n",
        "total_samples = len(labels)\n",
        "labeled_points = 10\n",
        "\n",
        "# Initialize LabelPropagation model\n",
        "label_propagation_model = LabelPropagation(kernel='knn', n_neighbors=2, max_iter=1000)\n",
        "\n",
        "for iteration in range(5):\n",
        "    # Fit model with labeled data\n",
        "    label_propagation_model.fit(features[:labeled_points], labels[:labeled_points])\n",
        "\n",
        "    # Make predictions on all data (including unlabeled)\n",
        "    predicted_labels = label_propagation_model.predict(features)\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(labels, predicted_labels)\n",
        "    confusion_matrix_result = confusion_matrix(labels, predicted_labels)\n",
        "\n",
        "    print(f\"Iteration {iteration + 1} - Labeled Points: {labeled_points}\")\n",
        "    print(f\"Accuracy: {accuracy:.3f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix_result)\n",
        "\n",
        "    # Select the top 5 most confident points to label\n",
        "    confidence_scores = label_propagation_model.predict_proba(features)\n",
        "    top_confident_indices = np.argsort(np.max(confidence_scores, axis=1))[-5:]\n",
        "\n",
        "    # Add the confident points to the labeled set\n",
        "    labeled_features = features[:labeled_points]\n",
        "    labeled_labels = labels[:labeled_points]\n",
        "    labeled_features = np.concatenate((labeled_features, features[top_confident_indices]))\n",
        "    labeled_labels = np.concatenate((labeled_labels, predicted_labels[top_confident_indices]))\n",
        "\n",
        "    # Increase the number of labeled points for the next iteration\n",
        "    labeled_points += 5\n",
        "\n",
        "    print(\"\\n\")\n",
        "print('Observation- Accuracy keeps on increasing in each iteration and will further continue to enhance if we keep iterating for a few more iterations')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o65cKMgMDo4J",
        "outputId": "8d9e6fd4-a51e-4ea1-c85e-a8e645605b40"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 - Labeled Points: 10\n",
            "Accuracy: 0.403\n",
            "Confusion Matrix:\n",
            "[[ 0  0  0  0  0  2 22  0  0  0]\n",
            " [ 0 27  2  0  0  1  0  0  0  0]\n",
            " [ 0  2 31  0  0  0  0  0  0  0]\n",
            " [ 0  0 14  0  0  0  0  1 13  0]\n",
            " [ 0  8  0  0  0  1 18  0  0  0]\n",
            " [ 0  0  0  0  0 19  7  0 10  0]\n",
            " [ 0 10  0  0  0  0 32  0  0  0]\n",
            " [ 0  6  4  0  0 21  0  6  0  0]\n",
            " [ 0  9  2  0  0  1  3  2 18  0]\n",
            " [ 0  1  6  0  0  2  1  3 25  0]]\n",
            "\n",
            "\n",
            "Iteration 2 - Labeled Points: 15\n",
            "Accuracy: 0.464\n",
            "Confusion Matrix:\n",
            "[[ 0  0  0  0  0  0 23  0  1  0]\n",
            " [ 0 24  2  0  0  0  4  0  0  0]\n",
            " [ 0  2 31  0  0  0  0  0  0  0]\n",
            " [ 0  0 14  0  0  0  0  1 13  0]\n",
            " [ 0  6  0  0  0  0 18  3  0  0]\n",
            " [ 0  0  0  0  0 19  7  0 10  0]\n",
            " [ 0  1  0  0  0  0 41  0  0  0]\n",
            " [ 0  5  1  0  0 12  1 18  0  0]\n",
            " [ 0  4  2  0  0  0  6  3 20  0]\n",
            " [ 0  1  5  0  0  2  6  1 23  0]]\n",
            "\n",
            "\n",
            "Iteration 3 - Labeled Points: 20\n",
            "Accuracy: 0.576\n",
            "Confusion Matrix:\n",
            "[[24  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 26  0  0  0  0  4  0  0  0]\n",
            " [ 3  2 28  0  0  0  0  0  0  0]\n",
            " [ 1  0 12  0  0  0  0  1 14  0]\n",
            " [10  8  0  0  0  1  6  2  0  0]\n",
            " [ 2  0  0  0  0 31  0  0  3  0]\n",
            " [ 0  1  0  0  0  0 41  0  0  0]\n",
            " [ 4  5  0  0  0 11  0 17  0  0]\n",
            " [ 1  4  1  0  0  0  3  3 23  0]\n",
            " [13  3  1  0  0  3  2  0 16  0]]\n",
            "\n",
            "\n",
            "Iteration 4 - Labeled Points: 25\n",
            "Accuracy: 0.667\n",
            "Confusion Matrix:\n",
            "[[24  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 26  0  0  0  0  4  0  0  0]\n",
            " [ 3  2 27  0  0  0  0  1  0  0]\n",
            " [ 1  0  7  0  0  0  0  1 19  0]\n",
            " [ 2  8  0  0 13  0  3  1  0  0]\n",
            " [ 2  0  0  0  0 31  0  0  3  0]\n",
            " [ 0  1  0  0  0  0 41  0  0  0]\n",
            " [ 2  3  0  0  0  0  0 32  0  0]\n",
            " [ 1  3  1  0  0  0  1  3 26  0]\n",
            " [ 4  1  0  0  0  2  2  3 26  0]]\n",
            "\n",
            "\n",
            "Iteration 5 - Labeled Points: 30\n",
            "Accuracy: 0.745\n",
            "Confusion Matrix:\n",
            "[[23  0  0  0  0  0  0  0  0  1]\n",
            " [ 0 26  0  0  0  0  4  0  0  0]\n",
            " [ 3  1 28  0  0  0  0  1  0  0]\n",
            " [ 1  0  6  0  0  1  0  1  9 10]\n",
            " [ 0  4  0  0 22  0  0  1  0  0]\n",
            " [ 1  0  0  0  0 31  0  0  1  3]\n",
            " [ 0  1  0  0  0  1 40  0  0  0]\n",
            " [ 1  3  0  0  2  0  0 31  0  0]\n",
            " [ 1  3  1  0  2  1  1  1 25  0]\n",
            " [ 3  1  0  0  0  3  0  3  8 20]]\n",
            "\n",
            "\n",
            "Observation- Accuracy keeps on increasing in each iteration and will further continue to enhance if we keep iterating for a few more iterations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 4"
      ],
      "metadata": {
        "id": "rlUJSVPwMIIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "0L7HUjekaFDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/layers.py"
      ],
      "metadata": {
        "id": "o9VQmMGrZwQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/__init__.py"
      ],
      "metadata": {
        "id": "ECvFbLuyfXRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models.py"
      ],
      "metadata": {
        "id": "tBKrEgqPZ0Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/utils.py"
      ],
      "metadata": {
        "id": "eKe6sO6afyx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "\n",
        "\n",
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
        "                    enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
        "                             dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "\n",
        "def load_data(path=\"/content/cora/\", dataset=\"cora\"):\n",
        "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
        "    print('Loading {} dataset...'.format(dataset))\n",
        "\n",
        "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
        "                                        dtype=np.dtype(str))\n",
        "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
        "    labels = encode_onehot(idx_features_labels[:, -1])\n",
        "\n",
        "    # build graph\n",
        "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
        "    idx_map = {j: i for i, j in enumerate(idx)}\n",
        "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
        "                                    dtype=np.int32)\n",
        "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
        "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
        "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
        "                        shape=(labels.shape[0], labels.shape[0]),\n",
        "                        dtype=np.float32)\n",
        "\n",
        "    # build symmetric adjacency matrix\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    features = normalize(features)\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "    idx_train = range(140)\n",
        "    idx_val = range(200, 500)\n",
        "    idx_test = range(500, 1500)\n",
        "\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    return adj, features, labels, idx_train, idx_val, idx_test\n",
        "\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n"
      ],
      "metadata": {
        "id": "1we4pgPhGjJt"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "\n",
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'\n"
      ],
      "metadata": {
        "id": "drFD-jEVG4JY"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from layers import GraphConvolution\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "        self.gc2 = GraphConvolution(nhid, nclass)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.relu(self.gc1(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.gc2(x, adj)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "zRSylBHdG9I0"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from _future_ import division\n",
        "# from _future_ import print_function\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "import os  # Added import for os module\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# from pygcn.utils import load_data, accuracy\n",
        "# from pygcn.models import GCN\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from layers import GraphConvolution\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "\n",
        "\n",
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
        "                    enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
        "                             dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "\n",
        "def load_data(path=\"/content/cora/\", dataset=\"cora\"):\n",
        "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
        "    print('Loading {} dataset...'.format(dataset))\n",
        "\n",
        "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
        "                                        dtype=np.dtype(str))\n",
        "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
        "    labels = encode_onehot(idx_features_labels[:, -1])\n",
        "\n",
        "    # build graph\n",
        "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
        "    idx_map = {j: i for i, j in enumerate(idx)}\n",
        "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
        "                                    dtype=np.int32)\n",
        "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
        "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
        "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
        "                        shape=(labels.shape[0], labels.shape[0]),\n",
        "                        dtype=np.float32)\n",
        "\n",
        "    # build symmetric adjacency matrix\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    features = normalize(features)\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "    idx_train = range(140)\n",
        "    idx_val = range(200, 500)\n",
        "    idx_test = range(500, 1500)\n",
        "\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    return adj, features, labels, idx_train, idx_val, idx_test\n",
        "\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "        self.gc2 = GraphConvolution(nhid, nclass)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.relu(self.gc1(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.gc2(x, adj)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Set the training settings\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.no_cuda = False  # Set to True if we want to disable CUDA\n",
        "        self.fastmode = False\n",
        "        self.seed = 42\n",
        "        self.epochs = 200\n",
        "        self.lr = 0.01\n",
        "        self.weight_decay = 5e-4\n",
        "        self.hidden = 16\n",
        "        self.dropout = 0.5\n",
        "\n",
        "args = Args()\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "if args.cuda:\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "# Specify the data directory\n",
        "data_dir = '/content/pygcn-cora/'\n",
        "\n",
        "# Load data\n",
        "adj, features, labels, _, idx_val, idx_test = load_data(data_dir)\n",
        "\n",
        "# Model and optimizer\n",
        "model = GCN(nfeat=features.shape[1],\n",
        "            nhid=args.hidden,\n",
        "            nclass=labels.max().item() + 1,\n",
        "            dropout=args.dropout)\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "if args.cuda:\n",
        "    model.cuda()\n",
        "    features = features.cuda()\n",
        "    adj = adj.cuda()\n",
        "    labels = labels.cuda()\n",
        "    idx_val = idx_val.cuda()\n",
        "    idx_test = idx_test.cuda()\n",
        "\n",
        "# Define a list of labeled node counts\n",
        "# number of labeled nodes to be 60, 120, 180, 240, 300, respectively.\n",
        "number_of_labeled_node = [60, 120, 180, 240, 300]\n",
        "\n",
        "for labeled_nodes_count in number_of_labeled_node:\n",
        "    # Randomly choose labeled nodes\n",
        "    idx_train = np.random.choice(idx_val, labeled_nodes_count, replace=False)\n",
        "\n",
        "    def train(epoch):\n",
        "        t = time.time()\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(features, adj)\n",
        "        loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
        "        acc_train = accuracy(output[idx_train], labels[idx_train])\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if not args.fastmode:\n",
        "            # Evaluate validation set performance separately,\n",
        "            # deactivates dropout during the validation run.\n",
        "            model.eval()\n",
        "            output = model(features, adj)\n",
        "\n",
        "        loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
        "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
        "        print('Epoch: {:04d}'.format(epoch + 1),\n",
        "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
        "              'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "    def test():\n",
        "        model.eval()\n",
        "        output = model(features, adj)\n",
        "        loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
        "        acc_test = accuracy(output[idx_test], labels[idx_test])\n",
        "        print(\"Test set results:\",\n",
        "              \"loss= {:.4f}\".format(loss_test.item()),\n",
        "              \"accuracy= {:.4f}\".format(acc_test.item()))\n",
        "\n",
        "    # Train model\n",
        "    t_total = time.time()\n",
        "    for epoch in range(args.epochs):\n",
        "        train(epoch)\n",
        "    print(f\"After Completion of {labeled_nodes_count} labeled nodes\")\n",
        "    print(\"Time taken: {:.4f}s\".format(time.time() - t_total))\n",
        "\n",
        "    # Testing\n",
        "    test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pl9Cu4JQ2Fc",
        "outputId": "a9c50a62-f5ed-40b9-cd10-425c09efbc05"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cora dataset...\n",
            "Epoch: 0001 loss_train: 1.9300 acc_train: 0.1833 loss_val: 1.9391 acc_val: 0.1567 time: 0.0209s\n",
            "Epoch: 0002 loss_train: 1.9134 acc_train: 0.1667 loss_val: 1.9296 acc_val: 0.1567 time: 0.0181s\n",
            "Epoch: 0003 loss_train: 1.9184 acc_train: 0.1833 loss_val: 1.9210 acc_val: 0.1567 time: 0.0193s\n",
            "Epoch: 0004 loss_train: 1.9068 acc_train: 0.1833 loss_val: 1.9130 acc_val: 0.1567 time: 0.0192s\n",
            "Epoch: 0005 loss_train: 1.8951 acc_train: 0.1833 loss_val: 1.9055 acc_val: 0.1567 time: 0.0201s\n",
            "Epoch: 0006 loss_train: 1.8739 acc_train: 0.1667 loss_val: 1.8980 acc_val: 0.1567 time: 0.0192s\n",
            "Epoch: 0007 loss_train: 1.8617 acc_train: 0.2000 loss_val: 1.8906 acc_val: 0.1567 time: 0.0184s\n",
            "Epoch: 0008 loss_train: 1.8726 acc_train: 0.1833 loss_val: 1.8830 acc_val: 0.1567 time: 0.0195s\n",
            "Epoch: 0009 loss_train: 1.8645 acc_train: 0.2000 loss_val: 1.8752 acc_val: 0.1667 time: 0.0194s\n",
            "Epoch: 0010 loss_train: 1.8540 acc_train: 0.2500 loss_val: 1.8676 acc_val: 0.3200 time: 0.0189s\n",
            "Epoch: 0011 loss_train: 1.8366 acc_train: 0.2833 loss_val: 1.8599 acc_val: 0.4467 time: 0.0221s\n",
            "Epoch: 0012 loss_train: 1.8389 acc_train: 0.3500 loss_val: 1.8520 acc_val: 0.4267 time: 0.0198s\n",
            "Epoch: 0013 loss_train: 1.8316 acc_train: 0.3833 loss_val: 1.8443 acc_val: 0.3867 time: 0.0250s\n",
            "Epoch: 0014 loss_train: 1.8275 acc_train: 0.3833 loss_val: 1.8366 acc_val: 0.3767 time: 0.0210s\n",
            "Epoch: 0015 loss_train: 1.7993 acc_train: 0.3000 loss_val: 1.8289 acc_val: 0.3533 time: 0.0210s\n",
            "Epoch: 0016 loss_train: 1.8053 acc_train: 0.3167 loss_val: 1.8211 acc_val: 0.3500 time: 0.0198s\n",
            "Epoch: 0017 loss_train: 1.7968 acc_train: 0.2667 loss_val: 1.8137 acc_val: 0.3500 time: 0.0199s\n",
            "Epoch: 0018 loss_train: 1.8025 acc_train: 0.3000 loss_val: 1.8066 acc_val: 0.3500 time: 0.0194s\n",
            "Epoch: 0019 loss_train: 1.7916 acc_train: 0.2500 loss_val: 1.7998 acc_val: 0.3500 time: 0.0200s\n",
            "Epoch: 0020 loss_train: 1.7824 acc_train: 0.3000 loss_val: 1.7933 acc_val: 0.3500 time: 0.0220s\n",
            "Epoch: 0021 loss_train: 1.7490 acc_train: 0.2833 loss_val: 1.7871 acc_val: 0.3500 time: 0.0207s\n",
            "Epoch: 0022 loss_train: 1.7295 acc_train: 0.2667 loss_val: 1.7809 acc_val: 0.3500 time: 0.0184s\n",
            "Epoch: 0023 loss_train: 1.7413 acc_train: 0.2667 loss_val: 1.7750 acc_val: 0.3500 time: 0.0212s\n",
            "Epoch: 0024 loss_train: 1.7288 acc_train: 0.2667 loss_val: 1.7691 acc_val: 0.3500 time: 0.0200s\n",
            "Epoch: 0025 loss_train: 1.7463 acc_train: 0.2667 loss_val: 1.7636 acc_val: 0.3500 time: 0.0195s\n",
            "Epoch: 0026 loss_train: 1.7158 acc_train: 0.2833 loss_val: 1.7580 acc_val: 0.3500 time: 0.0190s\n",
            "Epoch: 0027 loss_train: 1.6999 acc_train: 0.2833 loss_val: 1.7524 acc_val: 0.3500 time: 0.0192s\n",
            "Epoch: 0028 loss_train: 1.6994 acc_train: 0.2667 loss_val: 1.7470 acc_val: 0.3500 time: 0.0220s\n",
            "Epoch: 0029 loss_train: 1.6653 acc_train: 0.2667 loss_val: 1.7418 acc_val: 0.3500 time: 0.0270s\n",
            "Epoch: 0030 loss_train: 1.6986 acc_train: 0.2667 loss_val: 1.7367 acc_val: 0.3500 time: 0.0188s\n",
            "Epoch: 0031 loss_train: 1.6740 acc_train: 0.2833 loss_val: 1.7316 acc_val: 0.3500 time: 0.0185s\n",
            "Epoch: 0032 loss_train: 1.6659 acc_train: 0.2667 loss_val: 1.7263 acc_val: 0.3500 time: 0.0180s\n",
            "Epoch: 0033 loss_train: 1.6319 acc_train: 0.2833 loss_val: 1.7207 acc_val: 0.3500 time: 0.0184s\n",
            "Epoch: 0034 loss_train: 1.6326 acc_train: 0.2833 loss_val: 1.7148 acc_val: 0.3567 time: 0.0187s\n",
            "Epoch: 0035 loss_train: 1.6349 acc_train: 0.3000 loss_val: 1.7087 acc_val: 0.3567 time: 0.0226s\n",
            "Epoch: 0036 loss_train: 1.6227 acc_train: 0.3000 loss_val: 1.7028 acc_val: 0.3600 time: 0.0188s\n",
            "Epoch: 0037 loss_train: 1.6219 acc_train: 0.3000 loss_val: 1.6968 acc_val: 0.3733 time: 0.0190s\n",
            "Epoch: 0038 loss_train: 1.5988 acc_train: 0.3333 loss_val: 1.6908 acc_val: 0.3767 time: 0.0240s\n",
            "Epoch: 0039 loss_train: 1.5998 acc_train: 0.3500 loss_val: 1.6852 acc_val: 0.3800 time: 0.0224s\n",
            "Epoch: 0040 loss_train: 1.5821 acc_train: 0.3667 loss_val: 1.6795 acc_val: 0.3833 time: 0.0187s\n",
            "Epoch: 0041 loss_train: 1.5619 acc_train: 0.3333 loss_val: 1.6737 acc_val: 0.3967 time: 0.0189s\n",
            "Epoch: 0042 loss_train: 1.5649 acc_train: 0.3500 loss_val: 1.6678 acc_val: 0.4033 time: 0.0179s\n",
            "Epoch: 0043 loss_train: 1.5180 acc_train: 0.3667 loss_val: 1.6613 acc_val: 0.4067 time: 0.0190s\n",
            "Epoch: 0044 loss_train: 1.5062 acc_train: 0.4000 loss_val: 1.6541 acc_val: 0.4233 time: 0.0192s\n",
            "Epoch: 0045 loss_train: 1.4778 acc_train: 0.4833 loss_val: 1.6463 acc_val: 0.4233 time: 0.0201s\n",
            "Epoch: 0046 loss_train: 1.4919 acc_train: 0.3833 loss_val: 1.6379 acc_val: 0.4267 time: 0.0183s\n",
            "Epoch: 0047 loss_train: 1.4666 acc_train: 0.4500 loss_val: 1.6295 acc_val: 0.4300 time: 0.0183s\n",
            "Epoch: 0048 loss_train: 1.4727 acc_train: 0.4667 loss_val: 1.6206 acc_val: 0.4433 time: 0.0254s\n",
            "Epoch: 0049 loss_train: 1.4458 acc_train: 0.5000 loss_val: 1.6113 acc_val: 0.4633 time: 0.0184s\n",
            "Epoch: 0050 loss_train: 1.4661 acc_train: 0.5167 loss_val: 1.6019 acc_val: 0.4767 time: 0.0202s\n",
            "Epoch: 0051 loss_train: 1.4014 acc_train: 0.5500 loss_val: 1.5923 acc_val: 0.4967 time: 0.0183s\n",
            "Epoch: 0052 loss_train: 1.4265 acc_train: 0.5167 loss_val: 1.5822 acc_val: 0.5100 time: 0.0184s\n",
            "Epoch: 0053 loss_train: 1.3712 acc_train: 0.6000 loss_val: 1.5713 acc_val: 0.5267 time: 0.0184s\n",
            "Epoch: 0054 loss_train: 1.3288 acc_train: 0.7000 loss_val: 1.5606 acc_val: 0.5500 time: 0.0196s\n",
            "Epoch: 0055 loss_train: 1.3380 acc_train: 0.6833 loss_val: 1.5493 acc_val: 0.5733 time: 0.0186s\n",
            "Epoch: 0056 loss_train: 1.2673 acc_train: 0.7333 loss_val: 1.5377 acc_val: 0.5733 time: 0.0196s\n",
            "Epoch: 0057 loss_train: 1.2981 acc_train: 0.6667 loss_val: 1.5253 acc_val: 0.5767 time: 0.0199s\n",
            "Epoch: 0058 loss_train: 1.2646 acc_train: 0.7000 loss_val: 1.5129 acc_val: 0.5800 time: 0.0225s\n",
            "Epoch: 0059 loss_train: 1.2802 acc_train: 0.7333 loss_val: 1.5006 acc_val: 0.5833 time: 0.0184s\n",
            "Epoch: 0060 loss_train: 1.3112 acc_train: 0.7000 loss_val: 1.4883 acc_val: 0.5833 time: 0.0187s\n",
            "Epoch: 0061 loss_train: 1.2405 acc_train: 0.6833 loss_val: 1.4769 acc_val: 0.5900 time: 0.0191s\n",
            "Epoch: 0062 loss_train: 1.2130 acc_train: 0.7167 loss_val: 1.4658 acc_val: 0.5900 time: 0.0194s\n",
            "Epoch: 0063 loss_train: 1.1994 acc_train: 0.6833 loss_val: 1.4551 acc_val: 0.5933 time: 0.0205s\n",
            "Epoch: 0064 loss_train: 1.2008 acc_train: 0.7000 loss_val: 1.4447 acc_val: 0.5967 time: 0.0201s\n",
            "Epoch: 0065 loss_train: 1.1573 acc_train: 0.7500 loss_val: 1.4345 acc_val: 0.5967 time: 0.0190s\n",
            "Epoch: 0066 loss_train: 1.0970 acc_train: 0.7167 loss_val: 1.4243 acc_val: 0.6067 time: 0.0186s\n",
            "Epoch: 0067 loss_train: 1.1515 acc_train: 0.7167 loss_val: 1.4143 acc_val: 0.6000 time: 0.0184s\n",
            "Epoch: 0068 loss_train: 1.1322 acc_train: 0.6833 loss_val: 1.4050 acc_val: 0.5967 time: 0.0206s\n",
            "Epoch: 0069 loss_train: 1.1202 acc_train: 0.7667 loss_val: 1.3948 acc_val: 0.6000 time: 0.0187s\n",
            "Epoch: 0070 loss_train: 1.0732 acc_train: 0.7500 loss_val: 1.3841 acc_val: 0.6000 time: 0.0198s\n",
            "Epoch: 0071 loss_train: 1.1132 acc_train: 0.7833 loss_val: 1.3733 acc_val: 0.6033 time: 0.0202s\n",
            "Epoch: 0072 loss_train: 1.0508 acc_train: 0.7667 loss_val: 1.3623 acc_val: 0.6033 time: 0.0213s\n",
            "Epoch: 0073 loss_train: 1.0118 acc_train: 0.8000 loss_val: 1.3518 acc_val: 0.6100 time: 0.0210s\n",
            "Epoch: 0074 loss_train: 1.0621 acc_train: 0.7833 loss_val: 1.3415 acc_val: 0.6133 time: 0.0197s\n",
            "Epoch: 0075 loss_train: 0.9774 acc_train: 0.8000 loss_val: 1.3318 acc_val: 0.6167 time: 0.0199s\n",
            "Epoch: 0076 loss_train: 1.0051 acc_train: 0.7667 loss_val: 1.3227 acc_val: 0.6333 time: 0.0199s\n",
            "Epoch: 0077 loss_train: 1.0470 acc_train: 0.7500 loss_val: 1.3133 acc_val: 0.6400 time: 0.0230s\n",
            "Epoch: 0078 loss_train: 0.9941 acc_train: 0.7667 loss_val: 1.3040 acc_val: 0.6467 time: 0.0199s\n",
            "Epoch: 0079 loss_train: 0.9873 acc_train: 0.8167 loss_val: 1.2942 acc_val: 0.6433 time: 0.0194s\n",
            "Epoch: 0080 loss_train: 0.9377 acc_train: 0.7667 loss_val: 1.2841 acc_val: 0.6433 time: 0.0211s\n",
            "Epoch: 0081 loss_train: 0.9291 acc_train: 0.8333 loss_val: 1.2746 acc_val: 0.6467 time: 0.0191s\n",
            "Epoch: 0082 loss_train: 0.9442 acc_train: 0.7833 loss_val: 1.2664 acc_val: 0.6533 time: 0.0214s\n",
            "Epoch: 0083 loss_train: 0.9564 acc_train: 0.7667 loss_val: 1.2582 acc_val: 0.6567 time: 0.0254s\n",
            "Epoch: 0084 loss_train: 0.9029 acc_train: 0.8167 loss_val: 1.2498 acc_val: 0.6567 time: 0.0216s\n",
            "Epoch: 0085 loss_train: 0.8852 acc_train: 0.7833 loss_val: 1.2421 acc_val: 0.6567 time: 0.0188s\n",
            "Epoch: 0086 loss_train: 0.9263 acc_train: 0.8000 loss_val: 1.2347 acc_val: 0.6633 time: 0.0258s\n",
            "Epoch: 0087 loss_train: 0.8740 acc_train: 0.7667 loss_val: 1.2273 acc_val: 0.6733 time: 0.0193s\n",
            "Epoch: 0088 loss_train: 0.8963 acc_train: 0.8167 loss_val: 1.2197 acc_val: 0.6800 time: 0.0200s\n",
            "Epoch: 0089 loss_train: 0.8575 acc_train: 0.8167 loss_val: 1.2121 acc_val: 0.6833 time: 0.0193s\n",
            "Epoch: 0090 loss_train: 0.8257 acc_train: 0.8167 loss_val: 1.2048 acc_val: 0.6833 time: 0.0203s\n",
            "Epoch: 0091 loss_train: 0.8618 acc_train: 0.7667 loss_val: 1.1977 acc_val: 0.6867 time: 0.0199s\n",
            "Epoch: 0092 loss_train: 0.8528 acc_train: 0.7833 loss_val: 1.1907 acc_val: 0.6900 time: 0.0196s\n",
            "Epoch: 0093 loss_train: 0.8833 acc_train: 0.8000 loss_val: 1.1826 acc_val: 0.6900 time: 0.0191s\n",
            "Epoch: 0094 loss_train: 0.8528 acc_train: 0.8333 loss_val: 1.1735 acc_val: 0.6867 time: 0.0186s\n",
            "Epoch: 0095 loss_train: 0.8280 acc_train: 0.8500 loss_val: 1.1648 acc_val: 0.6867 time: 0.0187s\n",
            "Epoch: 0096 loss_train: 0.8246 acc_train: 0.8167 loss_val: 1.1566 acc_val: 0.6833 time: 0.0233s\n",
            "Epoch: 0097 loss_train: 0.7734 acc_train: 0.9000 loss_val: 1.1491 acc_val: 0.6833 time: 0.0191s\n",
            "Epoch: 0098 loss_train: 0.8072 acc_train: 0.8667 loss_val: 1.1416 acc_val: 0.6833 time: 0.0194s\n",
            "Epoch: 0099 loss_train: 0.7683 acc_train: 0.8333 loss_val: 1.1338 acc_val: 0.6867 time: 0.0206s\n",
            "Epoch: 0100 loss_train: 0.7410 acc_train: 0.8833 loss_val: 1.1266 acc_val: 0.6867 time: 0.0208s\n",
            "Epoch: 0101 loss_train: 0.7488 acc_train: 0.8500 loss_val: 1.1207 acc_val: 0.6933 time: 0.0198s\n",
            "Epoch: 0102 loss_train: 0.7803 acc_train: 0.8167 loss_val: 1.1158 acc_val: 0.6967 time: 0.0186s\n",
            "Epoch: 0103 loss_train: 0.7689 acc_train: 0.8167 loss_val: 1.1119 acc_val: 0.6967 time: 0.0188s\n",
            "Epoch: 0104 loss_train: 0.7470 acc_train: 0.8167 loss_val: 1.1066 acc_val: 0.6967 time: 0.0192s\n",
            "Epoch: 0105 loss_train: 0.7466 acc_train: 0.8333 loss_val: 1.0983 acc_val: 0.6967 time: 0.0231s\n",
            "Epoch: 0106 loss_train: 0.7034 acc_train: 0.8333 loss_val: 1.0896 acc_val: 0.6967 time: 0.0190s\n",
            "Epoch: 0107 loss_train: 0.6907 acc_train: 0.8667 loss_val: 1.0817 acc_val: 0.6933 time: 0.0195s\n",
            "Epoch: 0108 loss_train: 0.7013 acc_train: 0.8333 loss_val: 1.0752 acc_val: 0.6867 time: 0.0209s\n",
            "Epoch: 0109 loss_train: 0.7464 acc_train: 0.8833 loss_val: 1.0693 acc_val: 0.6900 time: 0.0237s\n",
            "Epoch: 0110 loss_train: 0.7275 acc_train: 0.8833 loss_val: 1.0637 acc_val: 0.6933 time: 0.0184s\n",
            "Epoch: 0111 loss_train: 0.6778 acc_train: 0.8833 loss_val: 1.0584 acc_val: 0.6933 time: 0.0182s\n",
            "Epoch: 0112 loss_train: 0.6718 acc_train: 0.8667 loss_val: 1.0527 acc_val: 0.6933 time: 0.0191s\n",
            "Epoch: 0113 loss_train: 0.7162 acc_train: 0.8500 loss_val: 1.0466 acc_val: 0.6933 time: 0.0190s\n",
            "Epoch: 0114 loss_train: 0.7030 acc_train: 0.8500 loss_val: 1.0402 acc_val: 0.6900 time: 0.0211s\n",
            "Epoch: 0115 loss_train: 0.6323 acc_train: 0.8833 loss_val: 1.0339 acc_val: 0.6967 time: 0.0242s\n",
            "Epoch: 0116 loss_train: 0.7322 acc_train: 0.8833 loss_val: 1.0277 acc_val: 0.6967 time: 0.0219s\n",
            "Epoch: 0117 loss_train: 0.6737 acc_train: 0.8833 loss_val: 1.0217 acc_val: 0.7000 time: 0.0192s\n",
            "Epoch: 0118 loss_train: 0.6714 acc_train: 0.8833 loss_val: 1.0158 acc_val: 0.7033 time: 0.0195s\n",
            "Epoch: 0119 loss_train: 0.6281 acc_train: 0.8833 loss_val: 1.0099 acc_val: 0.7067 time: 0.0189s\n",
            "Epoch: 0120 loss_train: 0.6451 acc_train: 0.9167 loss_val: 1.0038 acc_val: 0.7067 time: 0.0189s\n",
            "Epoch: 0121 loss_train: 0.7179 acc_train: 0.8333 loss_val: 0.9974 acc_val: 0.7033 time: 0.0197s\n",
            "Epoch: 0122 loss_train: 0.6535 acc_train: 0.8000 loss_val: 0.9923 acc_val: 0.7100 time: 0.0197s\n",
            "Epoch: 0123 loss_train: 0.6189 acc_train: 0.8833 loss_val: 0.9874 acc_val: 0.7167 time: 0.0191s\n",
            "Epoch: 0124 loss_train: 0.6077 acc_train: 0.9000 loss_val: 0.9827 acc_val: 0.7167 time: 0.0201s\n",
            "Epoch: 0125 loss_train: 0.6086 acc_train: 0.8833 loss_val: 0.9768 acc_val: 0.7200 time: 0.0215s\n",
            "Epoch: 0126 loss_train: 0.6449 acc_train: 0.8667 loss_val: 0.9718 acc_val: 0.7200 time: 0.0199s\n",
            "Epoch: 0127 loss_train: 0.6719 acc_train: 0.8333 loss_val: 0.9675 acc_val: 0.7200 time: 0.0206s\n",
            "Epoch: 0128 loss_train: 0.5711 acc_train: 0.8833 loss_val: 0.9639 acc_val: 0.7233 time: 0.0255s\n",
            "Epoch: 0129 loss_train: 0.5695 acc_train: 0.9167 loss_val: 0.9600 acc_val: 0.7233 time: 0.0220s\n",
            "Epoch: 0130 loss_train: 0.6082 acc_train: 0.8667 loss_val: 0.9563 acc_val: 0.7233 time: 0.0206s\n",
            "Epoch: 0131 loss_train: 0.6134 acc_train: 0.8833 loss_val: 0.9513 acc_val: 0.7233 time: 0.0192s\n",
            "Epoch: 0132 loss_train: 0.5583 acc_train: 0.8833 loss_val: 0.9462 acc_val: 0.7267 time: 0.0205s\n",
            "Epoch: 0133 loss_train: 0.5645 acc_train: 0.8500 loss_val: 0.9419 acc_val: 0.7267 time: 0.0227s\n",
            "Epoch: 0134 loss_train: 0.5681 acc_train: 0.9167 loss_val: 0.9376 acc_val: 0.7167 time: 0.0194s\n",
            "Epoch: 0135 loss_train: 0.5913 acc_train: 0.8833 loss_val: 0.9326 acc_val: 0.7133 time: 0.0194s\n",
            "Epoch: 0136 loss_train: 0.6301 acc_train: 0.8833 loss_val: 0.9275 acc_val: 0.7200 time: 0.0209s\n",
            "Epoch: 0137 loss_train: 0.5585 acc_train: 0.9167 loss_val: 0.9240 acc_val: 0.7200 time: 0.0187s\n",
            "Epoch: 0138 loss_train: 0.6179 acc_train: 0.9000 loss_val: 0.9192 acc_val: 0.7200 time: 0.0187s\n",
            "Epoch: 0139 loss_train: 0.5082 acc_train: 0.9000 loss_val: 0.9147 acc_val: 0.7200 time: 0.0198s\n",
            "Epoch: 0140 loss_train: 0.5742 acc_train: 0.9000 loss_val: 0.9099 acc_val: 0.7233 time: 0.0201s\n",
            "Epoch: 0141 loss_train: 0.4637 acc_train: 0.9167 loss_val: 0.9044 acc_val: 0.7267 time: 0.0192s\n",
            "Epoch: 0142 loss_train: 0.5577 acc_train: 0.9000 loss_val: 0.8986 acc_val: 0.7267 time: 0.0214s\n",
            "Epoch: 0143 loss_train: 0.5754 acc_train: 0.8500 loss_val: 0.8931 acc_val: 0.7267 time: 0.0248s\n",
            "Epoch: 0144 loss_train: 0.4941 acc_train: 0.8667 loss_val: 0.8891 acc_val: 0.7300 time: 0.0197s\n",
            "Epoch: 0145 loss_train: 0.5130 acc_train: 0.9333 loss_val: 0.8854 acc_val: 0.7267 time: 0.0179s\n",
            "Epoch: 0146 loss_train: 0.5272 acc_train: 0.9000 loss_val: 0.8839 acc_val: 0.7233 time: 0.0178s\n",
            "Epoch: 0147 loss_train: 0.5173 acc_train: 0.9333 loss_val: 0.8815 acc_val: 0.7267 time: 0.0210s\n",
            "Epoch: 0148 loss_train: 0.5241 acc_train: 0.9167 loss_val: 0.8800 acc_val: 0.7267 time: 0.0199s\n",
            "Epoch: 0149 loss_train: 0.4863 acc_train: 0.8833 loss_val: 0.8788 acc_val: 0.7300 time: 0.0188s\n",
            "Epoch: 0150 loss_train: 0.5066 acc_train: 0.9000 loss_val: 0.8766 acc_val: 0.7267 time: 0.0177s\n",
            "Epoch: 0151 loss_train: 0.5259 acc_train: 0.8833 loss_val: 0.8736 acc_val: 0.7200 time: 0.0174s\n",
            "Epoch: 0152 loss_train: 0.5482 acc_train: 0.8833 loss_val: 0.8705 acc_val: 0.7267 time: 0.0189s\n",
            "Epoch: 0153 loss_train: 0.4553 acc_train: 0.9333 loss_val: 0.8668 acc_val: 0.7267 time: 0.0213s\n",
            "Epoch: 0154 loss_train: 0.4963 acc_train: 0.9500 loss_val: 0.8629 acc_val: 0.7267 time: 0.0209s\n",
            "Epoch: 0155 loss_train: 0.5414 acc_train: 0.9333 loss_val: 0.8582 acc_val: 0.7267 time: 0.0192s\n",
            "Epoch: 0156 loss_train: 0.4344 acc_train: 0.9667 loss_val: 0.8532 acc_val: 0.7267 time: 0.0235s\n",
            "Epoch: 0157 loss_train: 0.5452 acc_train: 0.9000 loss_val: 0.8488 acc_val: 0.7233 time: 0.0193s\n",
            "Epoch: 0158 loss_train: 0.4897 acc_train: 0.9167 loss_val: 0.8438 acc_val: 0.7267 time: 0.0199s\n",
            "Epoch: 0159 loss_train: 0.4631 acc_train: 0.9167 loss_val: 0.8396 acc_val: 0.7267 time: 0.0188s\n",
            "Epoch: 0160 loss_train: 0.5379 acc_train: 0.8833 loss_val: 0.8361 acc_val: 0.7267 time: 0.0218s\n",
            "Epoch: 0161 loss_train: 0.5273 acc_train: 0.8333 loss_val: 0.8327 acc_val: 0.7233 time: 0.0201s\n",
            "Epoch: 0162 loss_train: 0.4851 acc_train: 0.9333 loss_val: 0.8290 acc_val: 0.7267 time: 0.0219s\n",
            "Epoch: 0163 loss_train: 0.4378 acc_train: 0.9500 loss_val: 0.8258 acc_val: 0.7300 time: 0.0197s\n",
            "Epoch: 0164 loss_train: 0.5023 acc_train: 0.9000 loss_val: 0.8227 acc_val: 0.7300 time: 0.0196s\n",
            "Epoch: 0165 loss_train: 0.5000 acc_train: 0.9333 loss_val: 0.8209 acc_val: 0.7300 time: 0.0193s\n",
            "Epoch: 0166 loss_train: 0.4706 acc_train: 0.9500 loss_val: 0.8193 acc_val: 0.7333 time: 0.0190s\n",
            "Epoch: 0167 loss_train: 0.4475 acc_train: 0.9167 loss_val: 0.8175 acc_val: 0.7333 time: 0.0211s\n",
            "Epoch: 0168 loss_train: 0.4263 acc_train: 0.9167 loss_val: 0.8149 acc_val: 0.7367 time: 0.0206s\n",
            "Epoch: 0169 loss_train: 0.5278 acc_train: 0.9167 loss_val: 0.8121 acc_val: 0.7367 time: 0.0188s\n",
            "Epoch: 0170 loss_train: 0.4328 acc_train: 0.9500 loss_val: 0.8088 acc_val: 0.7367 time: 0.0192s\n",
            "Epoch: 0171 loss_train: 0.4445 acc_train: 0.9333 loss_val: 0.8058 acc_val: 0.7367 time: 0.0204s\n",
            "Epoch: 0172 loss_train: 0.4129 acc_train: 0.9333 loss_val: 0.8026 acc_val: 0.7367 time: 0.0239s\n",
            "Epoch: 0173 loss_train: 0.5397 acc_train: 0.9000 loss_val: 0.7988 acc_val: 0.7367 time: 0.0266s\n",
            "Epoch: 0174 loss_train: 0.4051 acc_train: 0.9500 loss_val: 0.7958 acc_val: 0.7333 time: 0.0216s\n",
            "Epoch: 0175 loss_train: 0.4160 acc_train: 0.9500 loss_val: 0.7937 acc_val: 0.7300 time: 0.0202s\n",
            "Epoch: 0176 loss_train: 0.4795 acc_train: 0.9500 loss_val: 0.7923 acc_val: 0.7300 time: 0.0199s\n",
            "Epoch: 0177 loss_train: 0.4419 acc_train: 0.9833 loss_val: 0.7929 acc_val: 0.7333 time: 0.0195s\n",
            "Epoch: 0178 loss_train: 0.5284 acc_train: 0.8833 loss_val: 0.7930 acc_val: 0.7300 time: 0.0192s\n",
            "Epoch: 0179 loss_train: 0.4383 acc_train: 0.9500 loss_val: 0.7921 acc_val: 0.7300 time: 0.0197s\n",
            "Epoch: 0180 loss_train: 0.4043 acc_train: 0.9500 loss_val: 0.7888 acc_val: 0.7300 time: 0.0237s\n",
            "Epoch: 0181 loss_train: 0.4605 acc_train: 0.9000 loss_val: 0.7852 acc_val: 0.7333 time: 0.0201s\n",
            "Epoch: 0182 loss_train: 0.3987 acc_train: 0.9500 loss_val: 0.7818 acc_val: 0.7367 time: 0.0186s\n",
            "Epoch: 0183 loss_train: 0.4044 acc_train: 0.9167 loss_val: 0.7781 acc_val: 0.7367 time: 0.0191s\n",
            "Epoch: 0184 loss_train: 0.3923 acc_train: 0.9667 loss_val: 0.7756 acc_val: 0.7400 time: 0.0226s\n",
            "Epoch: 0185 loss_train: 0.4241 acc_train: 0.9333 loss_val: 0.7750 acc_val: 0.7467 time: 0.0209s\n",
            "Epoch: 0186 loss_train: 0.3882 acc_train: 0.9000 loss_val: 0.7746 acc_val: 0.7467 time: 0.0197s\n",
            "Epoch: 0187 loss_train: 0.4184 acc_train: 0.9167 loss_val: 0.7738 acc_val: 0.7367 time: 0.0198s\n",
            "Epoch: 0188 loss_train: 0.4326 acc_train: 0.9167 loss_val: 0.7718 acc_val: 0.7400 time: 0.0196s\n",
            "Epoch: 0189 loss_train: 0.4076 acc_train: 0.9500 loss_val: 0.7703 acc_val: 0.7400 time: 0.0223s\n",
            "Epoch: 0190 loss_train: 0.4016 acc_train: 0.9333 loss_val: 0.7688 acc_val: 0.7367 time: 0.0206s\n",
            "Epoch: 0191 loss_train: 0.3861 acc_train: 0.9500 loss_val: 0.7688 acc_val: 0.7300 time: 0.0191s\n",
            "Epoch: 0192 loss_train: 0.4325 acc_train: 0.9000 loss_val: 0.7667 acc_val: 0.7300 time: 0.0249s\n",
            "Epoch: 0193 loss_train: 0.3984 acc_train: 0.9500 loss_val: 0.7623 acc_val: 0.7367 time: 0.0240s\n",
            "Epoch: 0194 loss_train: 0.4307 acc_train: 0.9167 loss_val: 0.7578 acc_val: 0.7500 time: 0.0190s\n",
            "Epoch: 0195 loss_train: 0.4040 acc_train: 0.9833 loss_val: 0.7536 acc_val: 0.7667 time: 0.0194s\n",
            "Epoch: 0196 loss_train: 0.3813 acc_train: 0.9833 loss_val: 0.7478 acc_val: 0.7767 time: 0.0194s\n",
            "Epoch: 0197 loss_train: 0.3522 acc_train: 1.0000 loss_val: 0.7428 acc_val: 0.7800 time: 0.0202s\n",
            "Epoch: 0198 loss_train: 0.4039 acc_train: 0.9000 loss_val: 0.7394 acc_val: 0.7767 time: 0.0249s\n",
            "Epoch: 0199 loss_train: 0.3962 acc_train: 0.9167 loss_val: 0.7371 acc_val: 0.7633 time: 0.0201s\n",
            "Epoch: 0200 loss_train: 0.3733 acc_train: 0.9667 loss_val: 0.7348 acc_val: 0.7600 time: 0.0194s\n",
            "After Completion of 60 labeled nodes\n",
            "Time taken: 4.5737s\n",
            "Test set results: loss= 0.8145 accuracy= 0.7500\n",
            "Epoch: 0001 loss_train: 0.8648 acc_train: 0.7167 loss_val: 0.7226 acc_val: 0.7733 time: 0.0205s\n",
            "Epoch: 0002 loss_train: 0.8627 acc_train: 0.7000 loss_val: 0.7100 acc_val: 0.7833 time: 0.0193s\n",
            "Epoch: 0003 loss_train: 0.8231 acc_train: 0.7417 loss_val: 0.7005 acc_val: 0.8200 time: 0.0204s\n",
            "Epoch: 0004 loss_train: 0.8513 acc_train: 0.7583 loss_val: 0.6950 acc_val: 0.8200 time: 0.0190s\n",
            "Epoch: 0005 loss_train: 0.7910 acc_train: 0.7833 loss_val: 0.6870 acc_val: 0.8267 time: 0.0205s\n",
            "Epoch: 0006 loss_train: 0.7345 acc_train: 0.7833 loss_val: 0.6767 acc_val: 0.8367 time: 0.0185s\n",
            "Epoch: 0007 loss_train: 0.7581 acc_train: 0.8000 loss_val: 0.6632 acc_val: 0.8533 time: 0.0239s\n",
            "Epoch: 0008 loss_train: 0.7310 acc_train: 0.8333 loss_val: 0.6490 acc_val: 0.8667 time: 0.0192s\n",
            "Epoch: 0009 loss_train: 0.7093 acc_train: 0.8417 loss_val: 0.6340 acc_val: 0.8900 time: 0.0215s\n",
            "Epoch: 0010 loss_train: 0.6644 acc_train: 0.8250 loss_val: 0.6201 acc_val: 0.8867 time: 0.0193s\n",
            "Epoch: 0011 loss_train: 0.6089 acc_train: 0.8917 loss_val: 0.6085 acc_val: 0.8867 time: 0.0205s\n",
            "Epoch: 0012 loss_train: 0.6116 acc_train: 0.8833 loss_val: 0.5983 acc_val: 0.8833 time: 0.0190s\n",
            "Epoch: 0013 loss_train: 0.6188 acc_train: 0.8583 loss_val: 0.5896 acc_val: 0.8767 time: 0.0191s\n",
            "Epoch: 0014 loss_train: 0.5610 acc_train: 0.8917 loss_val: 0.5819 acc_val: 0.8767 time: 0.0187s\n",
            "Epoch: 0015 loss_train: 0.5856 acc_train: 0.8750 loss_val: 0.5755 acc_val: 0.8767 time: 0.0205s\n",
            "Epoch: 0016 loss_train: 0.5322 acc_train: 0.9000 loss_val: 0.5685 acc_val: 0.8800 time: 0.0203s\n",
            "Epoch: 0017 loss_train: 0.5197 acc_train: 0.9083 loss_val: 0.5615 acc_val: 0.8833 time: 0.0322s\n",
            "Epoch: 0018 loss_train: 0.5069 acc_train: 0.9000 loss_val: 0.5560 acc_val: 0.8767 time: 0.0194s\n",
            "Epoch: 0019 loss_train: 0.5045 acc_train: 0.8917 loss_val: 0.5530 acc_val: 0.8667 time: 0.0208s\n",
            "Epoch: 0020 loss_train: 0.4731 acc_train: 0.8917 loss_val: 0.5506 acc_val: 0.8567 time: 0.0182s\n",
            "Epoch: 0021 loss_train: 0.4579 acc_train: 0.8917 loss_val: 0.5480 acc_val: 0.8533 time: 0.0209s\n",
            "Epoch: 0022 loss_train: 0.4312 acc_train: 0.8917 loss_val: 0.5451 acc_val: 0.8533 time: 0.0185s\n",
            "Epoch: 0023 loss_train: 0.4513 acc_train: 0.9000 loss_val: 0.5420 acc_val: 0.8633 time: 0.0183s\n",
            "Epoch: 0024 loss_train: 0.5090 acc_train: 0.8833 loss_val: 0.5391 acc_val: 0.8667 time: 0.0171s\n",
            "Epoch: 0025 loss_train: 0.4615 acc_train: 0.9000 loss_val: 0.5350 acc_val: 0.8700 time: 0.0177s\n",
            "Epoch: 0026 loss_train: 0.4198 acc_train: 0.9333 loss_val: 0.5316 acc_val: 0.8733 time: 0.0230s\n",
            "Epoch: 0027 loss_train: 0.4254 acc_train: 0.9167 loss_val: 0.5285 acc_val: 0.8867 time: 0.0192s\n",
            "Epoch: 0028 loss_train: 0.5117 acc_train: 0.8833 loss_val: 0.5282 acc_val: 0.8867 time: 0.0190s\n",
            "Epoch: 0029 loss_train: 0.4529 acc_train: 0.9000 loss_val: 0.5300 acc_val: 0.8867 time: 0.0188s\n",
            "Epoch: 0030 loss_train: 0.4344 acc_train: 0.9083 loss_val: 0.5332 acc_val: 0.8767 time: 0.0217s\n",
            "Epoch: 0031 loss_train: 0.4102 acc_train: 0.9333 loss_val: 0.5366 acc_val: 0.8767 time: 0.0185s\n",
            "Epoch: 0032 loss_train: 0.4356 acc_train: 0.9167 loss_val: 0.5400 acc_val: 0.8633 time: 0.0184s\n",
            "Epoch: 0033 loss_train: 0.3920 acc_train: 0.9250 loss_val: 0.5444 acc_val: 0.8567 time: 0.0177s\n",
            "Epoch: 0034 loss_train: 0.4238 acc_train: 0.9000 loss_val: 0.5482 acc_val: 0.8600 time: 0.0170s\n",
            "Epoch: 0035 loss_train: 0.4029 acc_train: 0.9250 loss_val: 0.5507 acc_val: 0.8600 time: 0.0187s\n",
            "Epoch: 0036 loss_train: 0.4374 acc_train: 0.9333 loss_val: 0.5501 acc_val: 0.8600 time: 0.0225s\n",
            "Epoch: 0037 loss_train: 0.3630 acc_train: 0.9417 loss_val: 0.5496 acc_val: 0.8600 time: 0.0185s\n",
            "Epoch: 0038 loss_train: 0.3504 acc_train: 0.9333 loss_val: 0.5482 acc_val: 0.8600 time: 0.0178s\n",
            "Epoch: 0039 loss_train: 0.3927 acc_train: 0.9417 loss_val: 0.5477 acc_val: 0.8633 time: 0.0187s\n",
            "Epoch: 0040 loss_train: 0.3700 acc_train: 0.9417 loss_val: 0.5472 acc_val: 0.8667 time: 0.0230s\n",
            "Epoch: 0041 loss_train: 0.3311 acc_train: 0.9417 loss_val: 0.5462 acc_val: 0.8667 time: 0.0178s\n",
            "Epoch: 0042 loss_train: 0.4146 acc_train: 0.9333 loss_val: 0.5454 acc_val: 0.8667 time: 0.0183s\n",
            "Epoch: 0043 loss_train: 0.3877 acc_train: 0.9250 loss_val: 0.5459 acc_val: 0.8667 time: 0.0184s\n",
            "Epoch: 0044 loss_train: 0.3520 acc_train: 0.9417 loss_val: 0.5468 acc_val: 0.8667 time: 0.0194s\n",
            "Epoch: 0045 loss_train: 0.3775 acc_train: 0.9333 loss_val: 0.5463 acc_val: 0.8667 time: 0.0182s\n",
            "Epoch: 0046 loss_train: 0.3713 acc_train: 0.9417 loss_val: 0.5456 acc_val: 0.8667 time: 0.0227s\n",
            "Epoch: 0047 loss_train: 0.3882 acc_train: 0.9500 loss_val: 0.5460 acc_val: 0.8633 time: 0.0190s\n",
            "Epoch: 0048 loss_train: 0.3389 acc_train: 0.9250 loss_val: 0.5447 acc_val: 0.8633 time: 0.0209s\n",
            "Epoch: 0049 loss_train: 0.3560 acc_train: 0.9333 loss_val: 0.5438 acc_val: 0.8667 time: 0.0179s\n",
            "Epoch: 0050 loss_train: 0.3343 acc_train: 0.9583 loss_val: 0.5439 acc_val: 0.8700 time: 0.0188s\n",
            "Epoch: 0051 loss_train: 0.3574 acc_train: 0.9500 loss_val: 0.5445 acc_val: 0.8667 time: 0.0176s\n",
            "Epoch: 0052 loss_train: 0.3407 acc_train: 0.9583 loss_val: 0.5459 acc_val: 0.8667 time: 0.0206s\n",
            "Epoch: 0053 loss_train: 0.3815 acc_train: 0.9500 loss_val: 0.5467 acc_val: 0.8667 time: 0.0177s\n",
            "Epoch: 0054 loss_train: 0.3558 acc_train: 0.9583 loss_val: 0.5470 acc_val: 0.8667 time: 0.0176s\n",
            "Epoch: 0055 loss_train: 0.3900 acc_train: 0.9250 loss_val: 0.5482 acc_val: 0.8633 time: 0.0176s\n",
            "Epoch: 0056 loss_train: 0.3783 acc_train: 0.9417 loss_val: 0.5483 acc_val: 0.8633 time: 0.0213s\n",
            "Epoch: 0057 loss_train: 0.3987 acc_train: 0.9500 loss_val: 0.5473 acc_val: 0.8667 time: 0.0189s\n",
            "Epoch: 0058 loss_train: 0.3671 acc_train: 0.9417 loss_val: 0.5478 acc_val: 0.8667 time: 0.0178s\n",
            "Epoch: 0059 loss_train: 0.3705 acc_train: 0.9333 loss_val: 0.5485 acc_val: 0.8667 time: 0.0179s\n",
            "Epoch: 0060 loss_train: 0.3777 acc_train: 0.9500 loss_val: 0.5487 acc_val: 0.8700 time: 0.0185s\n",
            "Epoch: 0061 loss_train: 0.3796 acc_train: 0.9667 loss_val: 0.5481 acc_val: 0.8700 time: 0.0201s\n",
            "Epoch: 0062 loss_train: 0.3263 acc_train: 0.9417 loss_val: 0.5476 acc_val: 0.8667 time: 0.0193s\n",
            "Epoch: 0063 loss_train: 0.3195 acc_train: 0.9583 loss_val: 0.5471 acc_val: 0.8567 time: 0.0206s\n",
            "Epoch: 0064 loss_train: 0.4080 acc_train: 0.8917 loss_val: 0.5465 acc_val: 0.8567 time: 0.0243s\n",
            "Epoch: 0065 loss_train: 0.3540 acc_train: 0.9250 loss_val: 0.5474 acc_val: 0.8567 time: 0.0198s\n",
            "Epoch: 0066 loss_train: 0.3577 acc_train: 0.9417 loss_val: 0.5482 acc_val: 0.8567 time: 0.0234s\n",
            "Epoch: 0067 loss_train: 0.3381 acc_train: 0.9583 loss_val: 0.5487 acc_val: 0.8567 time: 0.0196s\n",
            "Epoch: 0068 loss_train: 0.3240 acc_train: 0.9667 loss_val: 0.5492 acc_val: 0.8600 time: 0.0194s\n",
            "Epoch: 0069 loss_train: 0.3789 acc_train: 0.9417 loss_val: 0.5471 acc_val: 0.8600 time: 0.0204s\n",
            "Epoch: 0070 loss_train: 0.3577 acc_train: 0.9667 loss_val: 0.5444 acc_val: 0.8600 time: 0.0196s\n",
            "Epoch: 0071 loss_train: 0.3055 acc_train: 0.9583 loss_val: 0.5424 acc_val: 0.8600 time: 0.0183s\n",
            "Epoch: 0072 loss_train: 0.3421 acc_train: 0.9667 loss_val: 0.5417 acc_val: 0.8667 time: 0.0195s\n",
            "Epoch: 0073 loss_train: 0.3408 acc_train: 0.9333 loss_val: 0.5414 acc_val: 0.8667 time: 0.0195s\n",
            "Epoch: 0074 loss_train: 0.3529 acc_train: 0.9500 loss_val: 0.5429 acc_val: 0.8633 time: 0.0194s\n",
            "Epoch: 0075 loss_train: 0.2841 acc_train: 0.9583 loss_val: 0.5457 acc_val: 0.8567 time: 0.0182s\n",
            "Epoch: 0076 loss_train: 0.3626 acc_train: 0.9250 loss_val: 0.5487 acc_val: 0.8567 time: 0.0240s\n",
            "Epoch: 0077 loss_train: 0.3072 acc_train: 0.9833 loss_val: 0.5521 acc_val: 0.8533 time: 0.0189s\n",
            "Epoch: 0078 loss_train: 0.3143 acc_train: 0.9750 loss_val: 0.5542 acc_val: 0.8533 time: 0.0186s\n",
            "Epoch: 0079 loss_train: 0.3316 acc_train: 0.9583 loss_val: 0.5553 acc_val: 0.8533 time: 0.0195s\n",
            "Epoch: 0080 loss_train: 0.3580 acc_train: 0.9417 loss_val: 0.5527 acc_val: 0.8533 time: 0.0254s\n",
            "Epoch: 0081 loss_train: 0.3475 acc_train: 0.9500 loss_val: 0.5495 acc_val: 0.8567 time: 0.0181s\n",
            "Epoch: 0082 loss_train: 0.3449 acc_train: 0.9750 loss_val: 0.5488 acc_val: 0.8567 time: 0.0191s\n",
            "Epoch: 0083 loss_train: 0.3011 acc_train: 0.9583 loss_val: 0.5477 acc_val: 0.8567 time: 0.0175s\n",
            "Epoch: 0084 loss_train: 0.3326 acc_train: 0.9833 loss_val: 0.5466 acc_val: 0.8567 time: 0.0281s\n",
            "Epoch: 0085 loss_train: 0.2952 acc_train: 0.9583 loss_val: 0.5461 acc_val: 0.8533 time: 0.0296s\n",
            "Epoch: 0086 loss_train: 0.2960 acc_train: 0.9583 loss_val: 0.5464 acc_val: 0.8533 time: 0.0279s\n",
            "Epoch: 0087 loss_train: 0.3380 acc_train: 0.9333 loss_val: 0.5472 acc_val: 0.8533 time: 0.0272s\n",
            "Epoch: 0088 loss_train: 0.3403 acc_train: 0.9333 loss_val: 0.5470 acc_val: 0.8533 time: 0.0258s\n",
            "Epoch: 0089 loss_train: 0.3131 acc_train: 0.9500 loss_val: 0.5457 acc_val: 0.8533 time: 0.0259s\n",
            "Epoch: 0090 loss_train: 0.3111 acc_train: 0.9667 loss_val: 0.5447 acc_val: 0.8600 time: 0.0259s\n",
            "Epoch: 0091 loss_train: 0.3308 acc_train: 0.9667 loss_val: 0.5447 acc_val: 0.8600 time: 0.0332s\n",
            "Epoch: 0092 loss_train: 0.2912 acc_train: 0.9667 loss_val: 0.5452 acc_val: 0.8600 time: 0.0254s\n",
            "Epoch: 0093 loss_train: 0.2922 acc_train: 0.9583 loss_val: 0.5444 acc_val: 0.8633 time: 0.0254s\n",
            "Epoch: 0094 loss_train: 0.3281 acc_train: 0.9583 loss_val: 0.5433 acc_val: 0.8633 time: 0.0269s\n",
            "Epoch: 0095 loss_train: 0.3511 acc_train: 0.9583 loss_val: 0.5434 acc_val: 0.8633 time: 0.0255s\n",
            "Epoch: 0096 loss_train: 0.3380 acc_train: 0.9667 loss_val: 0.5452 acc_val: 0.8633 time: 0.0248s\n",
            "Epoch: 0097 loss_train: 0.3423 acc_train: 0.9750 loss_val: 0.5463 acc_val: 0.8600 time: 0.0250s\n",
            "Epoch: 0098 loss_train: 0.3375 acc_train: 0.9333 loss_val: 0.5470 acc_val: 0.8600 time: 0.0252s\n",
            "Epoch: 0099 loss_train: 0.3372 acc_train: 0.9667 loss_val: 0.5507 acc_val: 0.8567 time: 0.0274s\n",
            "Epoch: 0100 loss_train: 0.3051 acc_train: 0.9417 loss_val: 0.5522 acc_val: 0.8500 time: 0.0252s\n",
            "Epoch: 0101 loss_train: 0.3115 acc_train: 0.9333 loss_val: 0.5525 acc_val: 0.8433 time: 0.0249s\n",
            "Epoch: 0102 loss_train: 0.3162 acc_train: 0.9667 loss_val: 0.5506 acc_val: 0.8433 time: 0.0279s\n",
            "Epoch: 0103 loss_train: 0.2598 acc_train: 0.9583 loss_val: 0.5491 acc_val: 0.8433 time: 0.0272s\n",
            "Epoch: 0104 loss_train: 0.3763 acc_train: 0.9250 loss_val: 0.5469 acc_val: 0.8433 time: 0.0254s\n",
            "Epoch: 0105 loss_train: 0.3323 acc_train: 0.9667 loss_val: 0.5453 acc_val: 0.8500 time: 0.0308s\n",
            "Epoch: 0106 loss_train: 0.2493 acc_train: 0.9917 loss_val: 0.5452 acc_val: 0.8533 time: 0.0264s\n",
            "Epoch: 0107 loss_train: 0.3150 acc_train: 0.9750 loss_val: 0.5437 acc_val: 0.8567 time: 0.0249s\n",
            "Epoch: 0108 loss_train: 0.3160 acc_train: 0.9417 loss_val: 0.5438 acc_val: 0.8567 time: 0.0248s\n",
            "Epoch: 0109 loss_train: 0.2603 acc_train: 0.9917 loss_val: 0.5450 acc_val: 0.8567 time: 0.0262s\n",
            "Epoch: 0110 loss_train: 0.3235 acc_train: 0.9500 loss_val: 0.5450 acc_val: 0.8600 time: 0.0261s\n",
            "Epoch: 0111 loss_train: 0.3127 acc_train: 0.9583 loss_val: 0.5451 acc_val: 0.8567 time: 0.0255s\n",
            "Epoch: 0112 loss_train: 0.2927 acc_train: 0.9583 loss_val: 0.5461 acc_val: 0.8533 time: 0.0247s\n",
            "Epoch: 0113 loss_train: 0.2783 acc_train: 0.9833 loss_val: 0.5478 acc_val: 0.8467 time: 0.0251s\n",
            "Epoch: 0114 loss_train: 0.3090 acc_train: 0.9667 loss_val: 0.5519 acc_val: 0.8400 time: 0.0243s\n",
            "Epoch: 0115 loss_train: 0.2737 acc_train: 0.9833 loss_val: 0.5521 acc_val: 0.8400 time: 0.0254s\n",
            "Epoch: 0116 loss_train: 0.2679 acc_train: 0.9667 loss_val: 0.5476 acc_val: 0.8433 time: 0.0257s\n",
            "Epoch: 0117 loss_train: 0.2357 acc_train: 0.9750 loss_val: 0.5424 acc_val: 0.8500 time: 0.0248s\n",
            "Epoch: 0118 loss_train: 0.2771 acc_train: 0.9750 loss_val: 0.5396 acc_val: 0.8500 time: 0.0249s\n",
            "Epoch: 0119 loss_train: 0.3011 acc_train: 0.9417 loss_val: 0.5391 acc_val: 0.8600 time: 0.0246s\n",
            "Epoch: 0120 loss_train: 0.2721 acc_train: 0.9833 loss_val: 0.5388 acc_val: 0.8633 time: 0.0304s\n",
            "Epoch: 0121 loss_train: 0.2951 acc_train: 0.9583 loss_val: 0.5379 acc_val: 0.8633 time: 0.0256s\n",
            "Epoch: 0122 loss_train: 0.2970 acc_train: 0.9667 loss_val: 0.5358 acc_val: 0.8667 time: 0.0255s\n",
            "Epoch: 0123 loss_train: 0.2717 acc_train: 0.9667 loss_val: 0.5362 acc_val: 0.8667 time: 0.0250s\n",
            "Epoch: 0124 loss_train: 0.2831 acc_train: 0.9833 loss_val: 0.5363 acc_val: 0.8633 time: 0.0247s\n",
            "Epoch: 0125 loss_train: 0.2823 acc_train: 0.9667 loss_val: 0.5367 acc_val: 0.8633 time: 0.0250s\n",
            "Epoch: 0126 loss_train: 0.3156 acc_train: 0.9500 loss_val: 0.5387 acc_val: 0.8633 time: 0.0262s\n",
            "Epoch: 0127 loss_train: 0.2628 acc_train: 0.9750 loss_val: 0.5410 acc_val: 0.8633 time: 0.0269s\n",
            "Epoch: 0128 loss_train: 0.2749 acc_train: 0.9667 loss_val: 0.5433 acc_val: 0.8633 time: 0.0335s\n",
            "Epoch: 0129 loss_train: 0.2679 acc_train: 0.9583 loss_val: 0.5423 acc_val: 0.8633 time: 0.0255s\n",
            "Epoch: 0130 loss_train: 0.3046 acc_train: 0.9583 loss_val: 0.5410 acc_val: 0.8633 time: 0.0265s\n",
            "Epoch: 0131 loss_train: 0.2744 acc_train: 0.9583 loss_val: 0.5399 acc_val: 0.8633 time: 0.0249s\n",
            "Epoch: 0132 loss_train: 0.2991 acc_train: 0.9750 loss_val: 0.5404 acc_val: 0.8633 time: 0.0253s\n",
            "Epoch: 0133 loss_train: 0.2843 acc_train: 0.9667 loss_val: 0.5414 acc_val: 0.8567 time: 0.0256s\n",
            "Epoch: 0134 loss_train: 0.2682 acc_train: 0.9750 loss_val: 0.5414 acc_val: 0.8533 time: 0.0279s\n",
            "Epoch: 0135 loss_train: 0.2583 acc_train: 0.9750 loss_val: 0.5431 acc_val: 0.8533 time: 0.0278s\n",
            "Epoch: 0136 loss_train: 0.2741 acc_train: 0.9750 loss_val: 0.5417 acc_val: 0.8567 time: 0.0255s\n",
            "Epoch: 0137 loss_train: 0.2706 acc_train: 0.9750 loss_val: 0.5383 acc_val: 0.8633 time: 0.0275s\n",
            "Epoch: 0138 loss_train: 0.3205 acc_train: 0.9583 loss_val: 0.5352 acc_val: 0.8633 time: 0.0279s\n",
            "Epoch: 0139 loss_train: 0.2625 acc_train: 0.9750 loss_val: 0.5297 acc_val: 0.8667 time: 0.0262s\n",
            "Epoch: 0140 loss_train: 0.2893 acc_train: 0.9750 loss_val: 0.5276 acc_val: 0.8633 time: 0.0260s\n",
            "Epoch: 0141 loss_train: 0.2635 acc_train: 0.9833 loss_val: 0.5266 acc_val: 0.8633 time: 0.0304s\n",
            "Epoch: 0142 loss_train: 0.2929 acc_train: 0.9500 loss_val: 0.5266 acc_val: 0.8633 time: 0.0252s\n",
            "Epoch: 0143 loss_train: 0.2657 acc_train: 0.9750 loss_val: 0.5261 acc_val: 0.8633 time: 0.0245s\n",
            "Epoch: 0144 loss_train: 0.2997 acc_train: 0.9667 loss_val: 0.5271 acc_val: 0.8600 time: 0.0245s\n",
            "Epoch: 0145 loss_train: 0.2714 acc_train: 0.9833 loss_val: 0.5281 acc_val: 0.8600 time: 0.0269s\n",
            "Epoch: 0146 loss_train: 0.2860 acc_train: 0.9667 loss_val: 0.5292 acc_val: 0.8633 time: 0.0250s\n",
            "Epoch: 0147 loss_train: 0.2770 acc_train: 0.9667 loss_val: 0.5309 acc_val: 0.8600 time: 0.0250s\n",
            "Epoch: 0148 loss_train: 0.2903 acc_train: 0.9667 loss_val: 0.5326 acc_val: 0.8533 time: 0.0246s\n",
            "Epoch: 0149 loss_train: 0.3164 acc_train: 0.9667 loss_val: 0.5335 acc_val: 0.8500 time: 0.0300s\n",
            "Epoch: 0150 loss_train: 0.2705 acc_train: 0.9667 loss_val: 0.5325 acc_val: 0.8533 time: 0.0244s\n",
            "Epoch: 0151 loss_train: 0.2747 acc_train: 0.9833 loss_val: 0.5330 acc_val: 0.8533 time: 0.0252s\n",
            "Epoch: 0152 loss_train: 0.2688 acc_train: 0.9750 loss_val: 0.5318 acc_val: 0.8567 time: 0.0246s\n",
            "Epoch: 0153 loss_train: 0.2711 acc_train: 0.9667 loss_val: 0.5296 acc_val: 0.8600 time: 0.0246s\n",
            "Epoch: 0154 loss_train: 0.2423 acc_train: 0.9750 loss_val: 0.5276 acc_val: 0.8633 time: 0.0281s\n",
            "Epoch: 0155 loss_train: 0.2933 acc_train: 0.9750 loss_val: 0.5278 acc_val: 0.8600 time: 0.0252s\n",
            "Epoch: 0156 loss_train: 0.2640 acc_train: 0.9750 loss_val: 0.5266 acc_val: 0.8600 time: 0.0261s\n",
            "Epoch: 0157 loss_train: 0.2706 acc_train: 0.9500 loss_val: 0.5249 acc_val: 0.8600 time: 0.0301s\n",
            "Epoch: 0158 loss_train: 0.2572 acc_train: 0.9750 loss_val: 0.5243 acc_val: 0.8600 time: 0.0275s\n",
            "Epoch: 0159 loss_train: 0.2802 acc_train: 0.9583 loss_val: 0.5235 acc_val: 0.8567 time: 0.0297s\n",
            "Epoch: 0160 loss_train: 0.2766 acc_train: 0.9667 loss_val: 0.5234 acc_val: 0.8567 time: 0.0287s\n",
            "Epoch: 0161 loss_train: 0.2506 acc_train: 0.9750 loss_val: 0.5239 acc_val: 0.8567 time: 0.0255s\n",
            "Epoch: 0162 loss_train: 0.2484 acc_train: 0.9833 loss_val: 0.5246 acc_val: 0.8567 time: 0.0299s\n",
            "Epoch: 0163 loss_train: 0.2193 acc_train: 0.9833 loss_val: 0.5243 acc_val: 0.8533 time: 0.0252s\n",
            "Epoch: 0164 loss_train: 0.2760 acc_train: 0.9500 loss_val: 0.5214 acc_val: 0.8600 time: 0.0305s\n",
            "Epoch: 0165 loss_train: 0.2411 acc_train: 0.9833 loss_val: 0.5210 acc_val: 0.8600 time: 0.0257s\n",
            "Epoch: 0166 loss_train: 0.2570 acc_train: 0.9667 loss_val: 0.5210 acc_val: 0.8600 time: 0.0248s\n",
            "Epoch: 0167 loss_train: 0.2532 acc_train: 0.9750 loss_val: 0.5203 acc_val: 0.8567 time: 0.0285s\n",
            "Epoch: 0168 loss_train: 0.2861 acc_train: 0.9750 loss_val: 0.5220 acc_val: 0.8633 time: 0.0265s\n",
            "Epoch: 0169 loss_train: 0.2752 acc_train: 0.9500 loss_val: 0.5245 acc_val: 0.8600 time: 0.0283s\n",
            "Epoch: 0170 loss_train: 0.2499 acc_train: 0.9583 loss_val: 0.5232 acc_val: 0.8600 time: 0.0254s\n",
            "Epoch: 0171 loss_train: 0.2465 acc_train: 0.9750 loss_val: 0.5223 acc_val: 0.8633 time: 0.0299s\n",
            "Epoch: 0172 loss_train: 0.2573 acc_train: 0.9917 loss_val: 0.5214 acc_val: 0.8633 time: 0.0258s\n",
            "Epoch: 0173 loss_train: 0.2290 acc_train: 0.9833 loss_val: 0.5231 acc_val: 0.8567 time: 0.0290s\n",
            "Epoch: 0174 loss_train: 0.3053 acc_train: 0.9667 loss_val: 0.5251 acc_val: 0.8533 time: 0.0308s\n",
            "Epoch: 0175 loss_train: 0.2848 acc_train: 0.9833 loss_val: 0.5278 acc_val: 0.8567 time: 0.0261s\n",
            "Epoch: 0176 loss_train: 0.2521 acc_train: 0.9750 loss_val: 0.5294 acc_val: 0.8567 time: 0.0250s\n",
            "Epoch: 0177 loss_train: 0.2924 acc_train: 0.9583 loss_val: 0.5287 acc_val: 0.8533 time: 0.0255s\n",
            "Epoch: 0178 loss_train: 0.2562 acc_train: 0.9833 loss_val: 0.5254 acc_val: 0.8567 time: 0.0320s\n",
            "Epoch: 0179 loss_train: 0.2627 acc_train: 0.9833 loss_val: 0.5219 acc_val: 0.8600 time: 0.0267s\n",
            "Epoch: 0180 loss_train: 0.2505 acc_train: 0.9667 loss_val: 0.5204 acc_val: 0.8733 time: 0.0241s\n",
            "Epoch: 0181 loss_train: 0.2758 acc_train: 0.9500 loss_val: 0.5192 acc_val: 0.8733 time: 0.0250s\n",
            "Epoch: 0182 loss_train: 0.2090 acc_train: 0.9833 loss_val: 0.5191 acc_val: 0.8733 time: 0.0243s\n",
            "Epoch: 0183 loss_train: 0.2415 acc_train: 0.9833 loss_val: 0.5211 acc_val: 0.8600 time: 0.0244s\n",
            "Epoch: 0184 loss_train: 0.2219 acc_train: 0.9833 loss_val: 0.5227 acc_val: 0.8600 time: 0.0249s\n",
            "Epoch: 0185 loss_train: 0.2571 acc_train: 0.9750 loss_val: 0.5235 acc_val: 0.8567 time: 0.0245s\n",
            "Epoch: 0186 loss_train: 0.2196 acc_train: 0.9833 loss_val: 0.5253 acc_val: 0.8567 time: 0.0301s\n",
            "Epoch: 0187 loss_train: 0.2301 acc_train: 0.9917 loss_val: 0.5283 acc_val: 0.8567 time: 0.0248s\n",
            "Epoch: 0188 loss_train: 0.2556 acc_train: 0.9583 loss_val: 0.5310 acc_val: 0.8600 time: 0.0269s\n",
            "Epoch: 0189 loss_train: 0.2474 acc_train: 0.9667 loss_val: 0.5359 acc_val: 0.8600 time: 0.0258s\n",
            "Epoch: 0190 loss_train: 0.2856 acc_train: 0.9417 loss_val: 0.5353 acc_val: 0.8633 time: 0.0238s\n",
            "Epoch: 0191 loss_train: 0.2570 acc_train: 0.9667 loss_val: 0.5313 acc_val: 0.8600 time: 0.0238s\n",
            "Epoch: 0192 loss_train: 0.2448 acc_train: 0.9667 loss_val: 0.5247 acc_val: 0.8533 time: 0.0236s\n",
            "Epoch: 0193 loss_train: 0.2032 acc_train: 0.9917 loss_val: 0.5199 acc_val: 0.8567 time: 0.0227s\n",
            "Epoch: 0194 loss_train: 0.2522 acc_train: 0.9750 loss_val: 0.5169 acc_val: 0.8567 time: 0.0302s\n",
            "Epoch: 0195 loss_train: 0.2729 acc_train: 0.9667 loss_val: 0.5168 acc_val: 0.8533 time: 0.0274s\n",
            "Epoch: 0196 loss_train: 0.2840 acc_train: 0.9750 loss_val: 0.5212 acc_val: 0.8533 time: 0.0234s\n",
            "Epoch: 0197 loss_train: 0.2329 acc_train: 0.9750 loss_val: 0.5264 acc_val: 0.8600 time: 0.0240s\n",
            "Epoch: 0198 loss_train: 0.2203 acc_train: 0.9833 loss_val: 0.5272 acc_val: 0.8633 time: 0.0248s\n",
            "Epoch: 0199 loss_train: 0.2322 acc_train: 0.9833 loss_val: 0.5251 acc_val: 0.8600 time: 0.0246s\n",
            "Epoch: 0200 loss_train: 0.2375 acc_train: 0.9750 loss_val: 0.5219 acc_val: 0.8567 time: 0.0241s\n",
            "After Completion of 120 labeled nodes\n",
            "Time taken: 5.2855s\n",
            "Test set results: loss= 0.7413 accuracy= 0.7860\n",
            "Epoch: 0001 loss_train: 0.6457 acc_train: 0.8111 loss_val: 0.5006 acc_val: 0.8700 time: 0.0293s\n",
            "Epoch: 0002 loss_train: 0.5464 acc_train: 0.8722 loss_val: 0.4772 acc_val: 0.8800 time: 0.0258s\n",
            "Epoch: 0003 loss_train: 0.5142 acc_train: 0.8500 loss_val: 0.4575 acc_val: 0.8900 time: 0.0286s\n",
            "Epoch: 0004 loss_train: 0.4841 acc_train: 0.8556 loss_val: 0.4413 acc_val: 0.9033 time: 0.0254s\n",
            "Epoch: 0005 loss_train: 0.5063 acc_train: 0.8389 loss_val: 0.4251 acc_val: 0.9167 time: 0.0254s\n",
            "Epoch: 0006 loss_train: 0.4326 acc_train: 0.9000 loss_val: 0.4100 acc_val: 0.9300 time: 0.0258s\n",
            "Epoch: 0007 loss_train: 0.4152 acc_train: 0.9111 loss_val: 0.3955 acc_val: 0.9367 time: 0.0251s\n",
            "Epoch: 0008 loss_train: 0.4453 acc_train: 0.9222 loss_val: 0.3825 acc_val: 0.9367 time: 0.0305s\n",
            "Epoch: 0009 loss_train: 0.4101 acc_train: 0.9111 loss_val: 0.3713 acc_val: 0.9333 time: 0.0243s\n",
            "Epoch: 0010 loss_train: 0.3537 acc_train: 0.9556 loss_val: 0.3620 acc_val: 0.9233 time: 0.0280s\n",
            "Epoch: 0011 loss_train: 0.3266 acc_train: 0.9611 loss_val: 0.3553 acc_val: 0.9200 time: 0.0262s\n",
            "Epoch: 0012 loss_train: 0.3433 acc_train: 0.9167 loss_val: 0.3504 acc_val: 0.9200 time: 0.0260s\n",
            "Epoch: 0013 loss_train: 0.3293 acc_train: 0.9500 loss_val: 0.3471 acc_val: 0.9200 time: 0.0251s\n",
            "Epoch: 0014 loss_train: 0.3584 acc_train: 0.9111 loss_val: 0.3437 acc_val: 0.9167 time: 0.0252s\n",
            "Epoch: 0015 loss_train: 0.3617 acc_train: 0.9444 loss_val: 0.3411 acc_val: 0.9133 time: 0.0305s\n",
            "Epoch: 0016 loss_train: 0.3294 acc_train: 0.9500 loss_val: 0.3380 acc_val: 0.9133 time: 0.0257s\n",
            "Epoch: 0017 loss_train: 0.3195 acc_train: 0.9556 loss_val: 0.3351 acc_val: 0.9133 time: 0.0249s\n",
            "Epoch: 0018 loss_train: 0.3230 acc_train: 0.9333 loss_val: 0.3327 acc_val: 0.9133 time: 0.0268s\n",
            "Epoch: 0019 loss_train: 0.3282 acc_train: 0.9333 loss_val: 0.3302 acc_val: 0.9200 time: 0.0253s\n",
            "Epoch: 0020 loss_train: 0.3075 acc_train: 0.9389 loss_val: 0.3290 acc_val: 0.9167 time: 0.0256s\n",
            "Epoch: 0021 loss_train: 0.2974 acc_train: 0.9333 loss_val: 0.3285 acc_val: 0.9200 time: 0.0269s\n",
            "Epoch: 0022 loss_train: 0.2737 acc_train: 0.9500 loss_val: 0.3273 acc_val: 0.9200 time: 0.0242s\n",
            "Epoch: 0023 loss_train: 0.2915 acc_train: 0.9611 loss_val: 0.3267 acc_val: 0.9200 time: 0.0263s\n",
            "Epoch: 0024 loss_train: 0.3121 acc_train: 0.9556 loss_val: 0.3269 acc_val: 0.9267 time: 0.0270s\n",
            "Epoch: 0025 loss_train: 0.2766 acc_train: 0.9389 loss_val: 0.3279 acc_val: 0.9300 time: 0.0274s\n",
            "Epoch: 0026 loss_train: 0.2596 acc_train: 0.9611 loss_val: 0.3292 acc_val: 0.9267 time: 0.0257s\n",
            "Epoch: 0027 loss_train: 0.3138 acc_train: 0.9667 loss_val: 0.3302 acc_val: 0.9267 time: 0.0172s\n",
            "Epoch: 0028 loss_train: 0.2660 acc_train: 0.9556 loss_val: 0.3304 acc_val: 0.9267 time: 0.0175s\n",
            "Epoch: 0029 loss_train: 0.2524 acc_train: 0.9667 loss_val: 0.3302 acc_val: 0.9233 time: 0.0207s\n",
            "Epoch: 0030 loss_train: 0.3033 acc_train: 0.9611 loss_val: 0.3295 acc_val: 0.9267 time: 0.0194s\n",
            "Epoch: 0031 loss_train: 0.2760 acc_train: 0.9500 loss_val: 0.3296 acc_val: 0.9300 time: 0.0206s\n",
            "Epoch: 0032 loss_train: 0.2642 acc_train: 0.9389 loss_val: 0.3306 acc_val: 0.9267 time: 0.0207s\n",
            "Epoch: 0033 loss_train: 0.2869 acc_train: 0.9333 loss_val: 0.3318 acc_val: 0.9267 time: 0.0174s\n",
            "Epoch: 0034 loss_train: 0.2820 acc_train: 0.9667 loss_val: 0.3336 acc_val: 0.9267 time: 0.0188s\n",
            "Epoch: 0035 loss_train: 0.2978 acc_train: 0.9667 loss_val: 0.3351 acc_val: 0.9267 time: 0.0182s\n",
            "Epoch: 0036 loss_train: 0.2729 acc_train: 0.9500 loss_val: 0.3366 acc_val: 0.9233 time: 0.0169s\n",
            "Epoch: 0037 loss_train: 0.2690 acc_train: 0.9667 loss_val: 0.3384 acc_val: 0.9233 time: 0.0173s\n",
            "Epoch: 0038 loss_train: 0.3242 acc_train: 0.9333 loss_val: 0.3399 acc_val: 0.9233 time: 0.0178s\n",
            "Epoch: 0039 loss_train: 0.3038 acc_train: 0.9611 loss_val: 0.3411 acc_val: 0.9233 time: 0.0173s\n",
            "Epoch: 0040 loss_train: 0.2700 acc_train: 0.9611 loss_val: 0.3425 acc_val: 0.9233 time: 0.0223s\n",
            "Epoch: 0041 loss_train: 0.3330 acc_train: 0.9389 loss_val: 0.3429 acc_val: 0.9267 time: 0.0179s\n",
            "Epoch: 0042 loss_train: 0.2865 acc_train: 0.9444 loss_val: 0.3438 acc_val: 0.9233 time: 0.0225s\n",
            "Epoch: 0043 loss_train: 0.2847 acc_train: 0.9444 loss_val: 0.3448 acc_val: 0.9233 time: 0.0197s\n",
            "Epoch: 0044 loss_train: 0.2790 acc_train: 0.9556 loss_val: 0.3458 acc_val: 0.9200 time: 0.0180s\n",
            "Epoch: 0045 loss_train: 0.2663 acc_train: 0.9667 loss_val: 0.3469 acc_val: 0.9200 time: 0.0184s\n",
            "Epoch: 0046 loss_train: 0.2659 acc_train: 0.9667 loss_val: 0.3473 acc_val: 0.9200 time: 0.0195s\n",
            "Epoch: 0047 loss_train: 0.2993 acc_train: 0.9611 loss_val: 0.3471 acc_val: 0.9200 time: 0.0198s\n",
            "Epoch: 0048 loss_train: 0.2688 acc_train: 0.9611 loss_val: 0.3460 acc_val: 0.9233 time: 0.0178s\n",
            "Epoch: 0049 loss_train: 0.2773 acc_train: 0.9444 loss_val: 0.3450 acc_val: 0.9200 time: 0.0181s\n",
            "Epoch: 0050 loss_train: 0.3096 acc_train: 0.9611 loss_val: 0.3444 acc_val: 0.9200 time: 0.0179s\n",
            "Epoch: 0051 loss_train: 0.2748 acc_train: 0.9611 loss_val: 0.3444 acc_val: 0.9200 time: 0.0173s\n",
            "Epoch: 0052 loss_train: 0.2630 acc_train: 0.9722 loss_val: 0.3453 acc_val: 0.9200 time: 0.0312s\n",
            "Epoch: 0053 loss_train: 0.2718 acc_train: 0.9722 loss_val: 0.3461 acc_val: 0.9200 time: 0.0173s\n",
            "Epoch: 0054 loss_train: 0.2759 acc_train: 0.9611 loss_val: 0.3467 acc_val: 0.9200 time: 0.0180s\n",
            "Epoch: 0055 loss_train: 0.2681 acc_train: 0.9722 loss_val: 0.3467 acc_val: 0.9200 time: 0.0178s\n",
            "Epoch: 0056 loss_train: 0.3083 acc_train: 0.9500 loss_val: 0.3461 acc_val: 0.9200 time: 0.0177s\n",
            "Epoch: 0057 loss_train: 0.2441 acc_train: 0.9611 loss_val: 0.3457 acc_val: 0.9200 time: 0.0173s\n",
            "Epoch: 0058 loss_train: 0.2947 acc_train: 0.9500 loss_val: 0.3455 acc_val: 0.9200 time: 0.0184s\n",
            "Epoch: 0059 loss_train: 0.2977 acc_train: 0.9556 loss_val: 0.3451 acc_val: 0.9233 time: 0.0188s\n",
            "Epoch: 0060 loss_train: 0.2556 acc_train: 0.9556 loss_val: 0.3448 acc_val: 0.9167 time: 0.0178s\n",
            "Epoch: 0061 loss_train: 0.2812 acc_train: 0.9611 loss_val: 0.3444 acc_val: 0.9167 time: 0.0180s\n",
            "Epoch: 0062 loss_train: 0.2459 acc_train: 0.9722 loss_val: 0.3444 acc_val: 0.9200 time: 0.0217s\n",
            "Epoch: 0063 loss_train: 0.2706 acc_train: 0.9611 loss_val: 0.3457 acc_val: 0.9200 time: 0.0181s\n",
            "Epoch: 0064 loss_train: 0.2523 acc_train: 0.9611 loss_val: 0.3475 acc_val: 0.9200 time: 0.0177s\n",
            "Epoch: 0065 loss_train: 0.2755 acc_train: 0.9611 loss_val: 0.3493 acc_val: 0.9200 time: 0.0175s\n",
            "Epoch: 0066 loss_train: 0.2679 acc_train: 0.9667 loss_val: 0.3507 acc_val: 0.9200 time: 0.0169s\n",
            "Epoch: 0067 loss_train: 0.2504 acc_train: 0.9722 loss_val: 0.3509 acc_val: 0.9200 time: 0.0170s\n",
            "Epoch: 0068 loss_train: 0.2947 acc_train: 0.9556 loss_val: 0.3507 acc_val: 0.9200 time: 0.0188s\n",
            "Epoch: 0069 loss_train: 0.2639 acc_train: 0.9556 loss_val: 0.3498 acc_val: 0.9200 time: 0.0202s\n",
            "Epoch: 0070 loss_train: 0.2826 acc_train: 0.9667 loss_val: 0.3496 acc_val: 0.9233 time: 0.0180s\n",
            "Epoch: 0071 loss_train: 0.2686 acc_train: 0.9667 loss_val: 0.3495 acc_val: 0.9267 time: 0.0183s\n",
            "Epoch: 0072 loss_train: 0.2439 acc_train: 0.9833 loss_val: 0.3497 acc_val: 0.9300 time: 0.0208s\n",
            "Epoch: 0073 loss_train: 0.2624 acc_train: 0.9500 loss_val: 0.3484 acc_val: 0.9267 time: 0.0218s\n",
            "Epoch: 0074 loss_train: 0.2616 acc_train: 0.9667 loss_val: 0.3462 acc_val: 0.9267 time: 0.0188s\n",
            "Epoch: 0075 loss_train: 0.2770 acc_train: 0.9500 loss_val: 0.3450 acc_val: 0.9233 time: 0.0186s\n",
            "Epoch: 0076 loss_train: 0.2813 acc_train: 0.9611 loss_val: 0.3456 acc_val: 0.9200 time: 0.0196s\n",
            "Epoch: 0077 loss_train: 0.2452 acc_train: 0.9667 loss_val: 0.3475 acc_val: 0.9200 time: 0.0190s\n",
            "Epoch: 0078 loss_train: 0.2986 acc_train: 0.9611 loss_val: 0.3470 acc_val: 0.9200 time: 0.0191s\n",
            "Epoch: 0079 loss_train: 0.2838 acc_train: 0.9556 loss_val: 0.3453 acc_val: 0.9200 time: 0.0176s\n",
            "Epoch: 0080 loss_train: 0.2927 acc_train: 0.9556 loss_val: 0.3447 acc_val: 0.9200 time: 0.0173s\n",
            "Epoch: 0081 loss_train: 0.2904 acc_train: 0.9500 loss_val: 0.3468 acc_val: 0.9267 time: 0.0187s\n",
            "Epoch: 0082 loss_train: 0.2653 acc_train: 0.9722 loss_val: 0.3490 acc_val: 0.9233 time: 0.0214s\n",
            "Epoch: 0083 loss_train: 0.2565 acc_train: 0.9667 loss_val: 0.3495 acc_val: 0.9167 time: 0.0188s\n",
            "Epoch: 0084 loss_train: 0.2686 acc_train: 0.9611 loss_val: 0.3487 acc_val: 0.9233 time: 0.0177s\n",
            "Epoch: 0085 loss_train: 0.2895 acc_train: 0.9722 loss_val: 0.3490 acc_val: 0.9200 time: 0.0190s\n",
            "Epoch: 0086 loss_train: 0.2473 acc_train: 0.9667 loss_val: 0.3498 acc_val: 0.9167 time: 0.0186s\n",
            "Epoch: 0087 loss_train: 0.2717 acc_train: 0.9722 loss_val: 0.3502 acc_val: 0.9133 time: 0.0215s\n",
            "Epoch: 0088 loss_train: 0.2788 acc_train: 0.9611 loss_val: 0.3503 acc_val: 0.9133 time: 0.0181s\n",
            "Epoch: 0089 loss_train: 0.2302 acc_train: 0.9667 loss_val: 0.3495 acc_val: 0.9167 time: 0.0185s\n",
            "Epoch: 0090 loss_train: 0.2495 acc_train: 0.9444 loss_val: 0.3477 acc_val: 0.9200 time: 0.0185s\n",
            "Epoch: 0091 loss_train: 0.2599 acc_train: 0.9500 loss_val: 0.3458 acc_val: 0.9200 time: 0.0183s\n",
            "Epoch: 0092 loss_train: 0.2433 acc_train: 0.9778 loss_val: 0.3448 acc_val: 0.9233 time: 0.0219s\n",
            "Epoch: 0093 loss_train: 0.2547 acc_train: 0.9722 loss_val: 0.3448 acc_val: 0.9233 time: 0.0183s\n",
            "Epoch: 0094 loss_train: 0.2799 acc_train: 0.9389 loss_val: 0.3447 acc_val: 0.9300 time: 0.0180s\n",
            "Epoch: 0095 loss_train: 0.2769 acc_train: 0.9556 loss_val: 0.3449 acc_val: 0.9267 time: 0.0181s\n",
            "Epoch: 0096 loss_train: 0.2414 acc_train: 0.9500 loss_val: 0.3458 acc_val: 0.9233 time: 0.0211s\n",
            "Epoch: 0097 loss_train: 0.2611 acc_train: 0.9667 loss_val: 0.3472 acc_val: 0.9233 time: 0.0232s\n",
            "Epoch: 0098 loss_train: 0.2669 acc_train: 0.9667 loss_val: 0.3501 acc_val: 0.9133 time: 0.0205s\n",
            "Epoch: 0099 loss_train: 0.2957 acc_train: 0.9500 loss_val: 0.3531 acc_val: 0.9100 time: 0.0234s\n",
            "Epoch: 0100 loss_train: 0.2532 acc_train: 0.9667 loss_val: 0.3552 acc_val: 0.9033 time: 0.0224s\n",
            "Epoch: 0101 loss_train: 0.2725 acc_train: 0.9500 loss_val: 0.3564 acc_val: 0.9000 time: 0.0206s\n",
            "Epoch: 0102 loss_train: 0.2425 acc_train: 0.9722 loss_val: 0.3563 acc_val: 0.9000 time: 0.0191s\n",
            "Epoch: 0103 loss_train: 0.2732 acc_train: 0.9778 loss_val: 0.3551 acc_val: 0.9067 time: 0.0186s\n",
            "Epoch: 0104 loss_train: 0.2677 acc_train: 0.9667 loss_val: 0.3536 acc_val: 0.9100 time: 0.0189s\n",
            "Epoch: 0105 loss_train: 0.2801 acc_train: 0.9667 loss_val: 0.3516 acc_val: 0.9200 time: 0.0198s\n",
            "Epoch: 0106 loss_train: 0.2699 acc_train: 0.9667 loss_val: 0.3499 acc_val: 0.9200 time: 0.0191s\n",
            "Epoch: 0107 loss_train: 0.2540 acc_train: 0.9611 loss_val: 0.3480 acc_val: 0.9267 time: 0.0211s\n",
            "Epoch: 0108 loss_train: 0.2606 acc_train: 0.9611 loss_val: 0.3466 acc_val: 0.9267 time: 0.0183s\n",
            "Epoch: 0109 loss_train: 0.2938 acc_train: 0.9500 loss_val: 0.3458 acc_val: 0.9300 time: 0.0185s\n",
            "Epoch: 0110 loss_train: 0.2698 acc_train: 0.9722 loss_val: 0.3455 acc_val: 0.9300 time: 0.0188s\n",
            "Epoch: 0111 loss_train: 0.2250 acc_train: 0.9611 loss_val: 0.3461 acc_val: 0.9300 time: 0.0212s\n",
            "Epoch: 0112 loss_train: 0.2600 acc_train: 0.9611 loss_val: 0.3468 acc_val: 0.9300 time: 0.0200s\n",
            "Epoch: 0113 loss_train: 0.2552 acc_train: 0.9778 loss_val: 0.3476 acc_val: 0.9300 time: 0.0187s\n",
            "Epoch: 0114 loss_train: 0.2865 acc_train: 0.9611 loss_val: 0.3475 acc_val: 0.9267 time: 0.0195s\n",
            "Epoch: 0115 loss_train: 0.2612 acc_train: 0.9667 loss_val: 0.3470 acc_val: 0.9267 time: 0.0190s\n",
            "Epoch: 0116 loss_train: 0.2477 acc_train: 0.9722 loss_val: 0.3468 acc_val: 0.9233 time: 0.0193s\n",
            "Epoch: 0117 loss_train: 0.2412 acc_train: 0.9611 loss_val: 0.3468 acc_val: 0.9300 time: 0.0194s\n",
            "Epoch: 0118 loss_train: 0.2655 acc_train: 0.9667 loss_val: 0.3460 acc_val: 0.9267 time: 0.0195s\n",
            "Epoch: 0119 loss_train: 0.2445 acc_train: 0.9833 loss_val: 0.3454 acc_val: 0.9267 time: 0.0175s\n",
            "Epoch: 0120 loss_train: 0.2794 acc_train: 0.9556 loss_val: 0.3439 acc_val: 0.9267 time: 0.0183s\n",
            "Epoch: 0121 loss_train: 0.2620 acc_train: 0.9667 loss_val: 0.3432 acc_val: 0.9300 time: 0.0250s\n",
            "Epoch: 0122 loss_train: 0.2413 acc_train: 0.9722 loss_val: 0.3429 acc_val: 0.9300 time: 0.0182s\n",
            "Epoch: 0123 loss_train: 0.2849 acc_train: 0.9389 loss_val: 0.3429 acc_val: 0.9300 time: 0.0182s\n",
            "Epoch: 0124 loss_train: 0.2817 acc_train: 0.9500 loss_val: 0.3438 acc_val: 0.9300 time: 0.0180s\n",
            "Epoch: 0125 loss_train: 0.2568 acc_train: 0.9611 loss_val: 0.3445 acc_val: 0.9300 time: 0.0194s\n",
            "Epoch: 0126 loss_train: 0.2185 acc_train: 0.9778 loss_val: 0.3452 acc_val: 0.9267 time: 0.0201s\n",
            "Epoch: 0127 loss_train: 0.2619 acc_train: 0.9556 loss_val: 0.3465 acc_val: 0.9267 time: 0.0181s\n",
            "Epoch: 0128 loss_train: 0.2929 acc_train: 0.9500 loss_val: 0.3464 acc_val: 0.9233 time: 0.0177s\n",
            "Epoch: 0129 loss_train: 0.2567 acc_train: 0.9667 loss_val: 0.3454 acc_val: 0.9233 time: 0.0179s\n",
            "Epoch: 0130 loss_train: 0.2903 acc_train: 0.9667 loss_val: 0.3437 acc_val: 0.9233 time: 0.0191s\n",
            "Epoch: 0131 loss_train: 0.2575 acc_train: 0.9667 loss_val: 0.3414 acc_val: 0.9267 time: 0.0210s\n",
            "Epoch: 0132 loss_train: 0.2301 acc_train: 0.9556 loss_val: 0.3398 acc_val: 0.9300 time: 0.0196s\n",
            "Epoch: 0133 loss_train: 0.2711 acc_train: 0.9611 loss_val: 0.3392 acc_val: 0.9300 time: 0.0189s\n",
            "Epoch: 0134 loss_train: 0.2287 acc_train: 0.9667 loss_val: 0.3394 acc_val: 0.9267 time: 0.0183s\n",
            "Epoch: 0135 loss_train: 0.2620 acc_train: 0.9778 loss_val: 0.3394 acc_val: 0.9300 time: 0.0196s\n",
            "Epoch: 0136 loss_train: 0.2538 acc_train: 0.9556 loss_val: 0.3403 acc_val: 0.9300 time: 0.0192s\n",
            "Epoch: 0137 loss_train: 0.2849 acc_train: 0.9556 loss_val: 0.3415 acc_val: 0.9267 time: 0.0182s\n",
            "Epoch: 0138 loss_train: 0.2720 acc_train: 0.9722 loss_val: 0.3430 acc_val: 0.9267 time: 0.0182s\n",
            "Epoch: 0139 loss_train: 0.2796 acc_train: 0.9778 loss_val: 0.3440 acc_val: 0.9267 time: 0.0181s\n",
            "Epoch: 0140 loss_train: 0.2465 acc_train: 0.9667 loss_val: 0.3448 acc_val: 0.9267 time: 0.0183s\n",
            "Epoch: 0141 loss_train: 0.2467 acc_train: 0.9556 loss_val: 0.3453 acc_val: 0.9267 time: 0.0218s\n",
            "Epoch: 0142 loss_train: 0.2731 acc_train: 0.9444 loss_val: 0.3453 acc_val: 0.9267 time: 0.0182s\n",
            "Epoch: 0143 loss_train: 0.2330 acc_train: 0.9722 loss_val: 0.3456 acc_val: 0.9233 time: 0.0183s\n",
            "Epoch: 0144 loss_train: 0.2571 acc_train: 0.9556 loss_val: 0.3459 acc_val: 0.9233 time: 0.0187s\n",
            "Epoch: 0145 loss_train: 0.2550 acc_train: 0.9611 loss_val: 0.3461 acc_val: 0.9233 time: 0.0197s\n",
            "Epoch: 0146 loss_train: 0.2417 acc_train: 0.9611 loss_val: 0.3461 acc_val: 0.9233 time: 0.0278s\n",
            "Epoch: 0147 loss_train: 0.2718 acc_train: 0.9778 loss_val: 0.3455 acc_val: 0.9233 time: 0.0177s\n",
            "Epoch: 0148 loss_train: 0.2617 acc_train: 0.9722 loss_val: 0.3453 acc_val: 0.9300 time: 0.0182s\n",
            "Epoch: 0149 loss_train: 0.2306 acc_train: 0.9778 loss_val: 0.3451 acc_val: 0.9200 time: 0.0179s\n",
            "Epoch: 0150 loss_train: 0.2267 acc_train: 0.9722 loss_val: 0.3448 acc_val: 0.9200 time: 0.0182s\n",
            "Epoch: 0151 loss_train: 0.2545 acc_train: 0.9778 loss_val: 0.3448 acc_val: 0.9200 time: 0.0225s\n",
            "Epoch: 0152 loss_train: 0.2555 acc_train: 0.9667 loss_val: 0.3444 acc_val: 0.9200 time: 0.0184s\n",
            "Epoch: 0153 loss_train: 0.2536 acc_train: 0.9556 loss_val: 0.3442 acc_val: 0.9200 time: 0.0182s\n",
            "Epoch: 0154 loss_train: 0.2468 acc_train: 0.9556 loss_val: 0.3445 acc_val: 0.9133 time: 0.0180s\n",
            "Epoch: 0155 loss_train: 0.2401 acc_train: 0.9667 loss_val: 0.3448 acc_val: 0.9200 time: 0.0200s\n",
            "Epoch: 0156 loss_train: 0.2506 acc_train: 0.9667 loss_val: 0.3453 acc_val: 0.9100 time: 0.0235s\n",
            "Epoch: 0157 loss_train: 0.2527 acc_train: 0.9722 loss_val: 0.3467 acc_val: 0.9133 time: 0.0175s\n",
            "Epoch: 0158 loss_train: 0.2586 acc_train: 0.9722 loss_val: 0.3478 acc_val: 0.9133 time: 0.0180s\n",
            "Epoch: 0159 loss_train: 0.2499 acc_train: 0.9556 loss_val: 0.3477 acc_val: 0.9100 time: 0.0200s\n",
            "Epoch: 0160 loss_train: 0.2770 acc_train: 0.9722 loss_val: 0.3466 acc_val: 0.9200 time: 0.0174s\n",
            "Epoch: 0161 loss_train: 0.2540 acc_train: 0.9667 loss_val: 0.3453 acc_val: 0.9200 time: 0.0215s\n",
            "Epoch: 0162 loss_train: 0.2653 acc_train: 0.9500 loss_val: 0.3442 acc_val: 0.9200 time: 0.0186s\n",
            "Epoch: 0163 loss_train: 0.2355 acc_train: 0.9778 loss_val: 0.3450 acc_val: 0.9233 time: 0.0181s\n",
            "Epoch: 0164 loss_train: 0.2441 acc_train: 0.9667 loss_val: 0.3464 acc_val: 0.9233 time: 0.0181s\n",
            "Epoch: 0165 loss_train: 0.2409 acc_train: 0.9611 loss_val: 0.3473 acc_val: 0.9167 time: 0.0175s\n",
            "Epoch: 0166 loss_train: 0.2287 acc_train: 0.9722 loss_val: 0.3472 acc_val: 0.9200 time: 0.0210s\n",
            "Epoch: 0167 loss_train: 0.2540 acc_train: 0.9722 loss_val: 0.3456 acc_val: 0.9267 time: 0.0201s\n",
            "Epoch: 0168 loss_train: 0.2494 acc_train: 0.9833 loss_val: 0.3435 acc_val: 0.9300 time: 0.0181s\n",
            "Epoch: 0169 loss_train: 0.2295 acc_train: 0.9833 loss_val: 0.3425 acc_val: 0.9300 time: 0.0212s\n",
            "Epoch: 0170 loss_train: 0.2712 acc_train: 0.9778 loss_val: 0.3424 acc_val: 0.9300 time: 0.0213s\n",
            "Epoch: 0171 loss_train: 0.2690 acc_train: 0.9667 loss_val: 0.3427 acc_val: 0.9267 time: 0.0212s\n",
            "Epoch: 0172 loss_train: 0.2473 acc_train: 0.9556 loss_val: 0.3424 acc_val: 0.9267 time: 0.0194s\n",
            "Epoch: 0173 loss_train: 0.2448 acc_train: 0.9778 loss_val: 0.3427 acc_val: 0.9267 time: 0.0177s\n",
            "Epoch: 0174 loss_train: 0.2323 acc_train: 0.9722 loss_val: 0.3432 acc_val: 0.9167 time: 0.0177s\n",
            "Epoch: 0175 loss_train: 0.2516 acc_train: 0.9444 loss_val: 0.3440 acc_val: 0.9200 time: 0.0178s\n",
            "Epoch: 0176 loss_train: 0.2652 acc_train: 0.9611 loss_val: 0.3452 acc_val: 0.9200 time: 0.0190s\n",
            "Epoch: 0177 loss_train: 0.2633 acc_train: 0.9500 loss_val: 0.3446 acc_val: 0.9233 time: 0.0204s\n",
            "Epoch: 0178 loss_train: 0.2482 acc_train: 0.9722 loss_val: 0.3438 acc_val: 0.9233 time: 0.0199s\n",
            "Epoch: 0179 loss_train: 0.2302 acc_train: 0.9722 loss_val: 0.3435 acc_val: 0.9267 time: 0.0192s\n",
            "Epoch: 0180 loss_train: 0.2285 acc_train: 0.9722 loss_val: 0.3433 acc_val: 0.9267 time: 0.0180s\n",
            "Epoch: 0181 loss_train: 0.2578 acc_train: 0.9556 loss_val: 0.3434 acc_val: 0.9267 time: 0.0215s\n",
            "Epoch: 0182 loss_train: 0.2489 acc_train: 0.9611 loss_val: 0.3432 acc_val: 0.9267 time: 0.0172s\n",
            "Epoch: 0183 loss_train: 0.2399 acc_train: 0.9833 loss_val: 0.3425 acc_val: 0.9267 time: 0.0182s\n",
            "Epoch: 0184 loss_train: 0.2689 acc_train: 0.9667 loss_val: 0.3424 acc_val: 0.9300 time: 0.0185s\n",
            "Epoch: 0185 loss_train: 0.2494 acc_train: 0.9667 loss_val: 0.3436 acc_val: 0.9300 time: 0.0182s\n",
            "Epoch: 0186 loss_train: 0.2435 acc_train: 0.9500 loss_val: 0.3448 acc_val: 0.9300 time: 0.0182s\n",
            "Epoch: 0187 loss_train: 0.2696 acc_train: 0.9611 loss_val: 0.3456 acc_val: 0.9233 time: 0.0181s\n",
            "Epoch: 0188 loss_train: 0.2202 acc_train: 0.9833 loss_val: 0.3453 acc_val: 0.9233 time: 0.0177s\n",
            "Epoch: 0189 loss_train: 0.2401 acc_train: 0.9778 loss_val: 0.3437 acc_val: 0.9300 time: 0.0193s\n",
            "Epoch: 0190 loss_train: 0.2492 acc_train: 0.9611 loss_val: 0.3423 acc_val: 0.9300 time: 0.0184s\n",
            "Epoch: 0191 loss_train: 0.2402 acc_train: 0.9778 loss_val: 0.3421 acc_val: 0.9300 time: 0.0218s\n",
            "Epoch: 0192 loss_train: 0.2515 acc_train: 0.9667 loss_val: 0.3419 acc_val: 0.9267 time: 0.0187s\n",
            "Epoch: 0193 loss_train: 0.2481 acc_train: 0.9667 loss_val: 0.3415 acc_val: 0.9267 time: 0.0249s\n",
            "Epoch: 0194 loss_train: 0.2507 acc_train: 0.9611 loss_val: 0.3413 acc_val: 0.9233 time: 0.0179s\n",
            "Epoch: 0195 loss_train: 0.2502 acc_train: 0.9778 loss_val: 0.3408 acc_val: 0.9267 time: 0.0183s\n",
            "Epoch: 0196 loss_train: 0.2368 acc_train: 0.9722 loss_val: 0.3398 acc_val: 0.9300 time: 0.0195s\n",
            "Epoch: 0197 loss_train: 0.2563 acc_train: 0.9500 loss_val: 0.3402 acc_val: 0.9333 time: 0.0224s\n",
            "Epoch: 0198 loss_train: 0.2287 acc_train: 0.9833 loss_val: 0.3420 acc_val: 0.9233 time: 0.0183s\n",
            "Epoch: 0199 loss_train: 0.2444 acc_train: 0.9667 loss_val: 0.3435 acc_val: 0.9233 time: 0.0189s\n",
            "Epoch: 0200 loss_train: 0.2483 acc_train: 0.9778 loss_val: 0.3440 acc_val: 0.9167 time: 0.0187s\n",
            "After Completion of 180 labeled nodes\n",
            "Time taken: 4.5642s\n",
            "Test set results: loss= 0.6646 accuracy= 0.7870\n",
            "Epoch: 0001 loss_train: 0.4369 acc_train: 0.8958 loss_val: 0.3378 acc_val: 0.9233 time: 0.0206s\n",
            "Epoch: 0002 loss_train: 0.4230 acc_train: 0.8958 loss_val: 0.3298 acc_val: 0.9300 time: 0.0186s\n",
            "Epoch: 0003 loss_train: 0.3806 acc_train: 0.9125 loss_val: 0.3231 acc_val: 0.9267 time: 0.0184s\n",
            "Epoch: 0004 loss_train: 0.3794 acc_train: 0.9042 loss_val: 0.3184 acc_val: 0.9300 time: 0.0186s\n",
            "Epoch: 0005 loss_train: 0.3868 acc_train: 0.9042 loss_val: 0.3123 acc_val: 0.9433 time: 0.0189s\n",
            "Epoch: 0006 loss_train: 0.3792 acc_train: 0.9083 loss_val: 0.3042 acc_val: 0.9533 time: 0.0179s\n",
            "Epoch: 0007 loss_train: 0.3439 acc_train: 0.9333 loss_val: 0.2963 acc_val: 0.9533 time: 0.0207s\n",
            "Epoch: 0008 loss_train: 0.3768 acc_train: 0.9250 loss_val: 0.2886 acc_val: 0.9533 time: 0.0201s\n",
            "Epoch: 0009 loss_train: 0.3424 acc_train: 0.9375 loss_val: 0.2816 acc_val: 0.9533 time: 0.0186s\n",
            "Epoch: 0010 loss_train: 0.3389 acc_train: 0.9375 loss_val: 0.2758 acc_val: 0.9567 time: 0.0226s\n",
            "Epoch: 0011 loss_train: 0.3807 acc_train: 0.9292 loss_val: 0.2698 acc_val: 0.9567 time: 0.0184s\n",
            "Epoch: 0012 loss_train: 0.3239 acc_train: 0.9292 loss_val: 0.2647 acc_val: 0.9567 time: 0.0185s\n",
            "Epoch: 0013 loss_train: 0.3250 acc_train: 0.9500 loss_val: 0.2606 acc_val: 0.9633 time: 0.0203s\n",
            "Epoch: 0014 loss_train: 0.2952 acc_train: 0.9375 loss_val: 0.2585 acc_val: 0.9633 time: 0.0184s\n",
            "Epoch: 0015 loss_train: 0.2949 acc_train: 0.9625 loss_val: 0.2570 acc_val: 0.9633 time: 0.0180s\n",
            "Epoch: 0016 loss_train: 0.3097 acc_train: 0.9500 loss_val: 0.2551 acc_val: 0.9633 time: 0.0179s\n",
            "Epoch: 0017 loss_train: 0.3223 acc_train: 0.9417 loss_val: 0.2531 acc_val: 0.9667 time: 0.0197s\n",
            "Epoch: 0018 loss_train: 0.3223 acc_train: 0.9583 loss_val: 0.2513 acc_val: 0.9667 time: 0.0207s\n",
            "Epoch: 0019 loss_train: 0.2983 acc_train: 0.9417 loss_val: 0.2502 acc_val: 0.9667 time: 0.0181s\n",
            "Epoch: 0020 loss_train: 0.3187 acc_train: 0.9333 loss_val: 0.2499 acc_val: 0.9667 time: 0.0217s\n",
            "Epoch: 0021 loss_train: 0.2817 acc_train: 0.9625 loss_val: 0.2498 acc_val: 0.9667 time: 0.0187s\n",
            "Epoch: 0022 loss_train: 0.3006 acc_train: 0.9542 loss_val: 0.2497 acc_val: 0.9667 time: 0.0184s\n",
            "Epoch: 0023 loss_train: 0.2959 acc_train: 0.9458 loss_val: 0.2496 acc_val: 0.9667 time: 0.0197s\n",
            "Epoch: 0024 loss_train: 0.2892 acc_train: 0.9667 loss_val: 0.2492 acc_val: 0.9667 time: 0.0205s\n",
            "Epoch: 0025 loss_train: 0.3129 acc_train: 0.9542 loss_val: 0.2485 acc_val: 0.9667 time: 0.0200s\n",
            "Epoch: 0026 loss_train: 0.2682 acc_train: 0.9583 loss_val: 0.2479 acc_val: 0.9633 time: 0.0183s\n",
            "Epoch: 0027 loss_train: 0.2866 acc_train: 0.9458 loss_val: 0.2470 acc_val: 0.9633 time: 0.0177s\n",
            "Epoch: 0028 loss_train: 0.2908 acc_train: 0.9625 loss_val: 0.2463 acc_val: 0.9633 time: 0.0181s\n",
            "Epoch: 0029 loss_train: 0.2913 acc_train: 0.9667 loss_val: 0.2459 acc_val: 0.9633 time: 0.0184s\n",
            "Epoch: 0030 loss_train: 0.2746 acc_train: 0.9542 loss_val: 0.2457 acc_val: 0.9633 time: 0.0214s\n",
            "Epoch: 0031 loss_train: 0.2783 acc_train: 0.9583 loss_val: 0.2457 acc_val: 0.9633 time: 0.0176s\n",
            "Epoch: 0032 loss_train: 0.2657 acc_train: 0.9583 loss_val: 0.2461 acc_val: 0.9633 time: 0.0175s\n",
            "Epoch: 0033 loss_train: 0.2749 acc_train: 0.9625 loss_val: 0.2466 acc_val: 0.9667 time: 0.0183s\n",
            "Epoch: 0034 loss_train: 0.2890 acc_train: 0.9625 loss_val: 0.2467 acc_val: 0.9667 time: 0.0182s\n",
            "Epoch: 0035 loss_train: 0.2566 acc_train: 0.9708 loss_val: 0.2469 acc_val: 0.9667 time: 0.0196s\n",
            "Epoch: 0036 loss_train: 0.2947 acc_train: 0.9542 loss_val: 0.2464 acc_val: 0.9667 time: 0.0231s\n",
            "Epoch: 0037 loss_train: 0.3146 acc_train: 0.9625 loss_val: 0.2461 acc_val: 0.9667 time: 0.0194s\n",
            "Epoch: 0038 loss_train: 0.3241 acc_train: 0.9375 loss_val: 0.2465 acc_val: 0.9633 time: 0.0185s\n",
            "Epoch: 0039 loss_train: 0.2771 acc_train: 0.9625 loss_val: 0.2477 acc_val: 0.9633 time: 0.0247s\n",
            "Epoch: 0040 loss_train: 0.2801 acc_train: 0.9667 loss_val: 0.2488 acc_val: 0.9667 time: 0.0238s\n",
            "Epoch: 0041 loss_train: 0.2835 acc_train: 0.9375 loss_val: 0.2491 acc_val: 0.9667 time: 0.0193s\n",
            "Epoch: 0042 loss_train: 0.2616 acc_train: 0.9583 loss_val: 0.2484 acc_val: 0.9667 time: 0.0183s\n",
            "Epoch: 0043 loss_train: 0.2875 acc_train: 0.9625 loss_val: 0.2482 acc_val: 0.9633 time: 0.0181s\n",
            "Epoch: 0044 loss_train: 0.2678 acc_train: 0.9583 loss_val: 0.2490 acc_val: 0.9633 time: 0.0184s\n",
            "Epoch: 0045 loss_train: 0.3128 acc_train: 0.9458 loss_val: 0.2502 acc_val: 0.9667 time: 0.0181s\n",
            "Epoch: 0046 loss_train: 0.2765 acc_train: 0.9500 loss_val: 0.2502 acc_val: 0.9700 time: 0.0191s\n",
            "Epoch: 0047 loss_train: 0.3073 acc_train: 0.9292 loss_val: 0.2496 acc_val: 0.9700 time: 0.0181s\n",
            "Epoch: 0048 loss_train: 0.2806 acc_train: 0.9708 loss_val: 0.2493 acc_val: 0.9667 time: 0.0189s\n",
            "Epoch: 0049 loss_train: 0.2911 acc_train: 0.9458 loss_val: 0.2501 acc_val: 0.9667 time: 0.0294s\n",
            "Epoch: 0050 loss_train: 0.2750 acc_train: 0.9667 loss_val: 0.2505 acc_val: 0.9667 time: 0.0180s\n",
            "Epoch: 0051 loss_train: 0.3090 acc_train: 0.9542 loss_val: 0.2501 acc_val: 0.9667 time: 0.0192s\n",
            "Epoch: 0052 loss_train: 0.2712 acc_train: 0.9667 loss_val: 0.2493 acc_val: 0.9667 time: 0.0181s\n",
            "Epoch: 0053 loss_train: 0.2964 acc_train: 0.9542 loss_val: 0.2486 acc_val: 0.9667 time: 0.0180s\n",
            "Epoch: 0054 loss_train: 0.2783 acc_train: 0.9542 loss_val: 0.2484 acc_val: 0.9700 time: 0.0179s\n",
            "Epoch: 0055 loss_train: 0.2969 acc_train: 0.9542 loss_val: 0.2486 acc_val: 0.9700 time: 0.0191s\n",
            "Epoch: 0056 loss_train: 0.2841 acc_train: 0.9500 loss_val: 0.2487 acc_val: 0.9700 time: 0.0190s\n",
            "Epoch: 0057 loss_train: 0.3077 acc_train: 0.9458 loss_val: 0.2489 acc_val: 0.9633 time: 0.0182s\n",
            "Epoch: 0058 loss_train: 0.2582 acc_train: 0.9667 loss_val: 0.2486 acc_val: 0.9633 time: 0.0197s\n",
            "Epoch: 0059 loss_train: 0.2778 acc_train: 0.9667 loss_val: 0.2482 acc_val: 0.9667 time: 0.0211s\n",
            "Epoch: 0060 loss_train: 0.2611 acc_train: 0.9625 loss_val: 0.2479 acc_val: 0.9667 time: 0.0184s\n",
            "Epoch: 0061 loss_train: 0.2758 acc_train: 0.9542 loss_val: 0.2476 acc_val: 0.9667 time: 0.0183s\n",
            "Epoch: 0062 loss_train: 0.2686 acc_train: 0.9500 loss_val: 0.2474 acc_val: 0.9667 time: 0.0175s\n",
            "Epoch: 0063 loss_train: 0.2789 acc_train: 0.9542 loss_val: 0.2476 acc_val: 0.9667 time: 0.0190s\n",
            "Epoch: 0064 loss_train: 0.2621 acc_train: 0.9667 loss_val: 0.2475 acc_val: 0.9667 time: 0.0179s\n",
            "Epoch: 0065 loss_train: 0.2531 acc_train: 0.9583 loss_val: 0.2474 acc_val: 0.9667 time: 0.0169s\n",
            "Epoch: 0066 loss_train: 0.2897 acc_train: 0.9625 loss_val: 0.2477 acc_val: 0.9667 time: 0.0186s\n",
            "Epoch: 0067 loss_train: 0.2734 acc_train: 0.9667 loss_val: 0.2478 acc_val: 0.9667 time: 0.0188s\n",
            "Epoch: 0068 loss_train: 0.2645 acc_train: 0.9750 loss_val: 0.2476 acc_val: 0.9667 time: 0.0186s\n",
            "Epoch: 0069 loss_train: 0.2540 acc_train: 0.9750 loss_val: 0.2474 acc_val: 0.9667 time: 0.0243s\n",
            "Epoch: 0070 loss_train: 0.2573 acc_train: 0.9625 loss_val: 0.2472 acc_val: 0.9667 time: 0.0190s\n",
            "Epoch: 0071 loss_train: 0.2916 acc_train: 0.9625 loss_val: 0.2473 acc_val: 0.9667 time: 0.0192s\n",
            "Epoch: 0072 loss_train: 0.2652 acc_train: 0.9708 loss_val: 0.2475 acc_val: 0.9667 time: 0.0189s\n",
            "Epoch: 0073 loss_train: 0.2680 acc_train: 0.9667 loss_val: 0.2478 acc_val: 0.9667 time: 0.0189s\n",
            "Epoch: 0074 loss_train: 0.2583 acc_train: 0.9667 loss_val: 0.2483 acc_val: 0.9667 time: 0.0181s\n",
            "Epoch: 0075 loss_train: 0.2830 acc_train: 0.9625 loss_val: 0.2481 acc_val: 0.9667 time: 0.0181s\n",
            "Epoch: 0076 loss_train: 0.2667 acc_train: 0.9583 loss_val: 0.2479 acc_val: 0.9667 time: 0.0192s\n",
            "Epoch: 0077 loss_train: 0.2544 acc_train: 0.9708 loss_val: 0.2478 acc_val: 0.9667 time: 0.0174s\n",
            "Epoch: 0078 loss_train: 0.2783 acc_train: 0.9583 loss_val: 0.2478 acc_val: 0.9667 time: 0.0175s\n",
            "Epoch: 0079 loss_train: 0.2967 acc_train: 0.9667 loss_val: 0.2477 acc_val: 0.9700 time: 0.0228s\n",
            "Epoch: 0080 loss_train: 0.2670 acc_train: 0.9667 loss_val: 0.2475 acc_val: 0.9700 time: 0.0185s\n",
            "Epoch: 0081 loss_train: 0.2730 acc_train: 0.9667 loss_val: 0.2471 acc_val: 0.9700 time: 0.0182s\n",
            "Epoch: 0082 loss_train: 0.2787 acc_train: 0.9667 loss_val: 0.2468 acc_val: 0.9700 time: 0.0182s\n",
            "Epoch: 0083 loss_train: 0.2807 acc_train: 0.9542 loss_val: 0.2466 acc_val: 0.9667 time: 0.0181s\n",
            "Epoch: 0084 loss_train: 0.2740 acc_train: 0.9667 loss_val: 0.2466 acc_val: 0.9600 time: 0.0183s\n",
            "Epoch: 0085 loss_train: 0.2752 acc_train: 0.9500 loss_val: 0.2466 acc_val: 0.9633 time: 0.0178s\n",
            "Epoch: 0086 loss_train: 0.2855 acc_train: 0.9750 loss_val: 0.2466 acc_val: 0.9633 time: 0.0245s\n",
            "Epoch: 0087 loss_train: 0.2798 acc_train: 0.9625 loss_val: 0.2464 acc_val: 0.9633 time: 0.0212s\n",
            "Epoch: 0088 loss_train: 0.2694 acc_train: 0.9625 loss_val: 0.2462 acc_val: 0.9667 time: 0.0192s\n",
            "Epoch: 0089 loss_train: 0.2584 acc_train: 0.9625 loss_val: 0.2462 acc_val: 0.9667 time: 0.0239s\n",
            "Epoch: 0090 loss_train: 0.2894 acc_train: 0.9667 loss_val: 0.2459 acc_val: 0.9667 time: 0.0189s\n",
            "Epoch: 0091 loss_train: 0.2565 acc_train: 0.9625 loss_val: 0.2456 acc_val: 0.9700 time: 0.0186s\n",
            "Epoch: 0092 loss_train: 0.2688 acc_train: 0.9542 loss_val: 0.2451 acc_val: 0.9667 time: 0.0183s\n",
            "Epoch: 0093 loss_train: 0.2730 acc_train: 0.9625 loss_val: 0.2451 acc_val: 0.9700 time: 0.0183s\n",
            "Epoch: 0094 loss_train: 0.3010 acc_train: 0.9292 loss_val: 0.2456 acc_val: 0.9667 time: 0.0179s\n",
            "Epoch: 0095 loss_train: 0.2542 acc_train: 0.9625 loss_val: 0.2456 acc_val: 0.9700 time: 0.0185s\n",
            "Epoch: 0096 loss_train: 0.2851 acc_train: 0.9667 loss_val: 0.2456 acc_val: 0.9700 time: 0.0201s\n",
            "Epoch: 0097 loss_train: 0.2633 acc_train: 0.9625 loss_val: 0.2455 acc_val: 0.9700 time: 0.0179s\n",
            "Epoch: 0098 loss_train: 0.2800 acc_train: 0.9708 loss_val: 0.2449 acc_val: 0.9700 time: 0.0212s\n",
            "Epoch: 0099 loss_train: 0.2928 acc_train: 0.9667 loss_val: 0.2442 acc_val: 0.9700 time: 0.0187s\n",
            "Epoch: 0100 loss_train: 0.2742 acc_train: 0.9583 loss_val: 0.2444 acc_val: 0.9700 time: 0.0179s\n",
            "Epoch: 0101 loss_train: 0.2738 acc_train: 0.9542 loss_val: 0.2450 acc_val: 0.9667 time: 0.0187s\n",
            "Epoch: 0102 loss_train: 0.2840 acc_train: 0.9458 loss_val: 0.2461 acc_val: 0.9667 time: 0.0177s\n",
            "Epoch: 0103 loss_train: 0.2768 acc_train: 0.9583 loss_val: 0.2475 acc_val: 0.9667 time: 0.0179s\n",
            "Epoch: 0104 loss_train: 0.2781 acc_train: 0.9625 loss_val: 0.2475 acc_val: 0.9667 time: 0.0175s\n",
            "Epoch: 0105 loss_train: 0.2919 acc_train: 0.9625 loss_val: 0.2470 acc_val: 0.9667 time: 0.0215s\n",
            "Epoch: 0106 loss_train: 0.2755 acc_train: 0.9542 loss_val: 0.2466 acc_val: 0.9667 time: 0.0171s\n",
            "Epoch: 0107 loss_train: 0.2896 acc_train: 0.9750 loss_val: 0.2466 acc_val: 0.9667 time: 0.0194s\n",
            "Epoch: 0108 loss_train: 0.2824 acc_train: 0.9708 loss_val: 0.2466 acc_val: 0.9667 time: 0.0217s\n",
            "Epoch: 0109 loss_train: 0.2679 acc_train: 0.9542 loss_val: 0.2467 acc_val: 0.9667 time: 0.0190s\n",
            "Epoch: 0110 loss_train: 0.3076 acc_train: 0.9333 loss_val: 0.2464 acc_val: 0.9700 time: 0.0178s\n",
            "Epoch: 0111 loss_train: 0.2821 acc_train: 0.9500 loss_val: 0.2460 acc_val: 0.9700 time: 0.0174s\n",
            "Epoch: 0112 loss_train: 0.2711 acc_train: 0.9542 loss_val: 0.2454 acc_val: 0.9700 time: 0.0177s\n",
            "Epoch: 0113 loss_train: 0.2663 acc_train: 0.9542 loss_val: 0.2447 acc_val: 0.9700 time: 0.0172s\n",
            "Epoch: 0114 loss_train: 0.2804 acc_train: 0.9708 loss_val: 0.2440 acc_val: 0.9700 time: 0.0171s\n",
            "Epoch: 0115 loss_train: 0.2694 acc_train: 0.9708 loss_val: 0.2432 acc_val: 0.9700 time: 0.0187s\n",
            "Epoch: 0116 loss_train: 0.3009 acc_train: 0.9750 loss_val: 0.2428 acc_val: 0.9700 time: 0.0195s\n",
            "Epoch: 0117 loss_train: 0.2702 acc_train: 0.9500 loss_val: 0.2426 acc_val: 0.9700 time: 0.0190s\n",
            "Epoch: 0118 loss_train: 0.2980 acc_train: 0.9583 loss_val: 0.2422 acc_val: 0.9700 time: 0.0212s\n",
            "Epoch: 0119 loss_train: 0.2936 acc_train: 0.9583 loss_val: 0.2424 acc_val: 0.9700 time: 0.0178s\n",
            "Epoch: 0120 loss_train: 0.2657 acc_train: 0.9625 loss_val: 0.2429 acc_val: 0.9733 time: 0.0204s\n",
            "Epoch: 0121 loss_train: 0.2638 acc_train: 0.9542 loss_val: 0.2432 acc_val: 0.9733 time: 0.0178s\n",
            "Epoch: 0122 loss_train: 0.2489 acc_train: 0.9708 loss_val: 0.2432 acc_val: 0.9700 time: 0.0181s\n",
            "Epoch: 0123 loss_train: 0.3010 acc_train: 0.9375 loss_val: 0.2433 acc_val: 0.9633 time: 0.0177s\n",
            "Epoch: 0124 loss_train: 0.2649 acc_train: 0.9708 loss_val: 0.2438 acc_val: 0.9667 time: 0.0185s\n",
            "Epoch: 0125 loss_train: 0.2555 acc_train: 0.9667 loss_val: 0.2440 acc_val: 0.9667 time: 0.0192s\n",
            "Epoch: 0126 loss_train: 0.2812 acc_train: 0.9667 loss_val: 0.2434 acc_val: 0.9667 time: 0.0185s\n",
            "Epoch: 0127 loss_train: 0.2892 acc_train: 0.9500 loss_val: 0.2425 acc_val: 0.9667 time: 0.0177s\n",
            "Epoch: 0128 loss_train: 0.2767 acc_train: 0.9667 loss_val: 0.2421 acc_val: 0.9667 time: 0.0204s\n",
            "Epoch: 0129 loss_train: 0.2804 acc_train: 0.9667 loss_val: 0.2421 acc_val: 0.9733 time: 0.0184s\n",
            "Epoch: 0130 loss_train: 0.3038 acc_train: 0.9500 loss_val: 0.2421 acc_val: 0.9700 time: 0.0177s\n",
            "Epoch: 0131 loss_train: 0.2704 acc_train: 0.9583 loss_val: 0.2419 acc_val: 0.9700 time: 0.0173s\n",
            "Epoch: 0132 loss_train: 0.2977 acc_train: 0.9500 loss_val: 0.2416 acc_val: 0.9700 time: 0.0176s\n",
            "Epoch: 0133 loss_train: 0.2309 acc_train: 0.9750 loss_val: 0.2413 acc_val: 0.9667 time: 0.0173s\n",
            "Epoch: 0134 loss_train: 0.2625 acc_train: 0.9583 loss_val: 0.2424 acc_val: 0.9600 time: 0.0246s\n",
            "Epoch: 0135 loss_train: 0.2500 acc_train: 0.9708 loss_val: 0.2438 acc_val: 0.9600 time: 0.0200s\n",
            "Epoch: 0136 loss_train: 0.2880 acc_train: 0.9625 loss_val: 0.2440 acc_val: 0.9600 time: 0.0174s\n",
            "Epoch: 0137 loss_train: 0.2504 acc_train: 0.9500 loss_val: 0.2432 acc_val: 0.9633 time: 0.0188s\n",
            "Epoch: 0138 loss_train: 0.2909 acc_train: 0.9667 loss_val: 0.2418 acc_val: 0.9667 time: 0.0205s\n",
            "Epoch: 0139 loss_train: 0.2550 acc_train: 0.9583 loss_val: 0.2417 acc_val: 0.9700 time: 0.0178s\n",
            "Epoch: 0140 loss_train: 0.2672 acc_train: 0.9625 loss_val: 0.2423 acc_val: 0.9700 time: 0.0174s\n",
            "Epoch: 0141 loss_train: 0.2453 acc_train: 0.9792 loss_val: 0.2428 acc_val: 0.9733 time: 0.0173s\n",
            "Epoch: 0142 loss_train: 0.2685 acc_train: 0.9625 loss_val: 0.2427 acc_val: 0.9733 time: 0.0167s\n",
            "Epoch: 0143 loss_train: 0.3044 acc_train: 0.9458 loss_val: 0.2421 acc_val: 0.9733 time: 0.0173s\n",
            "Epoch: 0144 loss_train: 0.2906 acc_train: 0.9625 loss_val: 0.2420 acc_val: 0.9700 time: 0.0171s\n",
            "Epoch: 0145 loss_train: 0.2623 acc_train: 0.9458 loss_val: 0.2421 acc_val: 0.9667 time: 0.0173s\n",
            "Epoch: 0146 loss_train: 0.2788 acc_train: 0.9667 loss_val: 0.2422 acc_val: 0.9667 time: 0.0203s\n",
            "Epoch: 0147 loss_train: 0.2709 acc_train: 0.9708 loss_val: 0.2416 acc_val: 0.9667 time: 0.0196s\n",
            "Epoch: 0148 loss_train: 0.2545 acc_train: 0.9625 loss_val: 0.2409 acc_val: 0.9667 time: 0.0186s\n",
            "Epoch: 0149 loss_train: 0.2845 acc_train: 0.9667 loss_val: 0.2403 acc_val: 0.9700 time: 0.0219s\n",
            "Epoch: 0150 loss_train: 0.2696 acc_train: 0.9625 loss_val: 0.2401 acc_val: 0.9700 time: 0.0179s\n",
            "Epoch: 0151 loss_train: 0.2966 acc_train: 0.9583 loss_val: 0.2402 acc_val: 0.9700 time: 0.0183s\n",
            "Epoch: 0152 loss_train: 0.2936 acc_train: 0.9458 loss_val: 0.2406 acc_val: 0.9667 time: 0.0192s\n",
            "Epoch: 0153 loss_train: 0.2657 acc_train: 0.9708 loss_val: 0.2411 acc_val: 0.9667 time: 0.0179s\n",
            "Epoch: 0154 loss_train: 0.2951 acc_train: 0.9542 loss_val: 0.2410 acc_val: 0.9667 time: 0.0182s\n",
            "Epoch: 0155 loss_train: 0.3293 acc_train: 0.9542 loss_val: 0.2408 acc_val: 0.9667 time: 0.0175s\n",
            "Epoch: 0156 loss_train: 0.2858 acc_train: 0.9542 loss_val: 0.2410 acc_val: 0.9633 time: 0.0192s\n",
            "Epoch: 0157 loss_train: 0.2449 acc_train: 0.9583 loss_val: 0.2412 acc_val: 0.9633 time: 0.0191s\n",
            "Epoch: 0158 loss_train: 0.2589 acc_train: 0.9625 loss_val: 0.2413 acc_val: 0.9633 time: 0.0207s\n",
            "Epoch: 0159 loss_train: 0.2925 acc_train: 0.9667 loss_val: 0.2415 acc_val: 0.9667 time: 0.0182s\n",
            "Epoch: 0160 loss_train: 0.2311 acc_train: 0.9792 loss_val: 0.2412 acc_val: 0.9667 time: 0.0178s\n",
            "Epoch: 0161 loss_train: 0.2456 acc_train: 0.9708 loss_val: 0.2408 acc_val: 0.9633 time: 0.0181s\n",
            "Epoch: 0162 loss_train: 0.2616 acc_train: 0.9500 loss_val: 0.2399 acc_val: 0.9633 time: 0.0191s\n",
            "Epoch: 0163 loss_train: 0.2897 acc_train: 0.9667 loss_val: 0.2388 acc_val: 0.9633 time: 0.0186s\n",
            "Epoch: 0164 loss_train: 0.2738 acc_train: 0.9583 loss_val: 0.2381 acc_val: 0.9667 time: 0.0195s\n",
            "Epoch: 0165 loss_train: 0.2862 acc_train: 0.9583 loss_val: 0.2380 acc_val: 0.9733 time: 0.0191s\n",
            "Epoch: 0166 loss_train: 0.2477 acc_train: 0.9792 loss_val: 0.2383 acc_val: 0.9767 time: 0.0183s\n",
            "Epoch: 0167 loss_train: 0.2491 acc_train: 0.9583 loss_val: 0.2387 acc_val: 0.9733 time: 0.0179s\n",
            "Epoch: 0168 loss_train: 0.2557 acc_train: 0.9625 loss_val: 0.2387 acc_val: 0.9733 time: 0.0232s\n",
            "Epoch: 0169 loss_train: 0.2431 acc_train: 0.9583 loss_val: 0.2387 acc_val: 0.9733 time: 0.0179s\n",
            "Epoch: 0170 loss_train: 0.2704 acc_train: 0.9542 loss_val: 0.2389 acc_val: 0.9700 time: 0.0178s\n",
            "Epoch: 0171 loss_train: 0.2669 acc_train: 0.9542 loss_val: 0.2390 acc_val: 0.9700 time: 0.0180s\n",
            "Epoch: 0172 loss_train: 0.2838 acc_train: 0.9667 loss_val: 0.2392 acc_val: 0.9700 time: 0.0174s\n",
            "Epoch: 0173 loss_train: 0.2852 acc_train: 0.9583 loss_val: 0.2395 acc_val: 0.9700 time: 0.0176s\n",
            "Epoch: 0174 loss_train: 0.2840 acc_train: 0.9583 loss_val: 0.2397 acc_val: 0.9700 time: 0.0173s\n",
            "Epoch: 0175 loss_train: 0.2579 acc_train: 0.9708 loss_val: 0.2401 acc_val: 0.9700 time: 0.0182s\n",
            "Epoch: 0176 loss_train: 0.2621 acc_train: 0.9708 loss_val: 0.2403 acc_val: 0.9700 time: 0.0179s\n",
            "Epoch: 0177 loss_train: 0.2579 acc_train: 0.9750 loss_val: 0.2401 acc_val: 0.9700 time: 0.0176s\n",
            "Epoch: 0178 loss_train: 0.2595 acc_train: 0.9542 loss_val: 0.2398 acc_val: 0.9633 time: 0.0182s\n",
            "Epoch: 0179 loss_train: 0.2730 acc_train: 0.9667 loss_val: 0.2395 acc_val: 0.9633 time: 0.0250s\n",
            "Epoch: 0180 loss_train: 0.2553 acc_train: 0.9708 loss_val: 0.2393 acc_val: 0.9633 time: 0.0176s\n",
            "Epoch: 0181 loss_train: 0.2515 acc_train: 0.9708 loss_val: 0.2393 acc_val: 0.9633 time: 0.0177s\n",
            "Epoch: 0182 loss_train: 0.2550 acc_train: 0.9625 loss_val: 0.2393 acc_val: 0.9633 time: 0.0219s\n",
            "Epoch: 0183 loss_train: 0.2558 acc_train: 0.9708 loss_val: 0.2394 acc_val: 0.9667 time: 0.0210s\n",
            "Epoch: 0184 loss_train: 0.2648 acc_train: 0.9667 loss_val: 0.2393 acc_val: 0.9667 time: 0.0176s\n",
            "Epoch: 0185 loss_train: 0.2798 acc_train: 0.9500 loss_val: 0.2395 acc_val: 0.9667 time: 0.0176s\n",
            "Epoch: 0186 loss_train: 0.2718 acc_train: 0.9792 loss_val: 0.2396 acc_val: 0.9667 time: 0.0177s\n",
            "Epoch: 0187 loss_train: 0.2628 acc_train: 0.9750 loss_val: 0.2396 acc_val: 0.9667 time: 0.0188s\n",
            "Epoch: 0188 loss_train: 0.2697 acc_train: 0.9667 loss_val: 0.2397 acc_val: 0.9667 time: 0.0213s\n",
            "Epoch: 0189 loss_train: 0.2768 acc_train: 0.9583 loss_val: 0.2400 acc_val: 0.9667 time: 0.0209s\n",
            "Epoch: 0190 loss_train: 0.2559 acc_train: 0.9667 loss_val: 0.2408 acc_val: 0.9667 time: 0.0220s\n",
            "Epoch: 0191 loss_train: 0.2881 acc_train: 0.9625 loss_val: 0.2411 acc_val: 0.9633 time: 0.0207s\n",
            "Epoch: 0192 loss_train: 0.2460 acc_train: 0.9792 loss_val: 0.2406 acc_val: 0.9633 time: 0.0190s\n",
            "Epoch: 0193 loss_train: 0.2657 acc_train: 0.9667 loss_val: 0.2395 acc_val: 0.9633 time: 0.0192s\n",
            "Epoch: 0194 loss_train: 0.2551 acc_train: 0.9583 loss_val: 0.2386 acc_val: 0.9667 time: 0.0185s\n",
            "Epoch: 0195 loss_train: 0.2555 acc_train: 0.9708 loss_val: 0.2384 acc_val: 0.9667 time: 0.0190s\n",
            "Epoch: 0196 loss_train: 0.2623 acc_train: 0.9667 loss_val: 0.2386 acc_val: 0.9667 time: 0.0189s\n",
            "Epoch: 0197 loss_train: 0.2786 acc_train: 0.9542 loss_val: 0.2392 acc_val: 0.9667 time: 0.0184s\n",
            "Epoch: 0198 loss_train: 0.2680 acc_train: 0.9583 loss_val: 0.2393 acc_val: 0.9667 time: 0.0254s\n",
            "Epoch: 0199 loss_train: 0.2599 acc_train: 0.9625 loss_val: 0.2394 acc_val: 0.9633 time: 0.0177s\n",
            "Epoch: 0200 loss_train: 0.2596 acc_train: 0.9542 loss_val: 0.2391 acc_val: 0.9633 time: 0.0195s\n",
            "After Completion of 240 labeled nodes\n",
            "Time taken: 4.3290s\n",
            "Test set results: loss= 0.5481 accuracy= 0.8230\n",
            "Epoch: 0001 loss_train: 0.3462 acc_train: 0.9300 loss_val: 0.2379 acc_val: 0.9667 time: 0.0200s\n",
            "Epoch: 0002 loss_train: 0.3012 acc_train: 0.9600 loss_val: 0.2358 acc_val: 0.9700 time: 0.0184s\n",
            "Epoch: 0003 loss_train: 0.2899 acc_train: 0.9533 loss_val: 0.2333 acc_val: 0.9733 time: 0.0189s\n",
            "Epoch: 0004 loss_train: 0.2991 acc_train: 0.9600 loss_val: 0.2304 acc_val: 0.9733 time: 0.0183s\n",
            "Epoch: 0005 loss_train: 0.3102 acc_train: 0.9500 loss_val: 0.2273 acc_val: 0.9700 time: 0.0175s\n",
            "Epoch: 0006 loss_train: 0.2740 acc_train: 0.9600 loss_val: 0.2237 acc_val: 0.9667 time: 0.0169s\n",
            "Epoch: 0007 loss_train: 0.3057 acc_train: 0.9367 loss_val: 0.2202 acc_val: 0.9667 time: 0.0167s\n",
            "Epoch: 0008 loss_train: 0.3024 acc_train: 0.9467 loss_val: 0.2173 acc_val: 0.9700 time: 0.0226s\n",
            "Epoch: 0009 loss_train: 0.2852 acc_train: 0.9500 loss_val: 0.2150 acc_val: 0.9800 time: 0.0190s\n",
            "Epoch: 0010 loss_train: 0.2863 acc_train: 0.9400 loss_val: 0.2132 acc_val: 0.9767 time: 0.0184s\n",
            "Epoch: 0011 loss_train: 0.3167 acc_train: 0.9233 loss_val: 0.2120 acc_val: 0.9767 time: 0.0191s\n",
            "Epoch: 0012 loss_train: 0.2963 acc_train: 0.9467 loss_val: 0.2110 acc_val: 0.9733 time: 0.0171s\n",
            "Epoch: 0013 loss_train: 0.2745 acc_train: 0.9500 loss_val: 0.2098 acc_val: 0.9767 time: 0.0172s\n",
            "Epoch: 0014 loss_train: 0.2888 acc_train: 0.9467 loss_val: 0.2081 acc_val: 0.9700 time: 0.0174s\n",
            "Epoch: 0015 loss_train: 0.3040 acc_train: 0.9367 loss_val: 0.2068 acc_val: 0.9700 time: 0.0173s\n",
            "Epoch: 0016 loss_train: 0.2921 acc_train: 0.9467 loss_val: 0.2061 acc_val: 0.9667 time: 0.0178s\n",
            "Epoch: 0017 loss_train: 0.3306 acc_train: 0.9300 loss_val: 0.2058 acc_val: 0.9667 time: 0.0167s\n",
            "Epoch: 0018 loss_train: 0.2976 acc_train: 0.9500 loss_val: 0.2061 acc_val: 0.9667 time: 0.0192s\n",
            "Epoch: 0019 loss_train: 0.2990 acc_train: 0.9467 loss_val: 0.2065 acc_val: 0.9700 time: 0.0197s\n",
            "Epoch: 0020 loss_train: 0.3016 acc_train: 0.9433 loss_val: 0.2065 acc_val: 0.9733 time: 0.0174s\n",
            "Epoch: 0021 loss_train: 0.2970 acc_train: 0.9400 loss_val: 0.2059 acc_val: 0.9733 time: 0.0198s\n",
            "Epoch: 0022 loss_train: 0.2737 acc_train: 0.9600 loss_val: 0.2052 acc_val: 0.9700 time: 0.0167s\n",
            "Epoch: 0023 loss_train: 0.2751 acc_train: 0.9633 loss_val: 0.2046 acc_val: 0.9700 time: 0.0171s\n",
            "Epoch: 0024 loss_train: 0.2605 acc_train: 0.9500 loss_val: 0.2039 acc_val: 0.9667 time: 0.0176s\n",
            "Epoch: 0025 loss_train: 0.2890 acc_train: 0.9600 loss_val: 0.2030 acc_val: 0.9633 time: 0.0170s\n",
            "Epoch: 0026 loss_train: 0.2615 acc_train: 0.9667 loss_val: 0.2023 acc_val: 0.9700 time: 0.0170s\n",
            "Epoch: 0027 loss_train: 0.2713 acc_train: 0.9367 loss_val: 0.2016 acc_val: 0.9700 time: 0.0166s\n",
            "Epoch: 0028 loss_train: 0.2588 acc_train: 0.9633 loss_val: 0.2017 acc_val: 0.9700 time: 0.0171s\n",
            "Epoch: 0029 loss_train: 0.2998 acc_train: 0.9500 loss_val: 0.2021 acc_val: 0.9733 time: 0.0226s\n",
            "Epoch: 0030 loss_train: 0.2754 acc_train: 0.9600 loss_val: 0.2023 acc_val: 0.9667 time: 0.0241s\n",
            "Epoch: 0031 loss_train: 0.2618 acc_train: 0.9567 loss_val: 0.2023 acc_val: 0.9700 time: 0.0186s\n",
            "Epoch: 0032 loss_train: 0.2732 acc_train: 0.9567 loss_val: 0.2022 acc_val: 0.9700 time: 0.0178s\n",
            "Epoch: 0033 loss_train: 0.2627 acc_train: 0.9433 loss_val: 0.2024 acc_val: 0.9733 time: 0.0182s\n",
            "Epoch: 0034 loss_train: 0.2873 acc_train: 0.9433 loss_val: 0.2029 acc_val: 0.9733 time: 0.0176s\n",
            "Epoch: 0035 loss_train: 0.2767 acc_train: 0.9367 loss_val: 0.2031 acc_val: 0.9767 time: 0.0174s\n",
            "Epoch: 0036 loss_train: 0.2719 acc_train: 0.9433 loss_val: 0.2033 acc_val: 0.9767 time: 0.0167s\n",
            "Epoch: 0037 loss_train: 0.2897 acc_train: 0.9533 loss_val: 0.2033 acc_val: 0.9833 time: 0.0173s\n",
            "Epoch: 0038 loss_train: 0.2750 acc_train: 0.9467 loss_val: 0.2037 acc_val: 0.9767 time: 0.0175s\n",
            "Epoch: 0039 loss_train: 0.2661 acc_train: 0.9500 loss_val: 0.2040 acc_val: 0.9733 time: 0.0206s\n",
            "Epoch: 0040 loss_train: 0.2913 acc_train: 0.9533 loss_val: 0.2044 acc_val: 0.9767 time: 0.0173s\n",
            "Epoch: 0041 loss_train: 0.2817 acc_train: 0.9567 loss_val: 0.2044 acc_val: 0.9767 time: 0.0166s\n",
            "Epoch: 0042 loss_train: 0.2581 acc_train: 0.9500 loss_val: 0.2044 acc_val: 0.9767 time: 0.0172s\n",
            "Epoch: 0043 loss_train: 0.2840 acc_train: 0.9500 loss_val: 0.2044 acc_val: 0.9767 time: 0.0196s\n",
            "Epoch: 0044 loss_train: 0.2820 acc_train: 0.9500 loss_val: 0.2047 acc_val: 0.9767 time: 0.0193s\n",
            "Epoch: 0045 loss_train: 0.2686 acc_train: 0.9600 loss_val: 0.2056 acc_val: 0.9800 time: 0.0173s\n",
            "Epoch: 0046 loss_train: 0.2992 acc_train: 0.9567 loss_val: 0.2066 acc_val: 0.9800 time: 0.0192s\n",
            "Epoch: 0047 loss_train: 0.2735 acc_train: 0.9700 loss_val: 0.2067 acc_val: 0.9800 time: 0.0169s\n",
            "Epoch: 0048 loss_train: 0.2854 acc_train: 0.9533 loss_val: 0.2064 acc_val: 0.9833 time: 0.0187s\n",
            "Epoch: 0049 loss_train: 0.2937 acc_train: 0.9533 loss_val: 0.2062 acc_val: 0.9833 time: 0.0211s\n",
            "Epoch: 0050 loss_train: 0.2950 acc_train: 0.9333 loss_val: 0.2054 acc_val: 0.9767 time: 0.0175s\n",
            "Epoch: 0051 loss_train: 0.2685 acc_train: 0.9633 loss_val: 0.2045 acc_val: 0.9767 time: 0.0180s\n",
            "Epoch: 0052 loss_train: 0.2906 acc_train: 0.9467 loss_val: 0.2044 acc_val: 0.9767 time: 0.0183s\n",
            "Epoch: 0053 loss_train: 0.2811 acc_train: 0.9700 loss_val: 0.2042 acc_val: 0.9800 time: 0.0178s\n",
            "Epoch: 0054 loss_train: 0.2614 acc_train: 0.9633 loss_val: 0.2039 acc_val: 0.9800 time: 0.0200s\n",
            "Epoch: 0055 loss_train: 0.2648 acc_train: 0.9567 loss_val: 0.2027 acc_val: 0.9733 time: 0.0201s\n",
            "Epoch: 0056 loss_train: 0.2735 acc_train: 0.9700 loss_val: 0.2021 acc_val: 0.9700 time: 0.0188s\n",
            "Epoch: 0057 loss_train: 0.2858 acc_train: 0.9467 loss_val: 0.2030 acc_val: 0.9700 time: 0.0181s\n",
            "Epoch: 0058 loss_train: 0.2557 acc_train: 0.9567 loss_val: 0.2047 acc_val: 0.9633 time: 0.0180s\n",
            "Epoch: 0059 loss_train: 0.2674 acc_train: 0.9467 loss_val: 0.2049 acc_val: 0.9667 time: 0.0218s\n",
            "Epoch: 0060 loss_train: 0.2766 acc_train: 0.9467 loss_val: 0.2036 acc_val: 0.9733 time: 0.0189s\n",
            "Epoch: 0061 loss_train: 0.2930 acc_train: 0.9400 loss_val: 0.2017 acc_val: 0.9733 time: 0.0179s\n",
            "Epoch: 0062 loss_train: 0.2578 acc_train: 0.9467 loss_val: 0.2012 acc_val: 0.9733 time: 0.0211s\n",
            "Epoch: 0063 loss_train: 0.3122 acc_train: 0.9333 loss_val: 0.2020 acc_val: 0.9767 time: 0.0178s\n",
            "Epoch: 0064 loss_train: 0.2890 acc_train: 0.9500 loss_val: 0.2023 acc_val: 0.9800 time: 0.0174s\n",
            "Epoch: 0065 loss_train: 0.2758 acc_train: 0.9533 loss_val: 0.2018 acc_val: 0.9767 time: 0.0179s\n",
            "Epoch: 0066 loss_train: 0.2895 acc_train: 0.9400 loss_val: 0.2017 acc_val: 0.9767 time: 0.0174s\n",
            "Epoch: 0067 loss_train: 0.2616 acc_train: 0.9633 loss_val: 0.2019 acc_val: 0.9733 time: 0.0173s\n",
            "Epoch: 0068 loss_train: 0.2637 acc_train: 0.9600 loss_val: 0.2024 acc_val: 0.9767 time: 0.0173s\n",
            "Epoch: 0069 loss_train: 0.2551 acc_train: 0.9600 loss_val: 0.2026 acc_val: 0.9733 time: 0.0211s\n",
            "Epoch: 0070 loss_train: 0.2811 acc_train: 0.9567 loss_val: 0.2020 acc_val: 0.9733 time: 0.0201s\n",
            "Epoch: 0071 loss_train: 0.2748 acc_train: 0.9533 loss_val: 0.2018 acc_val: 0.9767 time: 0.0176s\n",
            "Epoch: 0072 loss_train: 0.2777 acc_train: 0.9633 loss_val: 0.2018 acc_val: 0.9733 time: 0.0171s\n",
            "Epoch: 0073 loss_train: 0.3077 acc_train: 0.9367 loss_val: 0.2020 acc_val: 0.9767 time: 0.0176s\n",
            "Epoch: 0074 loss_train: 0.2604 acc_train: 0.9533 loss_val: 0.2024 acc_val: 0.9800 time: 0.0176s\n",
            "Epoch: 0075 loss_train: 0.2570 acc_train: 0.9567 loss_val: 0.2026 acc_val: 0.9733 time: 0.0188s\n",
            "Epoch: 0076 loss_train: 0.2842 acc_train: 0.9367 loss_val: 0.2031 acc_val: 0.9700 time: 0.0184s\n",
            "Epoch: 0077 loss_train: 0.2725 acc_train: 0.9667 loss_val: 0.2032 acc_val: 0.9667 time: 0.0175s\n",
            "Epoch: 0078 loss_train: 0.2504 acc_train: 0.9667 loss_val: 0.2027 acc_val: 0.9733 time: 0.0169s\n",
            "Epoch: 0079 loss_train: 0.2877 acc_train: 0.9567 loss_val: 0.2019 acc_val: 0.9700 time: 0.0279s\n",
            "Epoch: 0080 loss_train: 0.2484 acc_train: 0.9733 loss_val: 0.2017 acc_val: 0.9700 time: 0.0214s\n",
            "Epoch: 0081 loss_train: 0.2753 acc_train: 0.9700 loss_val: 0.2016 acc_val: 0.9667 time: 0.0182s\n",
            "Epoch: 0082 loss_train: 0.2755 acc_train: 0.9533 loss_val: 0.2017 acc_val: 0.9700 time: 0.0183s\n",
            "Epoch: 0083 loss_train: 0.2363 acc_train: 0.9733 loss_val: 0.2016 acc_val: 0.9667 time: 0.0178s\n",
            "Epoch: 0084 loss_train: 0.2649 acc_train: 0.9567 loss_val: 0.2017 acc_val: 0.9700 time: 0.0201s\n",
            "Epoch: 0085 loss_train: 0.2611 acc_train: 0.9500 loss_val: 0.2017 acc_val: 0.9700 time: 0.0195s\n",
            "Epoch: 0086 loss_train: 0.3040 acc_train: 0.9433 loss_val: 0.2022 acc_val: 0.9767 time: 0.0186s\n",
            "Epoch: 0087 loss_train: 0.2847 acc_train: 0.9467 loss_val: 0.2026 acc_val: 0.9800 time: 0.0181s\n",
            "Epoch: 0088 loss_train: 0.2988 acc_train: 0.9600 loss_val: 0.2031 acc_val: 0.9800 time: 0.0188s\n",
            "Epoch: 0089 loss_train: 0.2728 acc_train: 0.9500 loss_val: 0.2034 acc_val: 0.9833 time: 0.0380s\n",
            "Epoch: 0090 loss_train: 0.2470 acc_train: 0.9500 loss_val: 0.2033 acc_val: 0.9800 time: 0.0255s\n",
            "Epoch: 0091 loss_train: 0.2714 acc_train: 0.9600 loss_val: 0.2033 acc_val: 0.9767 time: 0.0213s\n",
            "Epoch: 0092 loss_train: 0.2652 acc_train: 0.9767 loss_val: 0.2031 acc_val: 0.9800 time: 0.0276s\n",
            "Epoch: 0093 loss_train: 0.2843 acc_train: 0.9600 loss_val: 0.2029 acc_val: 0.9800 time: 0.0388s\n",
            "Epoch: 0094 loss_train: 0.2947 acc_train: 0.9533 loss_val: 0.2031 acc_val: 0.9800 time: 0.0314s\n",
            "Epoch: 0095 loss_train: 0.2743 acc_train: 0.9433 loss_val: 0.2031 acc_val: 0.9767 time: 0.0271s\n",
            "Epoch: 0096 loss_train: 0.2758 acc_train: 0.9467 loss_val: 0.2030 acc_val: 0.9767 time: 0.0288s\n",
            "Epoch: 0097 loss_train: 0.2539 acc_train: 0.9633 loss_val: 0.2030 acc_val: 0.9767 time: 0.0245s\n",
            "Epoch: 0098 loss_train: 0.2671 acc_train: 0.9433 loss_val: 0.2033 acc_val: 0.9733 time: 0.0265s\n",
            "Epoch: 0099 loss_train: 0.2743 acc_train: 0.9600 loss_val: 0.2041 acc_val: 0.9733 time: 0.0254s\n",
            "Epoch: 0100 loss_train: 0.2632 acc_train: 0.9467 loss_val: 0.2046 acc_val: 0.9733 time: 0.0258s\n",
            "Epoch: 0101 loss_train: 0.2604 acc_train: 0.9533 loss_val: 0.2045 acc_val: 0.9767 time: 0.0249s\n",
            "Epoch: 0102 loss_train: 0.2894 acc_train: 0.9400 loss_val: 0.2040 acc_val: 0.9800 time: 0.0247s\n",
            "Epoch: 0103 loss_train: 0.2867 acc_train: 0.9667 loss_val: 0.2034 acc_val: 0.9767 time: 0.0255s\n",
            "Epoch: 0104 loss_train: 0.2706 acc_train: 0.9633 loss_val: 0.2030 acc_val: 0.9800 time: 0.0262s\n",
            "Epoch: 0105 loss_train: 0.2768 acc_train: 0.9500 loss_val: 0.2033 acc_val: 0.9833 time: 0.0251s\n",
            "Epoch: 0106 loss_train: 0.2461 acc_train: 0.9600 loss_val: 0.2036 acc_val: 0.9833 time: 0.0252s\n",
            "Epoch: 0107 loss_train: 0.2703 acc_train: 0.9633 loss_val: 0.2035 acc_val: 0.9800 time: 0.0241s\n",
            "Epoch: 0108 loss_train: 0.3229 acc_train: 0.9433 loss_val: 0.2033 acc_val: 0.9800 time: 0.0260s\n",
            "Epoch: 0109 loss_train: 0.2692 acc_train: 0.9500 loss_val: 0.2029 acc_val: 0.9800 time: 0.0254s\n",
            "Epoch: 0110 loss_train: 0.2648 acc_train: 0.9467 loss_val: 0.2030 acc_val: 0.9800 time: 0.0252s\n",
            "Epoch: 0111 loss_train: 0.2832 acc_train: 0.9600 loss_val: 0.2033 acc_val: 0.9767 time: 0.0338s\n",
            "Epoch: 0112 loss_train: 0.2619 acc_train: 0.9633 loss_val: 0.2037 acc_val: 0.9767 time: 0.0302s\n",
            "Epoch: 0113 loss_train: 0.2821 acc_train: 0.9367 loss_val: 0.2043 acc_val: 0.9767 time: 0.0241s\n",
            "Epoch: 0114 loss_train: 0.2733 acc_train: 0.9533 loss_val: 0.2045 acc_val: 0.9767 time: 0.0248s\n",
            "Epoch: 0115 loss_train: 0.2932 acc_train: 0.9433 loss_val: 0.2043 acc_val: 0.9700 time: 0.0278s\n",
            "Epoch: 0116 loss_train: 0.2750 acc_train: 0.9567 loss_val: 0.2041 acc_val: 0.9700 time: 0.0244s\n",
            "Epoch: 0117 loss_train: 0.2639 acc_train: 0.9600 loss_val: 0.2040 acc_val: 0.9700 time: 0.0251s\n",
            "Epoch: 0118 loss_train: 0.2926 acc_train: 0.9500 loss_val: 0.2040 acc_val: 0.9733 time: 0.0293s\n",
            "Epoch: 0119 loss_train: 0.2749 acc_train: 0.9500 loss_val: 0.2044 acc_val: 0.9767 time: 0.0319s\n",
            "Epoch: 0120 loss_train: 0.3138 acc_train: 0.9433 loss_val: 0.2045 acc_val: 0.9767 time: 0.0248s\n",
            "Epoch: 0121 loss_train: 0.2939 acc_train: 0.9533 loss_val: 0.2040 acc_val: 0.9733 time: 0.0249s\n",
            "Epoch: 0122 loss_train: 0.2775 acc_train: 0.9733 loss_val: 0.2032 acc_val: 0.9767 time: 0.0241s\n",
            "Epoch: 0123 loss_train: 0.3123 acc_train: 0.9400 loss_val: 0.2030 acc_val: 0.9767 time: 0.0241s\n",
            "Epoch: 0124 loss_train: 0.2653 acc_train: 0.9633 loss_val: 0.2034 acc_val: 0.9700 time: 0.0252s\n",
            "Epoch: 0125 loss_train: 0.2998 acc_train: 0.9400 loss_val: 0.2041 acc_val: 0.9733 time: 0.0253s\n",
            "Epoch: 0126 loss_train: 0.2670 acc_train: 0.9567 loss_val: 0.2040 acc_val: 0.9733 time: 0.0255s\n",
            "Epoch: 0127 loss_train: 0.2674 acc_train: 0.9500 loss_val: 0.2033 acc_val: 0.9733 time: 0.0289s\n",
            "Epoch: 0128 loss_train: 0.2886 acc_train: 0.9600 loss_val: 0.2029 acc_val: 0.9767 time: 0.0309s\n",
            "Epoch: 0129 loss_train: 0.2588 acc_train: 0.9500 loss_val: 0.2025 acc_val: 0.9767 time: 0.0254s\n",
            "Epoch: 0130 loss_train: 0.2743 acc_train: 0.9667 loss_val: 0.2022 acc_val: 0.9767 time: 0.0252s\n",
            "Epoch: 0131 loss_train: 0.2792 acc_train: 0.9400 loss_val: 0.2023 acc_val: 0.9767 time: 0.0248s\n",
            "Epoch: 0132 loss_train: 0.2909 acc_train: 0.9500 loss_val: 0.2029 acc_val: 0.9800 time: 0.0283s\n",
            "Epoch: 0133 loss_train: 0.2702 acc_train: 0.9500 loss_val: 0.2030 acc_val: 0.9833 time: 0.0252s\n",
            "Epoch: 0134 loss_train: 0.2980 acc_train: 0.9433 loss_val: 0.2030 acc_val: 0.9800 time: 0.0256s\n",
            "Epoch: 0135 loss_train: 0.2573 acc_train: 0.9567 loss_val: 0.2025 acc_val: 0.9767 time: 0.0250s\n",
            "Epoch: 0136 loss_train: 0.3178 acc_train: 0.9500 loss_val: 0.2022 acc_val: 0.9767 time: 0.0246s\n",
            "Epoch: 0137 loss_train: 0.2789 acc_train: 0.9600 loss_val: 0.2021 acc_val: 0.9733 time: 0.0250s\n",
            "Epoch: 0138 loss_train: 0.2862 acc_train: 0.9433 loss_val: 0.2023 acc_val: 0.9767 time: 0.0255s\n",
            "Epoch: 0139 loss_train: 0.2876 acc_train: 0.9467 loss_val: 0.2025 acc_val: 0.9800 time: 0.0249s\n",
            "Epoch: 0140 loss_train: 0.2753 acc_train: 0.9500 loss_val: 0.2025 acc_val: 0.9800 time: 0.0332s\n",
            "Epoch: 0141 loss_train: 0.2760 acc_train: 0.9567 loss_val: 0.2026 acc_val: 0.9833 time: 0.0247s\n",
            "Epoch: 0142 loss_train: 0.2866 acc_train: 0.9467 loss_val: 0.2026 acc_val: 0.9800 time: 0.0243s\n",
            "Epoch: 0143 loss_train: 0.2747 acc_train: 0.9500 loss_val: 0.2024 acc_val: 0.9767 time: 0.0239s\n",
            "Epoch: 0144 loss_train: 0.2811 acc_train: 0.9667 loss_val: 0.2019 acc_val: 0.9767 time: 0.0247s\n",
            "Epoch: 0145 loss_train: 0.2811 acc_train: 0.9633 loss_val: 0.2015 acc_val: 0.9767 time: 0.0241s\n",
            "Epoch: 0146 loss_train: 0.2781 acc_train: 0.9533 loss_val: 0.2011 acc_val: 0.9700 time: 0.0250s\n",
            "Epoch: 0147 loss_train: 0.2697 acc_train: 0.9500 loss_val: 0.2009 acc_val: 0.9700 time: 0.0242s\n",
            "Epoch: 0148 loss_train: 0.2803 acc_train: 0.9500 loss_val: 0.2008 acc_val: 0.9767 time: 0.0314s\n",
            "Epoch: 0149 loss_train: 0.2668 acc_train: 0.9533 loss_val: 0.2008 acc_val: 0.9800 time: 0.0243s\n",
            "Epoch: 0150 loss_train: 0.3057 acc_train: 0.9433 loss_val: 0.2003 acc_val: 0.9800 time: 0.0238s\n",
            "Epoch: 0151 loss_train: 0.2561 acc_train: 0.9700 loss_val: 0.2002 acc_val: 0.9733 time: 0.0256s\n",
            "Epoch: 0152 loss_train: 0.2774 acc_train: 0.9600 loss_val: 0.2007 acc_val: 0.9767 time: 0.0257s\n",
            "Epoch: 0153 loss_train: 0.3058 acc_train: 0.9400 loss_val: 0.2014 acc_val: 0.9767 time: 0.0249s\n",
            "Epoch: 0154 loss_train: 0.2735 acc_train: 0.9567 loss_val: 0.2017 acc_val: 0.9800 time: 0.0242s\n",
            "Epoch: 0155 loss_train: 0.2648 acc_train: 0.9500 loss_val: 0.2019 acc_val: 0.9767 time: 0.0246s\n",
            "Epoch: 0156 loss_train: 0.2819 acc_train: 0.9633 loss_val: 0.2018 acc_val: 0.9767 time: 0.0296s\n",
            "Epoch: 0157 loss_train: 0.2648 acc_train: 0.9567 loss_val: 0.2014 acc_val: 0.9767 time: 0.0235s\n",
            "Epoch: 0158 loss_train: 0.2690 acc_train: 0.9667 loss_val: 0.2010 acc_val: 0.9767 time: 0.0240s\n",
            "Epoch: 0159 loss_train: 0.2549 acc_train: 0.9633 loss_val: 0.2006 acc_val: 0.9767 time: 0.0246s\n",
            "Epoch: 0160 loss_train: 0.2650 acc_train: 0.9567 loss_val: 0.2002 acc_val: 0.9767 time: 0.0274s\n",
            "Epoch: 0161 loss_train: 0.2658 acc_train: 0.9400 loss_val: 0.2003 acc_val: 0.9800 time: 0.0310s\n",
            "Epoch: 0162 loss_train: 0.2888 acc_train: 0.9467 loss_val: 0.2006 acc_val: 0.9800 time: 0.0251s\n",
            "Epoch: 0163 loss_train: 0.3050 acc_train: 0.9433 loss_val: 0.2007 acc_val: 0.9800 time: 0.0255s\n",
            "Epoch: 0164 loss_train: 0.2891 acc_train: 0.9500 loss_val: 0.2009 acc_val: 0.9767 time: 0.0302s\n",
            "Epoch: 0165 loss_train: 0.2632 acc_train: 0.9600 loss_val: 0.2009 acc_val: 0.9800 time: 0.0247s\n",
            "Epoch: 0166 loss_train: 0.2576 acc_train: 0.9467 loss_val: 0.2005 acc_val: 0.9800 time: 0.0254s\n",
            "Epoch: 0167 loss_train: 0.2772 acc_train: 0.9467 loss_val: 0.2003 acc_val: 0.9733 time: 0.0287s\n",
            "Epoch: 0168 loss_train: 0.2664 acc_train: 0.9400 loss_val: 0.2005 acc_val: 0.9733 time: 0.0265s\n",
            "Epoch: 0169 loss_train: 0.2778 acc_train: 0.9433 loss_val: 0.2008 acc_val: 0.9700 time: 0.0256s\n",
            "Epoch: 0170 loss_train: 0.2743 acc_train: 0.9367 loss_val: 0.2012 acc_val: 0.9700 time: 0.0346s\n",
            "Epoch: 0171 loss_train: 0.2773 acc_train: 0.9467 loss_val: 0.2013 acc_val: 0.9700 time: 0.0251s\n",
            "Epoch: 0172 loss_train: 0.2916 acc_train: 0.9433 loss_val: 0.2012 acc_val: 0.9700 time: 0.0262s\n",
            "Epoch: 0173 loss_train: 0.2835 acc_train: 0.9400 loss_val: 0.2012 acc_val: 0.9700 time: 0.0256s\n",
            "Epoch: 0174 loss_train: 0.2792 acc_train: 0.9467 loss_val: 0.2018 acc_val: 0.9733 time: 0.0253s\n",
            "Epoch: 0175 loss_train: 0.2726 acc_train: 0.9633 loss_val: 0.2022 acc_val: 0.9767 time: 0.0253s\n",
            "Epoch: 0176 loss_train: 0.2950 acc_train: 0.9567 loss_val: 0.2023 acc_val: 0.9800 time: 0.0249s\n",
            "Epoch: 0177 loss_train: 0.2697 acc_train: 0.9500 loss_val: 0.2022 acc_val: 0.9767 time: 0.0250s\n",
            "Epoch: 0178 loss_train: 0.2610 acc_train: 0.9633 loss_val: 0.2028 acc_val: 0.9733 time: 0.0310s\n",
            "Epoch: 0179 loss_train: 0.2909 acc_train: 0.9433 loss_val: 0.2034 acc_val: 0.9700 time: 0.0254s\n",
            "Epoch: 0180 loss_train: 0.2654 acc_train: 0.9567 loss_val: 0.2036 acc_val: 0.9700 time: 0.0249s\n",
            "Epoch: 0181 loss_train: 0.2603 acc_train: 0.9533 loss_val: 0.2027 acc_val: 0.9767 time: 0.0251s\n",
            "Epoch: 0182 loss_train: 0.2700 acc_train: 0.9633 loss_val: 0.2019 acc_val: 0.9733 time: 0.0251s\n",
            "Epoch: 0183 loss_train: 0.2772 acc_train: 0.9400 loss_val: 0.2019 acc_val: 0.9767 time: 0.0244s\n",
            "Epoch: 0184 loss_train: 0.2821 acc_train: 0.9533 loss_val: 0.2018 acc_val: 0.9767 time: 0.0276s\n",
            "Epoch: 0185 loss_train: 0.2992 acc_train: 0.9500 loss_val: 0.2012 acc_val: 0.9767 time: 0.0255s\n",
            "Epoch: 0186 loss_train: 0.2781 acc_train: 0.9467 loss_val: 0.2008 acc_val: 0.9733 time: 0.0248s\n",
            "Epoch: 0187 loss_train: 0.2828 acc_train: 0.9467 loss_val: 0.2013 acc_val: 0.9733 time: 0.0260s\n",
            "Epoch: 0188 loss_train: 0.2953 acc_train: 0.9567 loss_val: 0.2035 acc_val: 0.9633 time: 0.0245s\n",
            "Epoch: 0189 loss_train: 0.2767 acc_train: 0.9400 loss_val: 0.2048 acc_val: 0.9600 time: 0.0263s\n",
            "Epoch: 0190 loss_train: 0.2903 acc_train: 0.9500 loss_val: 0.2045 acc_val: 0.9667 time: 0.0236s\n",
            "Epoch: 0191 loss_train: 0.2740 acc_train: 0.9333 loss_val: 0.2031 acc_val: 0.9667 time: 0.0237s\n",
            "Epoch: 0192 loss_train: 0.2818 acc_train: 0.9533 loss_val: 0.2014 acc_val: 0.9733 time: 0.0264s\n",
            "Epoch: 0193 loss_train: 0.2475 acc_train: 0.9667 loss_val: 0.2016 acc_val: 0.9800 time: 0.0239s\n",
            "Epoch: 0194 loss_train: 0.2538 acc_train: 0.9533 loss_val: 0.2035 acc_val: 0.9800 time: 0.0249s\n",
            "Epoch: 0195 loss_train: 0.2694 acc_train: 0.9733 loss_val: 0.2042 acc_val: 0.9800 time: 0.0237s\n",
            "Epoch: 0196 loss_train: 0.2877 acc_train: 0.9567 loss_val: 0.2025 acc_val: 0.9800 time: 0.0259s\n",
            "Epoch: 0197 loss_train: 0.2828 acc_train: 0.9633 loss_val: 0.2003 acc_val: 0.9800 time: 0.0240s\n",
            "Epoch: 0198 loss_train: 0.2761 acc_train: 0.9533 loss_val: 0.2007 acc_val: 0.9833 time: 0.0254s\n",
            "Epoch: 0199 loss_train: 0.2653 acc_train: 0.9433 loss_val: 0.2028 acc_val: 0.9667 time: 0.0243s\n",
            "Epoch: 0200 loss_train: 0.3042 acc_train: 0.9367 loss_val: 0.2036 acc_val: 0.9667 time: 0.0303s\n",
            "After Completion of 300 labeled nodes\n",
            "Time taken: 5.1353s\n",
            "Test set results: loss= 0.5274 accuracy= 0.8320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation-\n",
        "\n",
        "After Completion of 60 labeled nodes\n",
        "Time taken: 4.5737s\n",
        "Test set results: loss= 0.8145 accuracy= 0.7500\n",
        "\n",
        "After Completion of 180 labeled nodes\n",
        "Time taken: 4.5642s\n",
        "Test set results: loss= 0.6646 accuracy= 0.7870\n",
        "\n",
        "After Completion of 120 labeled nodes\n",
        "Time taken: 5.2855s\n",
        "Test set results: loss= 0.7413 accuracy= 0.7860\n",
        "\n",
        "After Completion of 240 labeled nodes\n",
        "Time taken: 4.3290s\n",
        "Test set results: loss= 0.5481 accuracy= 0.8230\n",
        "\n",
        "After Completion of 300 labeled nodes\n",
        "Time taken: 5.1353s\n",
        "Test set results: loss= 0.5274 accuracy= 0.8320"
      ],
      "metadata": {
        "id": "sowShB2kOrXa"
      }
    }
  ]
}